{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Instruction Formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": "## Why Formatting Matters (Really Matters)\n\nWith language models, they're just predicting the next token. That's it.\n\nThink about what happens when you type \"The capital of France is\" — the model sees those tokens and thinks \"ah yes, I've seen this pattern before in my training data, the next token is probably 'Paris'.\"\n\nBut now imagine you want the model to follow an instruction. You type:\n\n```\nTell me about Paris.\n```\n\nAnd... the model might continue with anything. Maybe it starts generating a conversation. Maybe it writes a story. Maybe it keeps asking more questions. Why? Because during pre-training, it saw all sorts of text on the internet — conversations, stories, articles, Q&A forums — and it has no idea which pattern you want it to follow right now.\n\n**This is where formatting comes in.**\n\nWhen we fine-tune a model on instructions, we're teaching it a very specific pattern:\n- When you see text formatted THIS way → that's an instruction\n- When you see THIS special marker → start your response\n- When you see THAT special token → stop generating\n\nIt's like training a dog with consistent commands. You can't say \"sit\" one day and \"please lower your rear end to the ground\" the next and expect the dog to understand. Same with models — they need consistency.\n\nWithout proper formatting:\n- The model doesn't know when to stop generating (it just keeps going...)\n- It can't tell instructions from responses (is this part of the question or the answer?)\n- Multi-turn conversations become impossible (who's talking right now?)\n- The model might repeat your instruction back to you instead of answering it\n\n**Chat templates** solve all of this by wrapping messages in a consistent structure with special tokens. And once a model learns a template, it works beautifully. But only if you use the exact same format every time.\n\n(This is why you can't just grab a model fine-tuned with one chat template and use it with a different one — it's like speaking German to someone who only learned French.)"
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## The Big Three Chat Formats\n",
    "\n",
    "Different research labs invented different formats. None is objectively \"better\" — they're just different conventions. Let's look at the three most popular ones.\n",
    "\n",
    "### Alpaca Format (Stanford)\n",
    "\n",
    "Stanford's Alpaca team wanted something human-readable. Look at this:\n",
    "\n",
    "```\n",
    "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Response:\n",
    "{response}\n",
    "```\n",
    "\n",
    "See what they did? The `### Instruction:` and `### Response:` markers are clear delimiters. A human can read this and immediately understand what's what. The model learns to recognize these markers and knows \"aha, after I see `### Response:`, I should start generating my answer.\"\n",
    "\n",
    "There's also a variant with an `### Input:` field for tasks where you need both an instruction AND some data to work with (like \"Summarize this text: [long article]\").\n",
    "\n",
    "### ChatML Format (OpenAI)\n",
    "\n",
    "OpenAI went a different direction — special tokens that won't appear in normal text:\n",
    "\n",
    "```\n",
    "<|im_start|>system\n",
    "You are a helpful assistant.<|im_end|>\n",
    "<|im_start|>user\n",
    "{instruction}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "{response}<|im_end|>\n",
    "```\n",
    "\n",
    "The `<|im_start|>` and `<|im_end|>` tokens (im = \"instant message\") are added to the tokenizer vocabulary. They're designed to never appear in regular text, which means the model can be absolutely certain that when it sees `<|im_start|>assistant`, it's time to generate a response.\n",
    "\n",
    "Notice the `system`, `user`, and `assistant` roles? This lets you:\n",
    "- Set a system prompt that guides behavior\n",
    "- Track who said what in multi-turn conversations\n",
    "- Handle back-and-forth dialogue naturally\n",
    "\n",
    "### Llama 2 Format (Meta)\n",
    "\n",
    "Meta created their own format for Llama 2:\n",
    "\n",
    "```\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful assistant.\n",
    "<</SYS>>\n",
    "\n",
    "{instruction} [/INST] {response} </s>\n",
    "```\n",
    "\n",
    "Here:\n",
    "- `<s>` = beginning of sequence (special token)\n",
    "- `[INST]` and `[/INST]` = instruction boundaries\n",
    "- `<<SYS>>` and `<</SYS>>` = system message boundaries\n",
    "- `</s>` = end of sequence (special token)\n",
    "\n",
    "The `<s>` and `</s>` tokens are borrowed from sequence-to-sequence models (think translation). They tell the model \"this is the start\" and \"this is the end.\"\n",
    "\n",
    "**The key insight:** All three formats do the same job — they create clear boundaries. The model just needs to learn whichever pattern you pick. But once you pick one, you're committed to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T21:18:15.880045Z",
     "iopub.status.busy": "2025-12-10T21:18:15.879952Z",
     "iopub.status.idle": "2025-12-10T21:18:15.882982Z",
     "shell.execute_reply": "2025-12-10T21:18:15.882695Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1: Simple instruction\n",
      "============================================================\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Explain quantum computing in simple terms.\n",
      "\n",
      "### Response:\n",
      "Quantum computing uses quantum mechanics to process information in fundamentally different ways than classical computers, potentially solving certain problems exponentially faster.\n",
      "\n",
      "\n",
      "Example 2: Instruction with input\n",
      "============================================================\n",
      "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Translate this sentence to French.\n",
      "\n",
      "### Input:\n",
      "The cat sits on the mat.\n",
      "\n",
      "### Response:\n",
      "Le chat est assis sur le tapis.\n"
     ]
    }
   ],
   "source": [
    "# Let's implement Alpaca formatting (it's the most human-readable)\n",
    "\n",
    "ALPACA_TEMPLATE = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Response:\n",
    "{response}\"\"\"\n",
    "\n",
    "ALPACA_TEMPLATE_WITH_INPUT = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Input:\n",
    "{input}\n",
    "\n",
    "### Response:\n",
    "{response}\"\"\"\n",
    "\n",
    "def format_alpaca(instruction: str, response: str = \"\", input_text: str = \"\") -> str:\n",
    "    \"\"\"\n",
    "    Format a training example in Alpaca style.\n",
    "    \n",
    "    Args:\n",
    "        instruction: The task description (\"Summarize this text\")\n",
    "        response: The model's expected response\n",
    "        input_text: Optional additional context (like the text to summarize)\n",
    "    \n",
    "    Returns:\n",
    "        Formatted string ready for training\n",
    "    \"\"\"\n",
    "    if input_text:\n",
    "        return ALPACA_TEMPLATE_WITH_INPUT.format(\n",
    "            instruction=instruction,\n",
    "            input=input_text,\n",
    "            response=response\n",
    "        )\n",
    "    return ALPACA_TEMPLATE.format(\n",
    "        instruction=instruction,\n",
    "        response=response\n",
    "    )\n",
    "\n",
    "# Let's see it in action\n",
    "print(\"Example 1: Simple instruction\")\n",
    "print(\"=\" * 60)\n",
    "formatted = format_alpaca(\n",
    "    instruction=\"Explain quantum computing in simple terms.\",\n",
    "    response=\"Quantum computing uses quantum mechanics to process information in fundamentally different ways than classical computers, potentially solving certain problems exponentially faster.\"\n",
    ")\n",
    "print(formatted)\n",
    "\n",
    "print(\"\\n\\nExample 2: Instruction with input\")\n",
    "print(\"=\" * 60)\n",
    "formatted_with_input = format_alpaca(\n",
    "    instruction=\"Translate this sentence to French.\",\n",
    "    input_text=\"The cat sits on the mat.\",\n",
    "    response=\"Le chat est assis sur le tapis.\"\n",
    ")\n",
    "print(formatted_with_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T21:18:15.883765Z",
     "iopub.status.busy": "2025-12-10T21:18:15.883694Z",
     "iopub.status.idle": "2025-12-10T21:18:15.885939Z",
     "shell.execute_reply": "2025-12-10T21:18:15.885638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatML Example:\n",
      "============================================================\n",
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "What is the capital of France?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "The capital of France is Paris.<|im_end|>\n",
      "\n",
      "\n",
      "Notice:\n",
      "- The system message comes first (sets the assistant's personality)\n",
      "- Each role is clearly marked: system, user, assistant\n",
      "- Special tokens make boundaries crystal clear\n",
      "- This format makes multi-turn conversations easy to handle\n"
     ]
    }
   ],
   "source": [
    "# Now let's implement ChatML (the one with special tokens)\n",
    "\n",
    "def format_chatml(\n",
    "    instruction: str,\n",
    "    response: str = \"\",\n",
    "    system: str = \"You are a helpful assistant.\"\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Format a conversation in ChatML style.\n",
    "    \n",
    "    This format uses special tokens (<|im_start|> and <|im_end|>) that are\n",
    "    added to the tokenizer's vocabulary. They're designed to never appear\n",
    "    in regular text, giving the model unambiguous boundaries.\n",
    "    \n",
    "    Args:\n",
    "        instruction: What the user is asking\n",
    "        response: What the assistant should say back\n",
    "        system: System prompt that sets the assistant's behavior\n",
    "    \n",
    "    Returns:\n",
    "        Formatted string with special tokens\n",
    "    \"\"\"\n",
    "    formatted = f\"<|im_start|>system\\n{system}<|im_end|>\\n\"\n",
    "    formatted += f\"<|im_start|>user\\n{instruction}<|im_end|>\\n\"\n",
    "    formatted += f\"<|im_start|>assistant\\n{response}\"\n",
    "    \n",
    "    # Only add the closing token if there's a response\n",
    "    # (During training, we'll want to generate starting from here)\n",
    "    if response:\n",
    "        formatted += \"<|im_end|>\"\n",
    "    \n",
    "    return formatted\n",
    "\n",
    "# Let's see how it looks\n",
    "print(\"ChatML Example:\")\n",
    "print(\"=\" * 60)\n",
    "formatted = format_chatml(\n",
    "    instruction=\"What is the capital of France?\",\n",
    "    response=\"The capital of France is Paris.\"\n",
    ")\n",
    "print(formatted)\n",
    "\n",
    "print(\"\\n\\nNotice:\")\n",
    "print(\"- The system message comes first (sets the assistant's personality)\")\n",
    "print(\"- Each role is clearly marked: system, user, assistant\")\n",
    "print(\"- Special tokens make boundaries crystal clear\")\n",
    "print(\"- This format makes multi-turn conversations easy to handle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Using Built-in Chat Templates\n",
    "\n",
    "Here's the good news: you usually don't have to write this formatting code yourself.\n",
    "\n",
    "Modern tokenizers (from HuggingFace) come with chat templates built in. When someone releases a fine-tuned model, they bake the chat template right into the tokenizer config. This means:\n",
    "- You can't accidentally use the wrong format\n",
    "- Multi-turn conversations are handled automatically\n",
    "- The format stays consistent between training and inference\n",
    "\n",
    "Let's load a tokenizer and see its chat template in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T21:18:15.886709Z",
     "iopub.status.busy": "2025-12-10T21:18:15.886640Z",
     "iopub.status.idle": "2025-12-10T21:18:17.738667Z",
     "shell.execute_reply": "2025-12-10T21:18:17.738351Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using built-in chat template:\n",
      "============================================================\n",
      "Hello, how are you?<|endoftext|>I'm doing well, thank you! How can I help you today?<|endoftext|>Can you explain machine learning?<|endoftext|>\n",
      "\n",
      "============================================================\n",
      "\n",
      "What happened here?\n",
      "The tokenizer automatically:\n",
      "- Added special tokens between turns\n",
      "- Formatted the multi-turn conversation\n",
      "- Made sure everything is ready for the model\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load a tokenizer with chat template support\n",
    "# (DialoGPT is a conversational model, so it has a simple chat template)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-small\")\n",
    "\n",
    "# Create a multi-turn conversation\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"I'm doing well, thank you! How can I help you today?\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you explain machine learning?\"}\n",
    "]\n",
    "\n",
    "# Check if tokenizer has a chat template\n",
    "if hasattr(tokenizer, 'chat_template') and tokenizer.chat_template:\n",
    "    formatted = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "    print(\"Using built-in chat template:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(formatted)\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"\\nWhat happened here?\")\n",
    "    print(\"The tokenizer automatically:\")\n",
    "    print(\"- Added special tokens between turns\")\n",
    "    print(\"- Formatted the multi-turn conversation\")\n",
    "    print(\"- Made sure everything is ready for the model\")\n",
    "else:\n",
    "    print(\"This tokenizer doesn't have a chat template.\")\n",
    "    print(\"(That's okay — we can use our custom formats from above)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Finding Where the Response Starts (This is Critical for Training)\n",
    "\n",
    "Okay, here's a key insight about how we actually train these models.\n",
    "\n",
    "When you fine-tune on instruction data, you don't want to compute loss on the instruction part. Why? Because the model doesn't need to learn how to generate instructions — it needs to learn how to generate *responses*.\n",
    "\n",
    "Think about it:\n",
    "- Instruction: \"Explain quantum computing in simple terms.\"\n",
    "- Response: \"Quantum computing uses quantum mechanics...\"\n",
    "\n",
    "We want the model to get better at generating that response. We don't care if it can predict the instruction — that's the input, not the output!\n",
    "\n",
    "So during training, we \"mask\" the instruction tokens. We only compute loss on the response tokens. This is called **loss masking** or **attention masking**.\n",
    "\n",
    "To do this, we need to know: where does the response start?\n",
    "\n",
    "Let's write some code to find that boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T21:18:17.739900Z",
     "iopub.status.busy": "2025-12-10T21:18:17.739774Z",
     "iopub.status.idle": "2025-12-10T21:18:18.059304Z",
     "shell.execute_reply": "2025-12-10T21:18:18.058948Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted text:\n",
      "============================================================\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is 2+2?\n",
      "\n",
      "### Response:\n",
      "2+2 equals 4. This is basic arithmetic.\n",
      "============================================================\n",
      "\n",
      "Response starts at:\n",
      "  Character position: 152\n",
      "  Token position: 36\n",
      "\n",
      "Token breakdown:\n",
      "  Total tokens: 47\n",
      "  Prompt tokens: 36 (we don't compute loss here)\n",
      "  Response tokens: 11 (we DO compute loss here)\n",
      "\n",
      "============================================================\n",
      "The prompt part (no loss):\n",
      "'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nWhat is 2+2?\\n\\n### Response:\\n'\n",
      "\n",
      "============================================================\n",
      "The response part (compute loss):\n",
      "'2+2 equals 4. This is basic arithmetic.'\n"
     ]
    }
   ],
   "source": [
    "def find_response_start(formatted_text: str, response_marker: str = \"### Response:\\n\") -> int:\n",
    "    \"\"\"\n",
    "    Find the character position where the response starts.\n",
    "    \n",
    "    Args:\n",
    "        formatted_text: The full formatted prompt\n",
    "        response_marker: The string that marks the start of the response\n",
    "    \n",
    "    Returns:\n",
    "        Character index where the response begins\n",
    "    \"\"\"\n",
    "    idx = formatted_text.find(response_marker)\n",
    "    if idx == -1:\n",
    "        raise ValueError(f\"Response marker '{response_marker}' not found in text\")\n",
    "    # Return position AFTER the marker (where the actual response starts)\n",
    "    return idx + len(response_marker)\n",
    "\n",
    "def find_response_start_tokens(tokenizer, formatted_text: str, response_marker: str = \"### Response:\\n\"):\n",
    "    \"\"\"\n",
    "    Find the token position where the response starts.\n",
    "    \n",
    "    This is trickier than finding the character position because:\n",
    "    - Tokens don't always align with character boundaries\n",
    "    - We need to count tokens, not characters\n",
    "    \n",
    "    Args:\n",
    "        tokenizer: The tokenizer to use\n",
    "        formatted_text: The full formatted prompt\n",
    "        response_marker: The string that marks the start of the response\n",
    "    \n",
    "    Returns:\n",
    "        Token index where the response begins\n",
    "    \"\"\"\n",
    "    # First, find where the response starts in character space\n",
    "    char_pos = find_response_start(formatted_text, response_marker)\n",
    "    \n",
    "    # Tokenize just the prompt part (everything before the response)\n",
    "    prompt_text = formatted_text[:char_pos]\n",
    "    prompt_tokens = tokenizer.encode(prompt_text, add_special_tokens=False)\n",
    "    \n",
    "    # The number of prompt tokens is where the response starts!\n",
    "    return len(prompt_tokens)\n",
    "\n",
    "# Let's test this\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Create a formatted example\n",
    "text = format_alpaca(\n",
    "    instruction=\"What is 2+2?\",\n",
    "    response=\"2+2 equals 4. This is basic arithmetic.\"\n",
    ")\n",
    "\n",
    "print(\"Formatted text:\")\n",
    "print(\"=\" * 60)\n",
    "print(text)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Find where the response starts\n",
    "response_start_char = find_response_start(text)\n",
    "response_start_token = find_response_start_tokens(tokenizer, text)\n",
    "\n",
    "print(f\"\\nResponse starts at:\")\n",
    "print(f\"  Character position: {response_start_char}\")\n",
    "print(f\"  Token position: {response_start_token}\")\n",
    "\n",
    "# Show the breakdown\n",
    "tokens = tokenizer.encode(text)\n",
    "print(f\"\\nToken breakdown:\")\n",
    "print(f\"  Total tokens: {len(tokens)}\")\n",
    "print(f\"  Prompt tokens: {response_start_token} (we don't compute loss here)\")\n",
    "print(f\"  Response tokens: {len(tokens) - response_start_token} (we DO compute loss here)\")\n",
    "\n",
    "# Visualize the split\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"The prompt part (no loss):\")\n",
    "print(repr(text[:response_start_char]))\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"The response part (compute loss):\")\n",
    "print(repr(text[response_start_char:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Best Practices (Learn from Others' Mistakes)\n",
    "\n",
    "Here are the things that trip people up when formatting instruction data:\n",
    "\n",
    "### 1. Be Consistent (No Really, Be Obsessively Consistent)\n",
    "\n",
    "Use the exact same format for every single training example. Not \"mostly the same\" — exactly the same. If you have:\n",
    "- 10,000 examples in Alpaca format\n",
    "- 5 examples where you forgot the preamble\n",
    "- 3 examples where you used a different marker\n",
    "\n",
    "Your model will be confused on those 8 examples and might learn the wrong pattern.\n",
    "\n",
    "### 2. Match Training and Inference\n",
    "\n",
    "This is the #1 mistake people make. They:\n",
    "- Train with Alpaca format\n",
    "- Then try to use it with ChatML format at inference time\n",
    "- Wonder why the model outputs gibberish\n",
    "\n",
    "The model learned that responses come after `### Response:`. If you don't include that marker when generating, it's like asking someone to \"fetch\" when you trained them to respond to \"sit\".\n",
    "\n",
    "### 3. Add Special Tokens to the Tokenizer\n",
    "\n",
    "If you're using special tokens like `<|im_start|>` or `<s>`, you need to:\n",
    "- Add them to the tokenizer's vocabulary\n",
    "- Tell the tokenizer they're special (so they don't get split up)\n",
    "- Make sure they're present in all examples\n",
    "\n",
    "### 4. Handle Edge Cases\n",
    "\n",
    "Think about:\n",
    "- Empty inputs (what if someone sends just the instruction?)\n",
    "- Very long texts (what if the instruction+response exceeds context length?)\n",
    "- Special characters (what if the instruction contains your marker string?)\n",
    "- Unicode and emojis (does your tokenizer handle them?)\n",
    "\n",
    "### 5. Document Your Format\n",
    "\n",
    "Seriously. Write down:\n",
    "- Which chat template you used\n",
    "- Why you chose it\n",
    "- How to use the model at inference time\n",
    "- Any special tokens you added\n",
    "\n",
    "Future you (or someone else using your model) will thank you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": "## What We Learned\n\nLet's recap what we covered:\n\n**Why formatting matters:** Language models are next-token predictors. Without consistent formatting, they don't know when to stop, when to respond, or how to handle multi-turn conversations. Chat templates solve this by creating clear boundaries with special tokens.\n\n**The three main formats:**\n- **Alpaca:** Human-readable with `### Instruction:` and `### Response:` markers\n- **ChatML:** Special tokens with role-based messages (system, user, assistant)\n- **Llama 2:** Meta's format with `[INST]` and `</s>` tokens\n\n**Built-in templates:** Modern tokenizers have chat templates baked in, so you usually don't need to write formatting code yourself. Just call `tokenizer.apply_chat_template()`.\n\n**Loss masking:** During training, we only compute loss on response tokens, not instruction tokens. This means we need to find where the response starts and mask everything before it.\n\n**Consistency is key:** Pick a format and stick with it. Use the same template during training and inference. Otherwise, your model won't understand what you're asking it to do.\n\n## Up Next\n\nNow that we understand formatting, the next notebook will dive into **loss masking** — how to actually implement the selective loss computation during training. We'll see how to create attention masks, why we mask the instruction part, and how this affects what the model learns.\n\n(It makes a huge difference in model quality.)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0d3b6d4bf6e8407f93d331b3e19afb45": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2024609be01444da9b7dc8ddc54a5505": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2deb1c7eccfd492b96378ba8a6061019": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "33eb3f7df30149cf9a7435e062aa136b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "354dc0f380844ee384663c24cc0ac8b0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4c2827a236db460e9254b5d2aa6c0ad8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0d3b6d4bf6e8407f93d331b3e19afb45",
       "max": 614,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ca848dc7e92942ada130fbf03c7447ab",
       "tabbable": null,
       "tooltip": null,
       "value": 614
      }
     },
     "51beed1c188d4e959cb44677019c5b1f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "53d879d357254022bb6d2725d1c50fc7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_551785afaa40454184dc8421725d6c9c",
       "placeholder": "​",
       "style": "IPY_MODEL_33eb3f7df30149cf9a7435e062aa136b",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "551785afaa40454184dc8421725d6c9c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "68b6a4f589bf437a81304a3443cad526": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_72271bcb06614690b02611d7f815f160",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_be811a14629f472fa428606ae1ec3961",
       "tabbable": null,
       "tooltip": null,
       "value": 1
      }
     },
     "6e91591f17f44294933da9f497bedb04": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "72271bcb06614690b02611d7f815f160": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "73a923805a3341eea3da4a2ca1d3e15d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7c8089bc98e2419482f724c2e631ee56": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "876d3892a8714924a629e1647a9e28a2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_73a923805a3341eea3da4a2ca1d3e15d",
       "placeholder": "​",
       "style": "IPY_MODEL_7c8089bc98e2419482f724c2e631ee56",
       "tabbable": null,
       "tooltip": null,
       "value": " 456k/? [00:00&lt;00:00, 89.8MB/s]"
      }
     },
     "8ec8204249394cd8b0983ddf431a8414": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "929fac731c694f35bb31d9594944074c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b39bb454ca0f49b1a4ac03221ba6a38a",
       "placeholder": "​",
       "style": "IPY_MODEL_2deb1c7eccfd492b96378ba8a6061019",
       "tabbable": null,
       "tooltip": null,
       "value": "merges.txt: "
      }
     },
     "97838a34d1684b7a8b886f7d85deee9c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "985535cb1f9349e6bed25270e4b5522a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9d644c7dd996420dbae384b19628b2b4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_97838a34d1684b7a8b886f7d85deee9c",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_51beed1c188d4e959cb44677019c5b1f",
       "tabbable": null,
       "tooltip": null,
       "value": 1
      }
     },
     "a098f276261443c583a6aa33fa14c4e9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_53d879d357254022bb6d2725d1c50fc7",
        "IPY_MODEL_4c2827a236db460e9254b5d2aa6c0ad8",
        "IPY_MODEL_b7b9c3401a414feeb790f7a30007960b"
       ],
       "layout": "IPY_MODEL_354dc0f380844ee384663c24cc0ac8b0",
       "tabbable": null,
       "tooltip": null
      }
     },
     "a466898ebbc74a6699a7275c9565b560": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6e91591f17f44294933da9f497bedb04",
       "placeholder": "​",
       "style": "IPY_MODEL_efc85091903442e5b76c951e52e71045",
       "tabbable": null,
       "tooltip": null,
       "value": " 1.04M/? [00:00&lt;00:00, 72.5MB/s]"
      }
     },
     "a70d9cfb77f94c3282b2efeb294a60df": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ac3d5f01968f491e995888be60fbafef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ae23b16b13124c6d92e0ae3854ecb1e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_929fac731c694f35bb31d9594944074c",
        "IPY_MODEL_68b6a4f589bf437a81304a3443cad526",
        "IPY_MODEL_876d3892a8714924a629e1647a9e28a2"
       ],
       "layout": "IPY_MODEL_985535cb1f9349e6bed25270e4b5522a",
       "tabbable": null,
       "tooltip": null
      }
     },
     "b35bee12c8bd4c3e8d50ca35ee1a367f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b39bb454ca0f49b1a4ac03221ba6a38a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b7b9c3401a414feeb790f7a30007960b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ac3d5f01968f491e995888be60fbafef",
       "placeholder": "​",
       "style": "IPY_MODEL_a70d9cfb77f94c3282b2efeb294a60df",
       "tabbable": null,
       "tooltip": null,
       "value": " 614/614 [00:00&lt;00:00, 194kB/s]"
      }
     },
     "be811a14629f472fa428606ae1ec3961": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ca848dc7e92942ada130fbf03c7447ab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d8f28bf9477c41c79e4ea430e9be45a6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f26508c2fada4d37aac254d7a5d1794d",
        "IPY_MODEL_9d644c7dd996420dbae384b19628b2b4",
        "IPY_MODEL_a466898ebbc74a6699a7275c9565b560"
       ],
       "layout": "IPY_MODEL_2024609be01444da9b7dc8ddc54a5505",
       "tabbable": null,
       "tooltip": null
      }
     },
     "efc85091903442e5b76c951e52e71045": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f26508c2fada4d37aac254d7a5d1794d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b35bee12c8bd4c3e8d50ca35ee1a367f",
       "placeholder": "​",
       "style": "IPY_MODEL_8ec8204249394cd8b0983ddf431a8414",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.json: "
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  },
  "description": "Why Formatting Matters (Really Matters)\n\nWith language models, they're just predicting the next token.",
  "thumbnail": "/intro.png"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}