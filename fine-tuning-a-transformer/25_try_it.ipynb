{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try It Yourself!\n",
    "\n",
    "**Hands-on tutorial: Train and evaluate your first fine-tuned model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to Hands-On Post-Training!\n",
    "\n",
    "This guide walks you through training your first fine-tuned language model. By the end, you'll have:\n",
    "\n",
    "- A GPT-2 model fine-tuned on instructions\n",
    "- Hands-on experience with SFT, evaluation, and generation\n",
    "- Understanding of how to apply these techniques to your own projects\n",
    "\n",
    "**Time required:** 30-60 minutes (depending on hardware)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "First, let's verify our environment and import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T23:30:34.151211Z",
     "iopub.status.busy": "2025-12-06T23:30:34.151112Z",
     "iopub.status.idle": "2025-12-06T23:30:34.845421Z",
     "shell.execute_reply": "2025-12-06T23:30:34.845095Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.10.0.dev20251124+rocm7.1\n",
      "CUDA available: True\n",
      "Device: Radeon RX 7900 XTX\n"
     ]
    }
   ],
   "source": [
    "# Check environment\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Device: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"Device: CPU (training will be slower)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T23:30:34.862073Z",
     "iopub.status.busy": "2025-12-06T23:30:34.861938Z",
     "iopub.status.idle": "2025-12-06T23:30:35.993881Z",
     "shell.execute_reply": "2025-12-06T23:30:35.993535Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, get_linear_schedule_with_warmup\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T23:30:35.994998Z",
     "iopub.status.busy": "2025-12-06T23:30:35.994871Z",
     "iopub.status.idle": "2025-12-06T23:30:36.958510Z",
     "shell.execute_reply": "2025-12-06T23:30:36.957963Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading gpt2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded!\n",
      "  Parameters: 124,439,808\n",
      "  Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Load GPT-2 (small, 124M parameters)\n",
    "model_name = \"gpt2\"\n",
    "\n",
    "print(f\"Loading {model_name}...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Set padding token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Move to device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model loaded!\")\n",
    "print(f\"  Parameters: {total_params:,}\")\n",
    "print(f\"  Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test Base Model (Before Fine-Tuning)\n",
    "\n",
    "Let's see how the base model handles instructions before we fine-tune it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T23:30:36.959499Z",
     "iopub.status.busy": "2025-12-06T23:30:36.959405Z",
     "iopub.status.idle": "2025-12-06T23:30:39.347078Z",
     "shell.execute_reply": "2025-12-06T23:30:39.346737Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model Responses (BEFORE fine-tuning):\n",
      "============================================================\n",
      "\n",
      "Instruction: What is the capital of France?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhubert/intro-to-transformers/.venv/lib/python3.12/site-packages/transformers/integrations/sdpa_attention.py:83: UserWarning: Flash Efficient attention on Current AMD GPU is still experimental. Enable it with TORCH_ROCM_AOTRITON_ENABLE_EXPERIMENTAL=1. (Triggered internally at /pytorch/aten/src/ATen/native/transformers/hip/sdp_utils.cpp:316.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "/home/zhubert/intro-to-transformers/.venv/lib/python3.12/site-packages/transformers/integrations/sdpa_attention.py:83: UserWarning: Mem Efficient attention on Current AMD GPU is still experimental. Enable it with TORCH_ROCM_AOTRITON_ENABLE_EXPERIMENTAL=1. (Triggered internally at /pytorch/aten/src/ATen/native/transformers/hip/sdp_utils.cpp:373.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: In the United States, capital letters are used for the capital letters, not the letters used for the letter \"a\".\n",
      "\n",
      "### Example:\n",
      "\n",
      "# Create an account with your friends. Username:\n",
      "\n",
      "Password:\n",
      "\n",
      "### User na...\n",
      "------------------------------------------------------------\n",
      "\n",
      "Instruction: Write a haiku about programming.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Write\n",
      "------------------------------------------------------------\n",
      "\n",
      "Instruction: Explain machine learning in one sentence.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: This is a simple example of a machine\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def generate_response(model, tokenizer, instruction, max_new_tokens=100):\n",
    "    \"\"\"Generate a response to an instruction.\"\"\"\n",
    "    # Format as Alpaca-style prompt\n",
    "    prompt = f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    full_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    response = full_text.split(\"### Response:\\n\")[-1].strip()\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Test base model\n",
    "test_instructions = [\n",
    "    \"What is the capital of France?\",\n",
    "    \"Write a haiku about programming.\",\n",
    "    \"Explain machine learning in one sentence.\",\n",
    "]\n",
    "\n",
    "print(\"Base Model Responses (BEFORE fine-tuning):\")\n",
    "print(\"=\" * 60)\n",
    "for instruction in test_instructions:\n",
    "    print(f\"\\nInstruction: {instruction}\")\n",
    "    response = generate_response(model, tokenizer, instruction)\n",
    "    print(f\"Response: {response[:200]}...\" if len(response) > 200 else f\"Response: {response}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the base model doesn't follow instructions well - it typically continues generating text in the same style rather than answering the question.\n",
    "\n",
    "## 4. Prepare Training Data\n",
    "\n",
    "We'll use the Alpaca dataset, which contains instruction-response pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T23:30:39.348201Z",
     "iopub.status.busy": "2025-12-06T23:30:39.348118Z",
     "iopub.status.idle": "2025-12-06T23:30:40.482092Z",
     "shell.execute_reply": "2025-12-06T23:30:40.481735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Alpaca dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 500 samples\n",
      "\n",
      "Example:\n",
      "  Instruction: Give three tips for staying healthy....\n",
      "  Input: (none)\n",
      "  Output: 1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and...\n"
     ]
    }
   ],
   "source": [
    "# Load Alpaca dataset\n",
    "print(\"Loading Alpaca dataset...\")\n",
    "raw_dataset = load_dataset(\"yahma/alpaca-cleaned\", split=\"train\")\n",
    "\n",
    "# Take a small subset for quick training\n",
    "num_samples = 500  # Adjust based on your time/hardware\n",
    "raw_dataset = raw_dataset.select(range(num_samples))\n",
    "\n",
    "print(f\"Dataset loaded: {len(raw_dataset)} samples\")\n",
    "print(f\"\\nExample:\")\n",
    "print(f\"  Instruction: {raw_dataset[0]['instruction'][:100]}...\")\n",
    "print(f\"  Input: {raw_dataset[0]['input'][:50]}...\" if raw_dataset[0]['input'] else \"  Input: (none)\")\n",
    "print(f\"  Output: {raw_dataset[0]['output'][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T23:30:40.482973Z",
     "iopub.status.busy": "2025-12-06T23:30:40.482887Z",
     "iopub.status.idle": "2025-12-06T23:30:40.486600Z",
     "shell.execute_reply": "2025-12-06T23:30:40.486323Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset with 500 samples\n",
      "Batches per epoch: 125\n"
     ]
    }
   ],
   "source": [
    "class InstructionDataset(Dataset):\n",
    "    \"\"\"Dataset for instruction fine-tuning with proper loss masking.\"\"\"\n",
    "    \n",
    "    def __init__(self, data, tokenizer, max_length=256):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def format_example(self, example):\n",
    "        \"\"\"Format example in Alpaca style.\"\"\"\n",
    "        if example['input']:\n",
    "            prompt = f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{example['instruction']}\n",
    "\n",
    "### Input:\n",
    "{example['input']}\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "        else:\n",
    "            prompt = f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{example['instruction']}\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "        return prompt, example['output']\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        example = self.data[idx]\n",
    "        prompt, response = self.format_example(example)\n",
    "        \n",
    "        # Tokenize prompt and response separately\n",
    "        prompt_tokens = self.tokenizer.encode(prompt, add_special_tokens=True)\n",
    "        response_tokens = self.tokenizer.encode(response, add_special_tokens=False)\n",
    "        \n",
    "        # Combine\n",
    "        input_ids = prompt_tokens + response_tokens + [self.tokenizer.eos_token_id]\n",
    "        \n",
    "        # Create labels: -100 for prompt tokens (ignored in loss)\n",
    "        labels = [-100] * len(prompt_tokens) + response_tokens + [self.tokenizer.eos_token_id]\n",
    "        \n",
    "        # Truncate if too long\n",
    "        if len(input_ids) > self.max_length:\n",
    "            input_ids = input_ids[:self.max_length]\n",
    "            labels = labels[:self.max_length]\n",
    "        \n",
    "        # Pad to max_length\n",
    "        padding_length = self.max_length - len(input_ids)\n",
    "        input_ids = input_ids + [self.tokenizer.pad_token_id] * padding_length\n",
    "        labels = labels + [-100] * padding_length  # Ignore padding in loss\n",
    "        attention_mask = [1] * (self.max_length - padding_length) + [0] * padding_length\n",
    "        \n",
    "        return {\n",
    "            'input_ids': torch.tensor(input_ids),\n",
    "            'attention_mask': torch.tensor(attention_mask),\n",
    "            'labels': torch.tensor(labels),\n",
    "        }\n",
    "\n",
    "# Create dataset and dataloader\n",
    "train_dataset = InstructionDataset(raw_dataset, tokenizer, max_length=256)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "print(f\"Created dataset with {len(train_dataset)} samples\")\n",
    "print(f\"Batches per epoch: {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Loop\n",
    "\n",
    "Now let's train the model on our instruction data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T23:30:40.487414Z",
     "iopub.status.busy": "2025-12-06T23:30:40.487335Z",
     "iopub.status.idle": "2025-12-06T23:30:40.489764Z",
     "shell.execute_reply": "2025-12-06T23:30:40.489467Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Configuration:\n",
      "  Learning rate: 5e-05\n",
      "  Epochs: 1\n",
      "  Total steps: 125\n",
      "  Warmup steps: 50\n"
     ]
    }
   ],
   "source": [
    "# Training configuration\n",
    "learning_rate = 5e-5\n",
    "num_epochs = 1\n",
    "warmup_steps = 50\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "# Setup optimizer and scheduler\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "total_steps = len(train_loader) * num_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "print(f\"Training Configuration:\")\n",
    "print(f\"  Learning rate: {learning_rate}\")\n",
    "print(f\"  Epochs: {num_epochs}\")\n",
    "print(f\"  Total steps: {total_steps}\")\n",
    "print(f\"  Warmup steps: {warmup_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T23:30:40.490463Z",
     "iopub.status.busy": "2025-12-06T23:30:40.490385Z",
     "iopub.status.idle": "2025-12-06T23:30:56.065228Z",
     "shell.execute_reply": "2025-12-06T23:30:56.064931Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:   0%|                                        | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:   0%| | 0/125 [00:00<?, ?it/s, loss=2.3985, avg_loss=2.3985, ppl=11.0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:   1%| | 1/125 [00:00<00:55,  2.23it/s, loss=2.3985, avg_loss=2.3985, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:   1%| | 1/125 [00:00<00:55,  2.23it/s, loss=2.7345, avg_loss=2.5665, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:   2%| | 2/125 [00:00<00:32,  3.82it/s, loss=2.7345, avg_loss=2.5665, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:   2%| | 2/125 [00:00<00:32,  3.82it/s, loss=2.7143, avg_loss=2.6158, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:   2%| | 3/125 [00:00<00:24,  5.02it/s, loss=2.7143, avg_loss=2.6158, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:   2%| | 3/125 [00:00<00:24,  5.02it/s, loss=2.8429, avg_loss=2.6725, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:   3%| | 4/125 [00:00<00:20,  5.93it/s, loss=2.8429, avg_loss=2.6725, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:   3%| | 4/125 [00:00<00:20,  5.93it/s, loss=3.1762, avg_loss=2.7733, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:   4%| | 5/125 [00:00<00:18,  6.60it/s, loss=3.1762, avg_loss=2.7733, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:   4%| | 5/125 [00:01<00:18,  6.60it/s, loss=2.6486, avg_loss=2.7525, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:   5%| | 6/125 [00:01<00:16,  7.05it/s, loss=2.6486, avg_loss=2.7525, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:   5%| | 6/125 [00:01<00:16,  7.05it/s, loss=3.0585, avg_loss=2.7962, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:   6%| | 7/125 [00:01<00:15,  7.40it/s, loss=3.0585, avg_loss=2.7962, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:   6%| | 7/125 [00:01<00:15,  7.40it/s, loss=2.3917, avg_loss=2.7457, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:   6%| | 8/125 [00:01<00:15,  7.64it/s, loss=2.3917, avg_loss=2.7457, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:   6%| | 8/125 [00:01<00:15,  7.64it/s, loss=3.1110, avg_loss=2.7863, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:   7%| | 9/125 [00:01<00:14,  7.84it/s, loss=3.1110, avg_loss=2.7863, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:   7%| | 9/125 [00:01<00:14,  7.84it/s, loss=2.8943, avg_loss=2.7971, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:   8%| | 10/125 [00:01<00:14,  7.98it/s, loss=2.8943, avg_loss=2.7971,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:   8%| | 10/125 [00:01<00:14,  7.98it/s, loss=2.9474, avg_loss=2.8107,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:   9%| | 11/125 [00:01<00:14,  8.08it/s, loss=2.9474, avg_loss=2.8107,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:   9%| | 11/125 [00:01<00:14,  8.08it/s, loss=2.7005, avg_loss=2.8015,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  10%| | 12/125 [00:01<00:13,  8.13it/s, loss=2.7005, avg_loss=2.8015,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  10%| | 12/125 [00:01<00:13,  8.13it/s, loss=2.4211, avg_loss=2.7723,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  10%| | 13/125 [00:01<00:13,  8.15it/s, loss=2.4211, avg_loss=2.7723,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  10%| | 13/125 [00:02<00:13,  8.15it/s, loss=2.5222, avg_loss=2.7544,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  11%| | 14/125 [00:02<00:13,  8.18it/s, loss=2.5222, avg_loss=2.7544,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  11%| | 14/125 [00:02<00:13,  8.18it/s, loss=2.5683, avg_loss=2.7420,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  12%| | 15/125 [00:02<00:13,  8.18it/s, loss=2.5683, avg_loss=2.7420,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  12%| | 15/125 [00:02<00:13,  8.18it/s, loss=2.8782, avg_loss=2.7505,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  13%|▏| 16/125 [00:02<00:13,  8.21it/s, loss=2.8782, avg_loss=2.7505,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  13%|▏| 16/125 [00:02<00:13,  8.21it/s, loss=2.8345, avg_loss=2.7555,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  14%|▏| 17/125 [00:02<00:13,  8.22it/s, loss=2.8345, avg_loss=2.7555,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  14%|▏| 17/125 [00:02<00:13,  8.22it/s, loss=2.7467, avg_loss=2.7550,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  14%|▏| 18/125 [00:02<00:13,  8.21it/s, loss=2.7467, avg_loss=2.7550,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  14%|▏| 18/125 [00:02<00:13,  8.21it/s, loss=2.8854, avg_loss=2.7618,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  15%|▏| 19/125 [00:02<00:12,  8.22it/s, loss=2.8854, avg_loss=2.7618,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  15%|▏| 19/125 [00:02<00:12,  8.22it/s, loss=2.4689, avg_loss=2.7472,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  16%|▏| 20/125 [00:02<00:12,  8.21it/s, loss=2.4689, avg_loss=2.7472,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  16%|▏| 20/125 [00:02<00:12,  8.21it/s, loss=2.7959, avg_loss=2.7495,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  17%|▏| 21/125 [00:02<00:12,  8.23it/s, loss=2.7959, avg_loss=2.7495,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  17%|▏| 21/125 [00:03<00:12,  8.23it/s, loss=2.6843, avg_loss=2.7465,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  18%|▏| 22/125 [00:03<00:12,  8.24it/s, loss=2.6843, avg_loss=2.7465,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  18%|▏| 22/125 [00:03<00:12,  8.24it/s, loss=2.0521, avg_loss=2.7164,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  18%|▏| 23/125 [00:03<00:12,  8.25it/s, loss=2.0521, avg_loss=2.7164,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  18%|▏| 23/125 [00:03<00:12,  8.25it/s, loss=2.0270, avg_loss=2.6876,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  19%|▏| 24/125 [00:03<00:12,  8.26it/s, loss=2.0270, avg_loss=2.6876,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  19%|▏| 24/125 [00:03<00:12,  8.26it/s, loss=2.9587, avg_loss=2.6985,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  20%|▏| 25/125 [00:03<00:12,  8.27it/s, loss=2.9587, avg_loss=2.6985,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  20%|▏| 25/125 [00:03<00:12,  8.27it/s, loss=2.2059, avg_loss=2.6795,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  21%|▏| 26/125 [00:03<00:12,  8.24it/s, loss=2.2059, avg_loss=2.6795,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  21%|▏| 26/125 [00:03<00:12,  8.24it/s, loss=2.3132, avg_loss=2.6660,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  22%|▏| 27/125 [00:03<00:11,  8.24it/s, loss=2.3132, avg_loss=2.6660,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  22%|▏| 27/125 [00:03<00:11,  8.24it/s, loss=2.5879, avg_loss=2.6632,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  22%|▏| 28/125 [00:03<00:11,  8.26it/s, loss=2.5879, avg_loss=2.6632,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  22%|▏| 28/125 [00:03<00:11,  8.26it/s, loss=2.0721, avg_loss=2.6428,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  23%|▏| 29/125 [00:03<00:11,  8.26it/s, loss=2.0721, avg_loss=2.6428,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  23%|▏| 29/125 [00:03<00:11,  8.26it/s, loss=2.4831, avg_loss=2.6375,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  24%|▏| 30/125 [00:03<00:11,  8.29it/s, loss=2.4831, avg_loss=2.6375,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  24%|▏| 30/125 [00:04<00:11,  8.29it/s, loss=2.3572, avg_loss=2.6284,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  25%|▏| 31/125 [00:04<00:11,  8.27it/s, loss=2.3572, avg_loss=2.6284,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  25%|▏| 31/125 [00:04<00:11,  8.27it/s, loss=2.0748, avg_loss=2.6111,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  26%|▎| 32/125 [00:04<00:11,  8.24it/s, loss=2.0748, avg_loss=2.6111,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  26%|▎| 32/125 [00:04<00:11,  8.24it/s, loss=2.3980, avg_loss=2.6047,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  26%|▎| 33/125 [00:04<00:11,  8.23it/s, loss=2.3980, avg_loss=2.6047,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  26%|▎| 33/125 [00:04<00:11,  8.23it/s, loss=2.3587, avg_loss=2.5974,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  27%|▎| 34/125 [00:04<00:11,  8.24it/s, loss=2.3587, avg_loss=2.5974,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  27%|▎| 34/125 [00:04<00:11,  8.24it/s, loss=1.9847, avg_loss=2.5799,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  28%|▎| 35/125 [00:04<00:10,  8.26it/s, loss=1.9847, avg_loss=2.5799,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  28%|▎| 35/125 [00:04<00:10,  8.26it/s, loss=3.0188, avg_loss=2.5921,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  29%|▎| 36/125 [00:04<00:10,  8.25it/s, loss=3.0188, avg_loss=2.5921,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  29%|▎| 36/125 [00:04<00:10,  8.25it/s, loss=2.5401, avg_loss=2.5907,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  30%|▎| 37/125 [00:04<00:10,  8.25it/s, loss=2.5401, avg_loss=2.5907,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  30%|▎| 37/125 [00:04<00:10,  8.25it/s, loss=2.7306, avg_loss=2.5944,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  30%|▎| 38/125 [00:04<00:10,  8.24it/s, loss=2.7306, avg_loss=2.5944,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  30%|▎| 38/125 [00:05<00:10,  8.24it/s, loss=2.1440, avg_loss=2.5828,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  31%|▎| 39/125 [00:05<00:10,  8.24it/s, loss=2.1440, avg_loss=2.5828,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  31%|▎| 39/125 [00:05<00:10,  8.24it/s, loss=2.2356, avg_loss=2.5742,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  32%|▎| 40/125 [00:05<00:10,  8.25it/s, loss=2.2356, avg_loss=2.5742,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  32%|▎| 40/125 [00:05<00:10,  8.25it/s, loss=2.0482, avg_loss=2.5613,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  33%|▎| 41/125 [00:05<00:10,  8.24it/s, loss=2.0482, avg_loss=2.5613,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  33%|▎| 41/125 [00:05<00:10,  8.24it/s, loss=1.9557, avg_loss=2.5469,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  34%|▎| 42/125 [00:05<00:10,  8.24it/s, loss=1.9557, avg_loss=2.5469,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  34%|▎| 42/125 [00:05<00:10,  8.24it/s, loss=2.3614, avg_loss=2.5426,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  34%|▎| 43/125 [00:05<00:09,  8.24it/s, loss=2.3614, avg_loss=2.5426,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  34%|▎| 43/125 [00:05<00:09,  8.24it/s, loss=2.3019, avg_loss=2.5371,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  35%|▎| 44/125 [00:05<00:09,  8.23it/s, loss=2.3019, avg_loss=2.5371,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  35%|▎| 44/125 [00:05<00:09,  8.23it/s, loss=2.3256, avg_loss=2.5324,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  36%|▎| 45/125 [00:05<00:09,  8.23it/s, loss=2.3256, avg_loss=2.5324,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  36%|▎| 45/125 [00:05<00:09,  8.23it/s, loss=2.4143, avg_loss=2.5299,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  37%|▎| 46/125 [00:05<00:09,  8.21it/s, loss=2.4143, avg_loss=2.5299,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  37%|▎| 46/125 [00:06<00:09,  8.21it/s, loss=2.2434, avg_loss=2.5238,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  38%|▍| 47/125 [00:06<00:09,  8.20it/s, loss=2.2434, avg_loss=2.5238,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  38%|▍| 47/125 [00:06<00:09,  8.20it/s, loss=2.3804, avg_loss=2.5208,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  38%|▍| 48/125 [00:06<00:09,  8.17it/s, loss=2.3804, avg_loss=2.5208,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  38%|▍| 48/125 [00:06<00:09,  8.17it/s, loss=2.0104, avg_loss=2.5104,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  39%|▍| 49/125 [00:06<00:09,  8.16it/s, loss=2.0104, avg_loss=2.5104,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  39%|▍| 49/125 [00:06<00:09,  8.16it/s, loss=2.4296, avg_loss=2.5087,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  40%|▍| 50/125 [00:06<00:09,  8.21it/s, loss=2.4296, avg_loss=2.5087,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  40%|▍| 50/125 [00:06<00:09,  8.21it/s, loss=2.3737, avg_loss=2.5061,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  41%|▍| 51/125 [00:06<00:08,  8.22it/s, loss=2.3737, avg_loss=2.5061,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  41%|▍| 51/125 [00:06<00:08,  8.22it/s, loss=2.3010, avg_loss=2.5022,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  42%|▍| 52/125 [00:06<00:08,  8.21it/s, loss=2.3010, avg_loss=2.5022,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  42%|▍| 52/125 [00:06<00:08,  8.21it/s, loss=2.2574, avg_loss=2.4975,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  42%|▍| 53/125 [00:06<00:08,  8.18it/s, loss=2.2574, avg_loss=2.4975,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  42%|▍| 53/125 [00:06<00:08,  8.18it/s, loss=2.0442, avg_loss=2.4891,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  43%|▍| 54/125 [00:06<00:08,  8.20it/s, loss=2.0442, avg_loss=2.4891,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  43%|▍| 54/125 [00:07<00:08,  8.20it/s, loss=2.5030, avg_loss=2.4894,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  44%|▍| 55/125 [00:07<00:08,  8.18it/s, loss=2.5030, avg_loss=2.4894,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  44%|▍| 55/125 [00:07<00:08,  8.18it/s, loss=2.3327, avg_loss=2.4866,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  45%|▍| 56/125 [00:07<00:08,  8.18it/s, loss=2.3327, avg_loss=2.4866,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  45%|▍| 56/125 [00:07<00:08,  8.18it/s, loss=2.0308, avg_loss=2.4786,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  46%|▍| 57/125 [00:07<00:08,  8.20it/s, loss=2.0308, avg_loss=2.4786,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  46%|▍| 57/125 [00:07<00:08,  8.20it/s, loss=2.1827, avg_loss=2.4735,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  46%|▍| 58/125 [00:07<00:08,  8.22it/s, loss=2.1827, avg_loss=2.4735,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  46%|▍| 58/125 [00:07<00:08,  8.22it/s, loss=2.2960, avg_loss=2.4705,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  47%|▍| 59/125 [00:07<00:08,  8.21it/s, loss=2.2960, avg_loss=2.4705,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  47%|▍| 59/125 [00:07<00:08,  8.21it/s, loss=2.1795, avg_loss=2.4656,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  48%|▍| 60/125 [00:07<00:07,  8.23it/s, loss=2.1795, avg_loss=2.4656,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  48%|▍| 60/125 [00:07<00:07,  8.23it/s, loss=2.4929, avg_loss=2.4661,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  49%|▍| 61/125 [00:07<00:07,  8.23it/s, loss=2.4929, avg_loss=2.4661,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  49%|▍| 61/125 [00:07<00:07,  8.23it/s, loss=2.0727, avg_loss=2.4597,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  50%|▍| 62/125 [00:07<00:07,  8.23it/s, loss=2.0727, avg_loss=2.4597,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  50%|▍| 62/125 [00:07<00:07,  8.23it/s, loss=2.7766, avg_loss=2.4648,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  50%|▌| 63/125 [00:07<00:07,  8.21it/s, loss=2.7766, avg_loss=2.4648,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  50%|▌| 63/125 [00:08<00:07,  8.21it/s, loss=2.2759, avg_loss=2.4618,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  51%|▌| 64/125 [00:08<00:07,  8.20it/s, loss=2.2759, avg_loss=2.4618,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  51%|▌| 64/125 [00:08<00:07,  8.20it/s, loss=2.1378, avg_loss=2.4568,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  52%|▌| 65/125 [00:08<00:07,  8.20it/s, loss=2.1378, avg_loss=2.4568,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  52%|▌| 65/125 [00:08<00:07,  8.20it/s, loss=2.3409, avg_loss=2.4551,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  53%|▌| 66/125 [00:08<00:07,  8.18it/s, loss=2.3409, avg_loss=2.4551,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  53%|▌| 66/125 [00:08<00:07,  8.18it/s, loss=2.2454, avg_loss=2.4519,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  54%|▌| 67/125 [00:08<00:07,  8.18it/s, loss=2.2454, avg_loss=2.4519,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  54%|▌| 67/125 [00:08<00:07,  8.18it/s, loss=2.2979, avg_loss=2.4497,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  54%|▌| 68/125 [00:08<00:06,  8.19it/s, loss=2.2979, avg_loss=2.4497,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  54%|▌| 68/125 [00:08<00:06,  8.19it/s, loss=1.9874, avg_loss=2.4430,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  55%|▌| 69/125 [00:08<00:06,  8.18it/s, loss=1.9874, avg_loss=2.4430,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  55%|▌| 69/125 [00:08<00:06,  8.18it/s, loss=2.2939, avg_loss=2.4408,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  56%|▌| 70/125 [00:08<00:06,  8.16it/s, loss=2.2939, avg_loss=2.4408,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  56%|▌| 70/125 [00:08<00:06,  8.16it/s, loss=2.5350, avg_loss=2.4422,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  57%|▌| 71/125 [00:08<00:06,  8.17it/s, loss=2.5350, avg_loss=2.4422,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  57%|▌| 71/125 [00:09<00:06,  8.17it/s, loss=2.3732, avg_loss=2.4412,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  58%|▌| 72/125 [00:09<00:06,  8.17it/s, loss=2.3732, avg_loss=2.4412,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  58%|▌| 72/125 [00:09<00:06,  8.17it/s, loss=2.1484, avg_loss=2.4372,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  58%|▌| 73/125 [00:09<00:06,  8.16it/s, loss=2.1484, avg_loss=2.4372,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  58%|▌| 73/125 [00:09<00:06,  8.16it/s, loss=2.2243, avg_loss=2.4343,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  59%|▌| 74/125 [00:09<00:06,  8.17it/s, loss=2.2243, avg_loss=2.4343,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  59%|▌| 74/125 [00:09<00:06,  8.17it/s, loss=2.2244, avg_loss=2.4315,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  60%|▌| 75/125 [00:09<00:06,  8.19it/s, loss=2.2244, avg_loss=2.4315,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  60%|▌| 75/125 [00:09<00:06,  8.19it/s, loss=3.1475, avg_loss=2.4409,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  61%|▌| 76/125 [00:09<00:05,  8.17it/s, loss=3.1475, avg_loss=2.4409,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  61%|▌| 76/125 [00:09<00:05,  8.17it/s, loss=2.4087, avg_loss=2.4405,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  62%|▌| 77/125 [00:09<00:05,  8.16it/s, loss=2.4087, avg_loss=2.4405,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  62%|▌| 77/125 [00:09<00:05,  8.16it/s, loss=2.1811, avg_loss=2.4372,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  62%|▌| 78/125 [00:09<00:05,  8.18it/s, loss=2.1811, avg_loss=2.4372,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  62%|▌| 78/125 [00:09<00:05,  8.18it/s, loss=2.4735, avg_loss=2.4377,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  63%|▋| 79/125 [00:09<00:05,  8.17it/s, loss=2.4735, avg_loss=2.4377,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  63%|▋| 79/125 [00:10<00:05,  8.17it/s, loss=2.0875, avg_loss=2.4333,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  64%|▋| 80/125 [00:10<00:05,  8.17it/s, loss=2.0875, avg_loss=2.4333,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  64%|▋| 80/125 [00:10<00:05,  8.17it/s, loss=2.1823, avg_loss=2.4302,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  65%|▋| 81/125 [00:10<00:05,  8.16it/s, loss=2.1823, avg_loss=2.4302,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  65%|▋| 81/125 [00:10<00:05,  8.16it/s, loss=2.8548, avg_loss=2.4354,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  66%|▋| 82/125 [00:10<00:05,  8.19it/s, loss=2.8548, avg_loss=2.4354,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  66%|▋| 82/125 [00:10<00:05,  8.19it/s, loss=2.1871, avg_loss=2.4324,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  66%|▋| 83/125 [00:10<00:05,  8.21it/s, loss=2.1871, avg_loss=2.4324,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  66%|▋| 83/125 [00:10<00:05,  8.21it/s, loss=2.3567, avg_loss=2.4315,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  67%|▋| 84/125 [00:10<00:04,  8.22it/s, loss=2.3567, avg_loss=2.4315,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  67%|▋| 84/125 [00:10<00:04,  8.22it/s, loss=2.1611, avg_loss=2.4283,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  68%|▋| 85/125 [00:10<00:04,  8.20it/s, loss=2.1611, avg_loss=2.4283,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  68%|▋| 85/125 [00:10<00:04,  8.20it/s, loss=2.0366, avg_loss=2.4237,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  69%|▋| 86/125 [00:10<00:04,  8.19it/s, loss=2.0366, avg_loss=2.4237,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  69%|▋| 86/125 [00:10<00:04,  8.19it/s, loss=2.0682, avg_loss=2.4197,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  70%|▋| 87/125 [00:10<00:04,  8.21it/s, loss=2.0682, avg_loss=2.4197,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  70%|▋| 87/125 [00:11<00:04,  8.21it/s, loss=2.2135, avg_loss=2.4173,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  70%|▋| 88/125 [00:11<00:04,  8.20it/s, loss=2.2135, avg_loss=2.4173,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  70%|▋| 88/125 [00:11<00:04,  8.20it/s, loss=2.3923, avg_loss=2.4170,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  71%|▋| 89/125 [00:11<00:04,  8.19it/s, loss=2.3923, avg_loss=2.4170,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  71%|▋| 89/125 [00:11<00:04,  8.19it/s, loss=2.0384, avg_loss=2.4128,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  72%|▋| 90/125 [00:11<00:04,  8.17it/s, loss=2.0384, avg_loss=2.4128,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  72%|▋| 90/125 [00:11<00:04,  8.17it/s, loss=2.2088, avg_loss=2.4106,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  73%|▋| 91/125 [00:11<00:04,  8.17it/s, loss=2.2088, avg_loss=2.4106,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  73%|▋| 91/125 [00:11<00:04,  8.17it/s, loss=1.9499, avg_loss=2.4056,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  74%|▋| 92/125 [00:11<00:04,  8.20it/s, loss=1.9499, avg_loss=2.4056,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  74%|▋| 92/125 [00:11<00:04,  8.20it/s, loss=2.4895, avg_loss=2.4065,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  74%|▋| 93/125 [00:11<00:03,  8.21it/s, loss=2.4895, avg_loss=2.4065,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  74%|▋| 93/125 [00:11<00:03,  8.21it/s, loss=1.7518, avg_loss=2.3995,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  75%|▊| 94/125 [00:11<00:03,  8.21it/s, loss=1.7518, avg_loss=2.3995,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  75%|▊| 94/125 [00:11<00:03,  8.21it/s, loss=2.4465, avg_loss=2.4000,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  76%|▊| 95/125 [00:11<00:03,  8.21it/s, loss=2.4465, avg_loss=2.4000,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  76%|▊| 95/125 [00:12<00:03,  8.21it/s, loss=2.2454, avg_loss=2.3984,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  77%|▊| 96/125 [00:12<00:03,  8.17it/s, loss=2.2454, avg_loss=2.3984,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  77%|▊| 96/125 [00:12<00:03,  8.17it/s, loss=2.4852, avg_loss=2.3993,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  78%|▊| 97/125 [00:12<00:03,  8.19it/s, loss=2.4852, avg_loss=2.3993,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  78%|▊| 97/125 [00:12<00:03,  8.19it/s, loss=2.4324, avg_loss=2.3996,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  78%|▊| 98/125 [00:12<00:03,  8.19it/s, loss=2.4324, avg_loss=2.3996,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  78%|▊| 98/125 [00:12<00:03,  8.19it/s, loss=2.4135, avg_loss=2.3998,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  79%|▊| 99/125 [00:12<00:03,  8.19it/s, loss=2.4135, avg_loss=2.3998,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  79%|▊| 99/125 [00:12<00:03,  8.19it/s, loss=1.6407, avg_loss=2.3922,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  80%|▊| 100/125 [00:12<00:03,  8.20it/s, loss=1.6407, avg_loss=2.3922"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  80%|▊| 100/125 [00:12<00:03,  8.20it/s, loss=2.4422, avg_loss=2.3927"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  81%|▊| 101/125 [00:12<00:02,  8.19it/s, loss=2.4422, avg_loss=2.3927"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  81%|▊| 101/125 [00:12<00:02,  8.19it/s, loss=2.2939, avg_loss=2.3917"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  82%|▊| 102/125 [00:12<00:02,  8.16it/s, loss=2.2939, avg_loss=2.3917"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  82%|▊| 102/125 [00:12<00:02,  8.16it/s, loss=2.6973, avg_loss=2.3947"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  82%|▊| 103/125 [00:12<00:02,  8.18it/s, loss=2.6973, avg_loss=2.3947"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  82%|▊| 103/125 [00:13<00:02,  8.18it/s, loss=2.2541, avg_loss=2.3933"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  83%|▊| 104/125 [00:13<00:02,  8.18it/s, loss=2.2541, avg_loss=2.3933"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  83%|▊| 104/125 [00:13<00:02,  8.18it/s, loss=2.0260, avg_loss=2.3898"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  84%|▊| 105/125 [00:13<00:02,  8.16it/s, loss=2.0260, avg_loss=2.3898"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  84%|▊| 105/125 [00:13<00:02,  8.16it/s, loss=2.7181, avg_loss=2.3929"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  85%|▊| 106/125 [00:13<00:02,  8.16it/s, loss=2.7181, avg_loss=2.3929"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  85%|▊| 106/125 [00:13<00:02,  8.16it/s, loss=2.2880, avg_loss=2.3919"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  86%|▊| 107/125 [00:13<00:02,  8.17it/s, loss=2.2880, avg_loss=2.3919"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  86%|▊| 107/125 [00:13<00:02,  8.17it/s, loss=2.2241, avg_loss=2.3904"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  86%|▊| 108/125 [00:13<00:02,  8.14it/s, loss=2.2241, avg_loss=2.3904"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  86%|▊| 108/125 [00:13<00:02,  8.14it/s, loss=2.0203, avg_loss=2.3870"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  87%|▊| 109/125 [00:13<00:01,  8.16it/s, loss=2.0203, avg_loss=2.3870"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  87%|▊| 109/125 [00:13<00:01,  8.16it/s, loss=2.2155, avg_loss=2.3854"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  88%|▉| 110/125 [00:13<00:01,  8.16it/s, loss=2.2155, avg_loss=2.3854"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  88%|▉| 110/125 [00:13<00:01,  8.16it/s, loss=2.4701, avg_loss=2.3862"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  89%|▉| 111/125 [00:13<00:01,  8.16it/s, loss=2.4701, avg_loss=2.3862"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  89%|▉| 111/125 [00:13<00:01,  8.16it/s, loss=2.2710, avg_loss=2.3852"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  90%|▉| 112/125 [00:13<00:01,  8.19it/s, loss=2.2710, avg_loss=2.3852"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  90%|▉| 112/125 [00:14<00:01,  8.19it/s, loss=3.2329, avg_loss=2.3927"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  90%|▉| 113/125 [00:14<00:01,  8.19it/s, loss=3.2329, avg_loss=2.3927"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  90%|▉| 113/125 [00:14<00:01,  8.19it/s, loss=1.9879, avg_loss=2.3891"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  91%|▉| 114/125 [00:14<00:01,  8.20it/s, loss=1.9879, avg_loss=2.3891"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  91%|▉| 114/125 [00:14<00:01,  8.20it/s, loss=2.2203, avg_loss=2.3876"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  92%|▉| 115/125 [00:14<00:01,  8.20it/s, loss=2.2203, avg_loss=2.3876"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  92%|▉| 115/125 [00:14<00:01,  8.20it/s, loss=2.4546, avg_loss=2.3882"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  93%|▉| 116/125 [00:14<00:01,  8.17it/s, loss=2.4546, avg_loss=2.3882"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  93%|▉| 116/125 [00:14<00:01,  8.17it/s, loss=2.0408, avg_loss=2.3853"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  94%|▉| 117/125 [00:14<00:00,  8.20it/s, loss=2.0408, avg_loss=2.3853"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  94%|▉| 117/125 [00:14<00:00,  8.20it/s, loss=2.1342, avg_loss=2.3831"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  94%|▉| 118/125 [00:14<00:00,  8.20it/s, loss=2.1342, avg_loss=2.3831"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  94%|▉| 118/125 [00:14<00:00,  8.20it/s, loss=1.9298, avg_loss=2.3793"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  95%|▉| 119/125 [00:14<00:00,  8.21it/s, loss=1.9298, avg_loss=2.3793"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  95%|▉| 119/125 [00:14<00:00,  8.21it/s, loss=2.2835, avg_loss=2.3785"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  96%|▉| 120/125 [00:14<00:00,  8.19it/s, loss=2.2835, avg_loss=2.3785"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  96%|▉| 120/125 [00:15<00:00,  8.19it/s, loss=2.4558, avg_loss=2.3792"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  97%|▉| 121/125 [00:15<00:00,  8.19it/s, loss=2.4558, avg_loss=2.3792"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  97%|▉| 121/125 [00:15<00:00,  8.19it/s, loss=2.4489, avg_loss=2.3797"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  98%|▉| 122/125 [00:15<00:00,  8.19it/s, loss=2.4489, avg_loss=2.3797"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  98%|▉| 122/125 [00:15<00:00,  8.19it/s, loss=2.4519, avg_loss=2.3803"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  98%|▉| 123/125 [00:15<00:00,  8.19it/s, loss=2.4519, avg_loss=2.3803"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  98%|▉| 123/125 [00:15<00:00,  8.19it/s, loss=1.8992, avg_loss=2.3764"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  99%|▉| 124/125 [00:15<00:00,  8.19it/s, loss=1.8992, avg_loss=2.3764"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1:  99%|▉| 124/125 [00:15<00:00,  8.19it/s, loss=2.3073, avg_loss=2.3759"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1: 100%|█| 125/125 [00:15<00:00,  8.20it/s, loss=2.3073, avg_loss=2.3759"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1/1: 100%|█| 125/125 [00:15<00:00,  8.03it/s, loss=2.3073, avg_loss=2.3759"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 complete!\n",
      "  Average loss: 2.3759\n",
      "  Perplexity: 10.76\n",
      "\n",
      "Training complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "print(\"\\nStarting training...\")\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    for step, batch in enumerate(progress_bar):\n",
    "        # Move batch to device\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(\n",
    "            input_ids=batch['input_ids'],\n",
    "            attention_mask=batch['attention_mask'],\n",
    "            labels=batch['labels']\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        \n",
    "        # Optimizer step\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Track loss\n",
    "        total_loss += loss.item()\n",
    "        avg_loss = total_loss / (step + 1)\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'avg_loss': f'{avg_loss:.4f}',\n",
    "            'ppl': f'{np.exp(avg_loss):.2f}'\n",
    "        })\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch+1} complete!\")\n",
    "    print(f\"  Average loss: {avg_loss:.4f}\")\n",
    "    print(f\"  Perplexity: {np.exp(avg_loss):.2f}\")\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test Fine-Tuned Model\n",
    "\n",
    "Now let's see how the model performs after fine-tuning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T23:30:56.066347Z",
     "iopub.status.busy": "2025-12-06T23:30:56.066252Z",
     "iopub.status.idle": "2025-12-06T23:30:57.091718Z",
     "shell.execute_reply": "2025-12-06T23:30:57.091403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuned Model Responses (AFTER fine-tuning):\n",
      "============================================================\n",
      "\n",
      "Instruction: What is the capital of France?\n",
      "Response: France is the capital of France, with its capital being Paris.\n",
      "------------------------------------------------------------\n",
      "\n",
      "Instruction: Write a haiku about programming.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The haiku describes a task that is one that is a combination of the three basic types of language.\n",
      "\n",
      "First, the verb \"hōshi\" refers to the verb \"to write\" and \"to make\", while the verb \"hōshirō\" refers to the verb \"to write\". The verb \"hōshirō\" is also used to refer to \"to write\" and \"to make\", while the verb \"hōshirō\" is used to\n",
      "------------------------------------------------------------\n",
      "\n",
      "Instruction: Explain machine learning in one sentence.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Machine learning is a powerful tool that enables computers to understand and predict human behavior and behaviors. In this paper, we present machine learning algorithms that can generate predictions about the future behavior of human beings. The algorithms are built on real-time data, and are used to predict the future behavior of humans, such as how quickly they will move, how long they will be able to run, and how they will perform in a given situation. Machine learning algorithms are widely used in machine learning applications, including machine\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Set model to eval mode\n",
    "model.eval()\n",
    "\n",
    "print(\"Fine-Tuned Model Responses (AFTER fine-tuning):\")\n",
    "print(\"=\" * 60)\n",
    "for instruction in test_instructions:\n",
    "    print(f\"\\nInstruction: {instruction}\")\n",
    "    response = generate_response(model, tokenizer, instruction)\n",
    "    print(f\"Response: {response}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T23:30:57.092609Z",
     "iopub.status.busy": "2025-12-06T23:30:57.092538Z",
     "iopub.status.idle": "2025-12-06T23:30:58.703088Z",
     "shell.execute_reply": "2025-12-06T23:30:58.702744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Tests:\n",
      "============================================================\n",
      "\n",
      "Instruction: List three benefits of exercise.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: 1. Exercise increases energy expenditure, reduces fatigue, and improves health.\n",
      "\n",
      "2. Exercise increases brain function, reduces depression, and improves mental well-being.\n",
      "\n",
      "3. Exercise increases physical activity, reduces stress, and improves mental health.\n",
      "\n",
      "4. Exercise increases cognitive function, reduces anxiety, and improves cognitive function.\n",
      "\n",
      "5. Exercise increases physical activity, improves sleep, and improves physical performance.\n",
      "\n",
      "6. Exercise increases physical activity, improves sleep, and improves physical performance\n",
      "------------------------------------------------------------\n",
      "\n",
      "Instruction: What is Python used for?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Python is a powerful and versatile language that can be used for many purposes, from scripting, to visual editing, to building applications, to creating custom applications. Python is also widely used for building web applications, and is a powerful language for building web applications in various browsers, including Chrome, Firefox, and Safari.\n",
      "\n",
      "There are many uses for Python, including:\n",
      "\n",
      "Documentation\n",
      "\n",
      "Automation\n",
      "\n",
      "Automation can be a powerful tool in a complex and complex world. Python is a\n",
      "------------------------------------------------------------\n",
      "\n",
      "Instruction: Explain what a neural network is in simple terms.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: A neural network is a type of computer system that learns about the world through data, information, and models. It is a network of interconnected computers that is responsible for processing, analyzing, and interpreting data. It is the backbone of computer science and engineering, and is used to develop algorithms and algorithms to solve problems. Neural networks are thought to be a key part of the computer science and engineering field, and have been used in many fields including robotics, artificial intelligence, and artificial intelligence.\n",
      "\n",
      "The\n",
      "------------------------------------------------------------\n",
      "\n",
      "Instruction: Write a short poem about the ocean.\n",
      "Response: The ocean is an important and beautiful place to visit, but it is not always a safe place. For that reason, it is important to understand the importance of staying in the ocean.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test with more instructions\n",
    "additional_tests = [\n",
    "    \"List three benefits of exercise.\",\n",
    "    \"What is Python used for?\",\n",
    "    \"Explain what a neural network is in simple terms.\",\n",
    "    \"Write a short poem about the ocean.\",\n",
    "]\n",
    "\n",
    "print(\"Additional Tests:\")\n",
    "print(\"=\" * 60)\n",
    "for instruction in additional_tests:\n",
    "    print(f\"\\nInstruction: {instruction}\")\n",
    "    response = generate_response(model, tokenizer, instruction)\n",
    "    print(f\"Response: {response}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate Model Quality\n",
    "\n",
    "Let's compute some quantitative metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T23:30:58.703977Z",
     "iopub.status.busy": "2025-12-06T23:30:58.703905Z",
     "iopub.status.idle": "2025-12-06T23:31:07.304954Z",
     "shell.execute_reply": "2025-12-06T23:31:07.304654Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:   0%|                             | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:   2%|▎                    | 2/125 [00:00<00:08, 14.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:   3%|▋                    | 4/125 [00:00<00:08, 14.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:   5%|█                    | 6/125 [00:00<00:08, 14.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:   6%|█▎                   | 8/125 [00:00<00:08, 14.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:   8%|█▌                  | 10/125 [00:00<00:07, 14.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  10%|█▉                  | 12/125 [00:00<00:07, 14.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  11%|██▏                 | 14/125 [00:00<00:07, 14.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  13%|██▌                 | 16/125 [00:01<00:07, 14.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  14%|██▉                 | 18/125 [00:01<00:07, 14.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  16%|███▏                | 20/125 [00:01<00:07, 14.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  18%|███▌                | 22/125 [00:01<00:07, 14.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  19%|███▊                | 24/125 [00:01<00:06, 14.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  21%|████▏               | 26/125 [00:01<00:06, 14.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  22%|████▍               | 28/125 [00:01<00:06, 14.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  24%|████▊               | 30/125 [00:02<00:06, 14.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  26%|█████               | 32/125 [00:02<00:06, 14.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  27%|█████▍              | 34/125 [00:02<00:06, 14.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  29%|█████▊              | 36/125 [00:02<00:06, 14.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  30%|██████              | 38/125 [00:02<00:05, 14.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  32%|██████▍             | 40/125 [00:02<00:05, 14.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  34%|██████▋             | 42/125 [00:02<00:05, 14.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  35%|███████             | 44/125 [00:03<00:05, 14.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  37%|███████▎            | 46/125 [00:03<00:05, 14.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  38%|███████▋            | 48/125 [00:03<00:05, 14.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  40%|████████            | 50/125 [00:03<00:05, 14.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  42%|████████▎           | 52/125 [00:03<00:05, 14.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  43%|████████▋           | 54/125 [00:03<00:04, 14.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  45%|████████▉           | 56/125 [00:03<00:04, 14.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  46%|█████████▎          | 58/125 [00:03<00:04, 14.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  48%|█████████▌          | 60/125 [00:04<00:04, 14.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  50%|█████████▉          | 62/125 [00:04<00:04, 14.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  51%|██████████▏         | 64/125 [00:04<00:04, 14.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  53%|██████████▌         | 66/125 [00:04<00:04, 14.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  54%|██████████▉         | 68/125 [00:04<00:03, 14.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  56%|███████████▏        | 70/125 [00:04<00:03, 14.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  58%|███████████▌        | 72/125 [00:04<00:03, 14.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  59%|███████████▊        | 74/125 [00:05<00:03, 14.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  61%|████████████▏       | 76/125 [00:05<00:03, 14.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  62%|████████████▍       | 78/125 [00:05<00:03, 14.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  64%|████████████▊       | 80/125 [00:05<00:03, 14.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  66%|█████████████       | 82/125 [00:05<00:02, 14.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  67%|█████████████▍      | 84/125 [00:05<00:02, 14.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  69%|█████████████▊      | 86/125 [00:05<00:02, 14.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  70%|██████████████      | 88/125 [00:06<00:02, 14.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  72%|██████████████▍     | 90/125 [00:06<00:02, 14.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  74%|██████████████▋     | 92/125 [00:06<00:02, 14.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  75%|███████████████     | 94/125 [00:06<00:02, 14.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  77%|███████████████▎    | 96/125 [00:06<00:01, 14.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  78%|███████████████▋    | 98/125 [00:06<00:01, 14.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  80%|███████████████▏   | 100/125 [00:06<00:01, 14.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  82%|███████████████▌   | 102/125 [00:07<00:01, 14.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  83%|███████████████▊   | 104/125 [00:07<00:01, 14.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  85%|████████████████   | 106/125 [00:07<00:01, 14.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  86%|████████████████▍  | 108/125 [00:07<00:01, 14.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  88%|████████████████▋  | 110/125 [00:07<00:01, 14.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  90%|█████████████████  | 112/125 [00:07<00:00, 14.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  91%|█████████████████▎ | 114/125 [00:07<00:00, 14.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  93%|█████████████████▋ | 116/125 [00:07<00:00, 14.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  94%|█████████████████▉ | 118/125 [00:08<00:00, 14.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  96%|██████████████████▏| 120/125 [00:08<00:00, 14.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  98%|██████████████████▌| 122/125 [00:08<00:00, 14.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity:  99%|██████████████████▊| 124/125 [00:08<00:00, 14.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing perplexity: 100%|███████████████████| 125/125 [00:08<00:00, 14.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Metrics:\n",
      "  Loss: 1.9576\n",
      "  Perplexity: 7.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def compute_perplexity(model, dataloader, device):\n",
    "    \"\"\"Compute perplexity on a dataset.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_tokens = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Computing perplexity\"):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids=batch['input_ids'],\n",
    "                attention_mask=batch['attention_mask'],\n",
    "                labels=batch['labels']\n",
    "            )\n",
    "            \n",
    "            # Count non-masked tokens\n",
    "            num_tokens = (batch['labels'] != -100).sum().item()\n",
    "            total_loss += outputs.loss.item() * num_tokens\n",
    "            total_tokens += num_tokens\n",
    "    \n",
    "    avg_loss = total_loss / total_tokens\n",
    "    perplexity = np.exp(avg_loss)\n",
    "    \n",
    "    return perplexity, avg_loss\n",
    "\n",
    "# Compute perplexity\n",
    "perplexity, loss = compute_perplexity(model, train_loader, device)\n",
    "print(f\"\\nFinal Metrics:\")\n",
    "print(f\"  Loss: {loss:.4f}\")\n",
    "print(f\"  Perplexity: {perplexity:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T23:31:07.305873Z",
     "iopub.status.busy": "2025-12-06T23:31:07.305791Z",
     "iopub.status.idle": "2025-12-06T23:31:09.501779Z",
     "shell.execute_reply": "2025-12-06T23:31:09.501416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Diversity Metrics:\n",
      "  Distinct-1 (unique unigrams): 39.40%\n",
      "  Distinct-2 (unique bigrams): 76.77%\n",
      "\n",
      "Interpretation:\n",
      "  > 0.4 distinct-1: Good diversity\n",
      "  < 0.2 distinct-1: May indicate mode collapse\n"
     ]
    }
   ],
   "source": [
    "def compute_diversity(responses):\n",
    "    \"\"\"Compute diversity metrics for generated responses.\"\"\"\n",
    "    all_unigrams = []\n",
    "    all_bigrams = []\n",
    "    \n",
    "    for response in responses:\n",
    "        tokens = response.lower().split()\n",
    "        all_unigrams.extend(tokens)\n",
    "        all_bigrams.extend(zip(tokens[:-1], tokens[1:]))\n",
    "    \n",
    "    distinct_1 = len(set(all_unigrams)) / len(all_unigrams) if all_unigrams else 0\n",
    "    distinct_2 = len(set(all_bigrams)) / len(all_bigrams) if all_bigrams else 0\n",
    "    \n",
    "    return distinct_1, distinct_2\n",
    "\n",
    "# Generate responses for diversity analysis\n",
    "diversity_prompts = [\n",
    "    \"Tell me about machine learning.\",\n",
    "    \"Explain artificial intelligence.\",\n",
    "    \"What is deep learning?\",\n",
    "    \"Describe natural language processing.\",\n",
    "    \"Explain what data science is.\",\n",
    "]\n",
    "\n",
    "responses = [generate_response(model, tokenizer, p) for p in diversity_prompts]\n",
    "d1, d2 = compute_diversity(responses)\n",
    "\n",
    "print(f\"\\nDiversity Metrics:\")\n",
    "print(f\"  Distinct-1 (unique unigrams): {d1:.2%}\")\n",
    "print(f\"  Distinct-2 (unique bigrams): {d2:.2%}\")\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"  > 0.4 distinct-1: Good diversity\")\n",
    "print(f\"  < 0.2 distinct-1: May indicate mode collapse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Your Model\n",
    "\n",
    "Save the fine-tuned model for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T23:31:09.502742Z",
     "iopub.status.busy": "2025-12-06T23:31:09.502669Z",
     "iopub.status.idle": "2025-12-06T23:31:10.053384Z",
     "shell.execute_reply": "2025-12-06T23:31:10.052990Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to ./my_finetuned_model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n",
      "\n",
      "Saved files:\n",
      "  tokenizer_config.json: 0.0 MB\n",
      "  config.json: 0.0 MB\n",
      "  tokenizer.json: 3.6 MB\n",
      "  merges.txt: 0.5 MB\n",
      "  special_tokens_map.json: 0.0 MB\n",
      "  generation_config.json: 0.0 MB\n",
      "  vocab.json: 0.8 MB\n",
      "  model.safetensors: 497.8 MB\n"
     ]
    }
   ],
   "source": [
    "# Save model and tokenizer\n",
    "save_path = \"./my_finetuned_model\"\n",
    "\n",
    "print(f\"Saving model to {save_path}...\")\n",
    "model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n",
    "print(\"Model saved!\")\n",
    "\n",
    "# Show saved files\n",
    "import os\n",
    "print(f\"\\nSaved files:\")\n",
    "for f in os.listdir(save_path):\n",
    "    size = os.path.getsize(os.path.join(save_path, f)) / 1e6\n",
    "    print(f\"  {f}: {size:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T23:31:10.054307Z",
     "iopub.status.busy": "2025-12-06T23:31:10.054206Z",
     "iopub.status.idle": "2025-12-06T23:31:10.482185Z",
     "shell.execute_reply": "2025-12-06T23:31:10.481658Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model loading...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test with loaded model:\n",
      "Instruction: What is the meaning of life?\n",
      "Response: Life is a journey of discovery, transformation, and renewal. It is a journey that is both deeply rewarding and rewarding.\n"
     ]
    }
   ],
   "source": [
    "# Test loading the saved model\n",
    "print(\"Testing model loading...\")\n",
    "\n",
    "loaded_model = AutoModelForCausalLM.from_pretrained(save_path)\n",
    "loaded_tokenizer = AutoTokenizer.from_pretrained(save_path)\n",
    "loaded_model = loaded_model.to(device)\n",
    "loaded_model.eval()\n",
    "\n",
    "test_instruction = \"What is the meaning of life?\"\n",
    "response = generate_response(loaded_model, loaded_tokenizer, test_instruction)\n",
    "\n",
    "print(f\"\\nTest with loaded model:\")\n",
    "print(f\"Instruction: {test_instruction}\")\n",
    "print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Congratulations! You've successfully:\n",
    "\n",
    "1. **Loaded** a pre-trained GPT-2 model\n",
    "2. **Tested** the base model on instructions (and saw it doesn't follow them well)\n",
    "3. **Prepared** training data with proper loss masking\n",
    "4. **Trained** the model using supervised fine-tuning (SFT)\n",
    "5. **Tested** the fine-tuned model (and saw significant improvement!)\n",
    "6. **Evaluated** using perplexity and diversity metrics\n",
    "7. **Saved** the model for later use\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Now that you've mastered the basics, try:\n",
    "\n",
    "1. **Train longer** - Increase epochs or use more data\n",
    "2. **Try LoRA** - More efficient training with fewer parameters\n",
    "3. **Try DPO** - Align model with human preferences\n",
    "4. **Use larger models** - Try GPT-2 Medium or Llama\n",
    "5. **Custom data** - Fine-tune on your own instruction dataset\n",
    "\n",
    "Happy fine-tuning!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
