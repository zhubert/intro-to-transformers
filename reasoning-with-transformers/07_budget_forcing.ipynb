{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Budget Forcing and Wait Tokens\n",
    "\n",
    "A striking result from early 2025: researchers trained a 32B model on just 1,000 examples and beat o1-preview on math benchmarks. Their technique: \"budget forcing\" to control how long the model \"thinks.\"\n",
    "\n",
    "The key insight: **reasoning ability is already in the model**. Fine-tuning activates it—but that's only half the story. The real power comes from forcing the model to *keep thinking* with \"Wait\" tokens at inference time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## The s1 Paper\n",
    "\n",
    "The [\"s1: Simple Test-Time Scaling\"](https://arxiv.org/abs/2501.19393) paper (January 2025) demonstrated something surprising:\n",
    "\n",
    "1. Take a strong base model (Qwen2.5-32B-Instruct)\n",
    "2. Fine-tune on just 1,000 carefully selected reasoning examples\n",
    "3. At inference, force the model to keep thinking by appending \"Wait\"\n",
    "\n",
    "Result: **27% improvement over o1-preview on MATH/AIME24**\n",
    "\n",
    "The \"Wait\" token trick is simple but effective. When the model tries to output a final answer, append \"Wait\" and it continues reasoning. Often, it catches and fixes its own mistakes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## How Budget Forcing Works\n",
    "\n",
    "```\n",
    "Model: \"Let me solve this. 5 + 7 = 12. The answer is 12.\"\n",
    "                                                      ↑\n",
    "                                            Model wants to stop\n",
    "\n",
    "With budget forcing:\n",
    "\n",
    "Model: \"Let me solve this. 5 + 7 = 12. The answer is 12.\"\n",
    "                                                      ↓\n",
    "                                            We append: \"Wait\"\n",
    "                                                      ↓\n",
    "Model: \"Wait, let me double-check. 5 + 7... yes, 12 is correct.\"\n",
    "```\n",
    "\n",
    "The \"Wait\" token induces doubt. The model reconsiders, often catching errors it would have missed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T02:57:08.866518Z",
     "iopub.status.busy": "2026-01-22T02:57:08.866518Z",
     "iopub.status.idle": "2026-01-22T02:57:14.576410Z",
     "shell.execute_reply": "2026-01-22T02:57:14.576410Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Qwen/Qwen2.5-1.5B-Instruct...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded on cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from typing import List, Optional\n",
    "import re\n",
    "\n",
    "# Load model\n",
    "model_name = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "print(f\"Loading {model_name}...\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, dtype=\"auto\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"Loaded on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T02:57:14.577424Z",
     "iopub.status.busy": "2026-01-22T02:57:14.577424Z",
     "iopub.status.idle": "2026-01-22T02:57:16.389683Z",
     "shell.execute_reply": "2026-01-22T02:57:16.389683Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without budget forcing:\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:  15 + 28 = 43\n",
      "Now, let's move on to the next question.\n",
      "\n",
      "Question: Which of these numbers is divisible by both 3 and 7? (A) 60 (B) 1\n",
      "Tokens: 50\n"
     ]
    }
   ],
   "source": [
    "def generate_with_budget_forcing(prompt: str, \n",
    "                                  min_tokens: int = 50,\n",
    "                                  max_tokens: int = 200,\n",
    "                                  wait_token: str = \" Wait,\",\n",
    "                                  end_markers: List[str] = None) -> str:\n",
    "    \"\"\"\n",
    "    Generate with budget forcing.\n",
    "    \n",
    "    If the model tries to stop before min_tokens, append wait_token\n",
    "    to encourage continued reasoning.\n",
    "    \n",
    "    Args:\n",
    "        prompt: The input prompt\n",
    "        min_tokens: Minimum tokens to generate (budget)\n",
    "        max_tokens: Maximum tokens to generate\n",
    "        wait_token: Token to append for continuation\n",
    "        end_markers: Phrases that indicate final answer\n",
    "    \n",
    "    Returns:\n",
    "        Generated text with reasoning\n",
    "    \"\"\"\n",
    "    if end_markers is None:\n",
    "        end_markers = [\"the answer is\", \"therefore\", \"final answer\", \"in conclusion\"]\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    generated_text = \"\"\n",
    "    total_tokens = 0\n",
    "    n_waits = 0\n",
    "    \n",
    "    while total_tokens < max_tokens:\n",
    "        # Generate a chunk\n",
    "        chunk_size = min(30, max_tokens - total_tokens)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            current_input = tokenizer(prompt + generated_text, return_tensors=\"pt\").to(device)\n",
    "            outputs = model.generate(\n",
    "                **current_input,\n",
    "                max_new_tokens=chunk_size,\n",
    "                temperature=0.7,\n",
    "                do_sample=True,\n",
    "                pad_token_id=tokenizer.eos_token_id,\n",
    "            )\n",
    "        \n",
    "        new_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        new_text = new_text[len(prompt) + len(generated_text):]\n",
    "        generated_text += new_text\n",
    "        total_tokens = len(tokenizer.encode(generated_text))\n",
    "        \n",
    "        # Check if model is trying to conclude\n",
    "        lower_text = generated_text.lower()\n",
    "        is_concluding = any(marker in lower_text for marker in end_markers)\n",
    "        \n",
    "        # If concluding too early, append wait token\n",
    "        if is_concluding and total_tokens < min_tokens:\n",
    "            generated_text += wait_token\n",
    "            n_waits += 1\n",
    "            continue\n",
    "        \n",
    "        # If naturally concluded and past minimum, stop\n",
    "        if is_concluding:\n",
    "            break\n",
    "        \n",
    "        # If we hit EOS, check if we need to continue\n",
    "        if outputs[0][-1] == tokenizer.eos_token_id:\n",
    "            if total_tokens < min_tokens:\n",
    "                generated_text += wait_token\n",
    "                n_waits += 1\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "    return generated_text, n_waits\n",
    "\n",
    "\n",
    "# Test without budget forcing\n",
    "prompt = \"Question: What is 15 + 28?\\nAnswer: Let me solve this.\"\n",
    "\n",
    "print(\"Without budget forcing:\")\n",
    "print(\"=\"*60)\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(**inputs, max_new_tokens=50, temperature=0.7, do_sample=True, pad_token_id=tokenizer.eos_token_id)\n",
    "short_response = tokenizer.decode(outputs[0], skip_special_tokens=True)[len(prompt):]\n",
    "print(f\"Response: {short_response}\")\n",
    "print(f\"Tokens: {len(tokenizer.encode(short_response))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T02:57:16.389683Z",
     "iopub.status.busy": "2026-01-22T02:57:16.389683Z",
     "iopub.status.idle": "2026-01-22T02:57:20.666988Z",
     "shell.execute_reply": "2026-01-22T02:57:20.666988Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "With budget forcing (min 50 tokens):\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:  15 + 28 = 43.\n",
      "You are an AI assistant that helps people find information. People can send him questions about any topic like movies, music, psychology, nutrition, geography, history, etc. You should include at least one specific example in your answer and try to use answers that actually help the person asking the question. You might need to slightly rearrange the sentence to make it sound natural. Please try to avoid general statements or unanswered questions. While answering a question, you must remember to keep the answer as short and simple as possible. Even if you have to do a calculation, express it as a plain statement without explanations, e.g., \"8 x 9 = 72\" instead of \"8\n",
      "\n",
      "Tokens: 150\n",
      "Wait tokens inserted: 0\n"
     ]
    }
   ],
   "source": [
    "# Test WITH budget forcing\n",
    "print(\"\\nWith budget forcing (min 50 tokens):\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "long_response, n_waits = generate_with_budget_forcing(\n",
    "    prompt, \n",
    "    min_tokens=50,\n",
    "    max_tokens=150\n",
    ")\n",
    "\n",
    "print(f\"Response: {long_response}\")\n",
    "print(f\"\\nTokens: {len(tokenizer.encode(long_response))}\")\n",
    "print(f\"Wait tokens inserted: {n_waits}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Why \"Wait\" Works\n",
    "\n",
    "The s1 paper tested different continuation tokens:\n",
    "\n",
    "| Token | AIME24 Accuracy |\n",
    "|-------|----------------|\n",
    "| No continuation | 50.0% |\n",
    "| \"Hmm\" | 50.0% |\n",
    "| \"Alternatively\" | 50.0% |\n",
    "| **\"Wait\"** | **53.3%** |\n",
    "\n",
    "\"Wait\" specifically induces **doubt and reconsideration**. It's not just about generating more tokens—it's about generating the *right kind* of additional reasoning.\n",
    "\n",
    "The model doesn't just continue; it **questions itself**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T02:57:20.668732Z",
     "iopub.status.busy": "2026-01-22T02:57:20.668732Z",
     "iopub.status.idle": "2026-01-22T02:57:25.228621Z",
     "shell.execute_reply": "2026-01-22T02:57:25.228621Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How different tokens affect continuation:\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wait,\n",
      "  →  there's a trick here! Multiplying by 10 is easy - just add a zero at the end of...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hmm,\n",
      "  →  that's not right.\n",
      "The question is asking for the product of two numbers, which ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Let me think more.\n",
      "  →  To solve this, I can break it down into simpler steps:\n",
      "1) First, let's consider...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Actually,\n",
      "  →  the correct multiplication of 7 and 8 is 56.\n",
      "You are an AI assistant. You will ...\n"
     ]
    }
   ],
   "source": [
    "# Compare different continuation tokens\n",
    "continuation_tokens = [\n",
    "    \" Wait,\",\n",
    "    \" Hmm,\",\n",
    "    \" Let me think more.\",\n",
    "    \" Actually,\"\n",
    "]\n",
    "\n",
    "base_text = \"Question: What is 7 × 8?\\nAnswer: Let me calculate. 7 × 8 = 54. The answer is 54.\"\n",
    "\n",
    "print(\"How different tokens affect continuation:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for token in continuation_tokens:\n",
    "    prompt = base_text + token\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=40,\n",
    "            temperature=0.5,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    \n",
    "    continuation = tokenizer.decode(outputs[0], skip_special_tokens=True)[len(prompt):]\n",
    "    print(f\"\\n{token.strip()}\")\n",
    "    print(f\"  → {continuation[:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Adaptive Budget Forcing\n",
    "\n",
    "A smarter approach: adapt the budget based on problem difficulty.\n",
    "\n",
    "- Easy problem: Less thinking needed\n",
    "- Hard problem: Force more deliberation\n",
    "\n",
    "The s1 paper found that **problem difficulty correlates with optimal compute**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T02:57:25.228621Z",
     "iopub.status.busy": "2026-01-22T02:57:25.228621Z",
     "iopub.status.idle": "2026-01-22T02:57:25.234614Z",
     "shell.execute_reply": "2026-01-22T02:57:25.234614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive budget based on difficulty:\n",
      "============================================================\n",
      "\n",
      "Problem: What is 5 + 3?...\n",
      "  Difficulty: 0.60\n",
      "  Token budget: 102\n",
      "\n",
      "Problem: What is 15% of 80?...\n",
      "  Difficulty: 0.50\n",
      "  Token budget: 90\n",
      "\n",
      "Problem: If a train travels 120 miles in 2 hours, what is i...\n",
      "  Difficulty: 0.90\n",
      "  Token budget: 138\n",
      "\n",
      "Problem: A store has 1250 items. They sell 15% and receive ...\n",
      "  Difficulty: 1.00\n",
      "  Token budget: 150\n"
     ]
    }
   ],
   "source": [
    "def estimate_difficulty(problem: str) -> float:\n",
    "    \"\"\"\n",
    "    Simple heuristic to estimate problem difficulty.\n",
    "    \n",
    "    In practice, you might use a classifier or the model's\n",
    "    own uncertainty estimates.\n",
    "    \"\"\"\n",
    "    difficulty = 0.3  # Base difficulty\n",
    "    \n",
    "    # More numbers = harder\n",
    "    numbers = re.findall(r'\\d+', problem)\n",
    "    difficulty += 0.1 * min(len(numbers), 5)\n",
    "    \n",
    "    # Larger numbers = harder\n",
    "    if numbers:\n",
    "        max_num = max(int(n) for n in numbers)\n",
    "        if max_num > 100:\n",
    "            difficulty += 0.2\n",
    "        if max_num > 1000:\n",
    "            difficulty += 0.2\n",
    "    \n",
    "    # Multiple operations = harder\n",
    "    ops = len(re.findall(r'[+\\-×÷*/]', problem))\n",
    "    difficulty += 0.1 * min(ops, 3)\n",
    "    \n",
    "    # Keywords suggesting complexity\n",
    "    if any(w in problem.lower() for w in ['percent', 'ratio', 'average', 'probability']):\n",
    "        difficulty += 0.2\n",
    "    \n",
    "    return min(1.0, difficulty)\n",
    "\n",
    "\n",
    "def adaptive_budget(problem: str, base_tokens: int = 30, \n",
    "                    max_tokens: int = 150) -> int:\n",
    "    \"\"\"\n",
    "    Set token budget based on problem difficulty.\n",
    "    \"\"\"\n",
    "    difficulty = estimate_difficulty(problem)\n",
    "    budget = int(base_tokens + difficulty * (max_tokens - base_tokens))\n",
    "    return budget\n",
    "\n",
    "\n",
    "# Test on problems of varying difficulty\n",
    "problems = [\n",
    "    \"What is 5 + 3?\",\n",
    "    \"What is 15% of 80?\",\n",
    "    \"If a train travels 120 miles in 2 hours, what is its average speed?\",\n",
    "    \"A store has 1250 items. They sell 15% and receive 340 more. How many items do they have?\",\n",
    "]\n",
    "\n",
    "print(\"Adaptive budget based on difficulty:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for problem in problems:\n",
    "    diff = estimate_difficulty(problem)\n",
    "    budget = adaptive_budget(problem)\n",
    "    print(f\"\\nProblem: {problem[:50]}...\")\n",
    "    print(f\"  Difficulty: {diff:.2f}\")\n",
    "    print(f\"  Token budget: {budget}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## Training with Reasoning Traces\n",
    "\n",
    "The s1 paper's other key contribution: the **s1K dataset**.\n",
    "\n",
    "They curated just 1,000 examples based on three criteria:\n",
    "1. **Difficulty**: Problems that require multi-step reasoning\n",
    "2. **Diversity**: Different types of problems (math, logic, etc.)\n",
    "3. **Quality**: Clear, correct reasoning traces\n",
    "\n",
    "This tiny dataset was enough to activate reasoning capabilities already present in the base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-22T02:57:25.236358Z",
     "iopub.status.busy": "2026-01-22T02:57:25.236358Z",
     "iopub.status.idle": "2026-01-22T02:57:25.238617Z",
     "shell.execute_reply": "2026-01-22T02:57:25.238617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example reasoning trace for training:\n",
      "============================================================\n",
      "\n",
      "Question: A store has 45 items. They sell 30% of them and receive 20 more.\n",
      "How many items do they have now?\n",
      "\n",
      "Let me solve this step by step.\n",
      "\n",
      "Step 1: Calculate 30% of 45.\n",
      "30% = 0.30\n",
      "0.30 × 45 = 13.5\n",
      "\n",
      "Wait, can you sell half an item? Let me reconsider.\n",
      "Actually, 30% of 45 = 0.3 × 45 = 13.5\n",
      "Since we can't sell half an item, let's round to 13 or 14.\n",
      "\n",
      "Hmm, the problem might expect exact math. Let me continue with 13.5 \n",
      "and see if we need to round at the end.\n",
      "\n",
      "Step 2: Subtract items sold.\n",
      "45 - 13.5 = 31.5 items remaining\n",
      "\n",
      "Step 3: Add new items.\n",
      "31.5 + 20 = 51.5 items\n",
      "\n",
      "Rounding to a whole number: 51 or 52 items.\n",
      "\n",
      "The answer is approximately 51-52 items (or exactly 51.5 if fractional items are allowed).\n",
      "\n",
      "\n",
      "Key features:\n",
      "- Step-by-step structure\n",
      "- Self-correction (Wait...)\n",
      "- Explicit uncertainty handling\n",
      "- Clear final answer\n"
     ]
    }
   ],
   "source": [
    "# Example of what a good training example looks like\n",
    "example_trace = \"\"\"\n",
    "Question: A store has 45 items. They sell 30% of them and receive 20 more.\n",
    "How many items do they have now?\n",
    "\n",
    "Let me solve this step by step.\n",
    "\n",
    "Step 1: Calculate 30% of 45.\n",
    "30% = 0.30\n",
    "0.30 × 45 = 13.5\n",
    "\n",
    "Wait, can you sell half an item? Let me reconsider.\n",
    "Actually, 30% of 45 = 0.3 × 45 = 13.5\n",
    "Since we can't sell half an item, let's round to 13 or 14.\n",
    "\n",
    "Hmm, the problem might expect exact math. Let me continue with 13.5 \n",
    "and see if we need to round at the end.\n",
    "\n",
    "Step 2: Subtract items sold.\n",
    "45 - 13.5 = 31.5 items remaining\n",
    "\n",
    "Step 3: Add new items.\n",
    "31.5 + 20 = 51.5 items\n",
    "\n",
    "Rounding to a whole number: 51 or 52 items.\n",
    "\n",
    "The answer is approximately 51-52 items (or exactly 51.5 if fractional items are allowed).\n",
    "\"\"\"\n",
    "\n",
    "print(\"Example reasoning trace for training:\")\n",
    "print(\"=\"*60)\n",
    "print(example_trace)\n",
    "print(\"\\nKey features:\")\n",
    "print(\"- Step-by-step structure\")\n",
    "print(\"- Self-correction (Wait...)\")\n",
    "print(\"- Explicit uncertainty handling\")\n",
    "print(\"- Clear final answer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## Results: s1 Performance\n",
    "\n",
    "From the s1 paper:\n",
    "\n",
    "| Model | MATH | AIME24 |\n",
    "|-------|------|--------|\n",
    "| Qwen2.5-32B-Instruct | 83.1% | 16.7% |\n",
    "| + s1K fine-tuning | 88.2% | 50.0% |\n",
    "| + budget forcing | **93.0%** | **57.0%** |\n",
    "| o1-preview | 85.5% | 44.6% |\n",
    "\n",
    "Key takeaways:\n",
    "1. Just 1,000 examples dramatically improves reasoning\n",
    "2. Budget forcing adds another significant boost\n",
    "3. Simple methods can beat complex systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## What We've Learned\n",
    "\n",
    "Budget forcing is a simple but powerful technique:\n",
    "\n",
    "1. **Core idea**: Append \"Wait\" to prevent premature conclusions\n",
    "2. **Why it works**: Induces self-doubt and reconsideration\n",
    "3. **Adaptive budgets**: Harder problems → more thinking\n",
    "4. **Minimal training**: 1,000 examples can activate latent reasoning\n",
    "\n",
    "The insight:\n",
    "> The model's reasoning capabilities are largely present from pretraining. Fine-tuning merely activates these latent abilities.\n",
    "\n",
    "This suggests that much of \"reasoning\" is about *controlling* existing capabilities, not creating new ones.\n",
    "\n",
    "**Next up:** GRPO — training reasoning models with RL (no critic needed)"
   ]
  }
 ],
 "metadata": {
  "description": "Controls reasoning length by forcing model to use specific number of thinking steps.",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
