{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Reasoning Distillation\n",
    "\n",
    "**Teaching small models to think like big ones**\n",
    "\n",
    "We've built powerful reasoning systems: chain-of-thought, process reward models, MCTS, GRPO. But these techniques work best with large models (70B+). What about reasoning on a phone? In a browser? On a tiny GPU?\n",
    "\n",
    "Distillation transfers the reasoning *patterns* from a large teacher to a small student."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## The DeepSeek Discovery\n",
    "\n",
    "From the DeepSeek-R1 paper:\n",
    "\n",
    "> The reasoning patterns of larger models can be distilled into smaller models, resulting in better performance compared to the reasoning patterns discovered through RL on small models.\n",
    "\n",
    "In other words:\n",
    "- Train a 70B model to reason with RL → good reasoning emerges\n",
    "- Distill to a 7B model → 7B inherits the reasoning patterns\n",
    "- Result: 7B with distillation > 7B with direct RL\n",
    "\n",
    "The small model can't discover complex reasoning patterns on its own, but it *can* learn to imitate them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Types of Distillation\n",
    "\n",
    "### 1. Standard Knowledge Distillation\n",
    "Train student to match teacher's *output distributions*.\n",
    "\n",
    "$$\\mathcal{L}_{\\text{KD}} = \\text{KL}(P_{\\text{teacher}} || P_{\\text{student}})$$\n",
    "\n",
    "### 2. Reasoning Trace Distillation\n",
    "Train student on teacher's *step-by-step solutions*.\n",
    "\n",
    "$$\\mathcal{L}_{\\text{trace}} = -\\log P_{\\text{student}}(\\text{reasoning trace})$$\n",
    "\n",
    "### 3. Behavioral Cloning\n",
    "Just train student to produce the same final outputs.\n",
    "\n",
    "For reasoning, **trace distillation** works best. The student learns not just *what* answer to give, but *how* to think."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T21:24:55.391317Z",
     "iopub.status.busy": "2025-12-10T21:24:55.391237Z",
     "iopub.status.idle": "2025-12-10T21:25:00.304436Z",
     "shell.execute_reply": "2025-12-10T21:25:00.304006Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded on cuda\n",
      "Teacher: Qwen2.5-1.5B-Instruct\n",
      "Student: Qwen2.5-0.5B-Instruct\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from typing import List\n",
    "import numpy as np\n",
    "\n",
    "# Load teacher and student models\n",
    "# Teacher: larger model, Student: smaller model\n",
    "print(\"Loading models...\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-1.5B-Instruct\")\n",
    "teacher = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-1.5B-Instruct\", dtype=\"auto\")\n",
    "student = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-0.5B-Instruct\", dtype=\"auto\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "teacher = teacher.to(device)\n",
    "student = student.to(device)\n",
    "\n",
    "teacher.eval()  # Teacher is frozen\n",
    "# Student will be trained\n",
    "\n",
    "print(f\"Loaded on {device}\")\n",
    "print(f\"Teacher: Qwen2.5-1.5B-Instruct\")\n",
    "print(f\"Student: Qwen2.5-0.5B-Instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Generating Teacher Reasoning Traces\n",
    "\n",
    "First, we need to collect high-quality reasoning traces from the teacher model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T21:25:00.305634Z",
     "iopub.status.busy": "2025-12-10T21:25:00.305418Z",
     "iopub.status.idle": "2025-12-10T21:25:15.365649Z",
     "shell.execute_reply": "2025-12-10T21:25:15.365322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating teacher traces...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated 6 traces\n",
      "\n",
      "Example trace:\n",
      "============================================================\n",
      "Problem: What is 15 + 28?\n",
      "\n",
      "Solution: Let me solve this step by step.\n",
      "Step 1: I know that 10 + 10 = 20\n",
      "Step 2: Now, let's add the remaining numbers. We have 15 and 8 left to add.\n",
      "Step 3: If we break down 15 into 10 + 5, then we can see that 10 + 8 = 18 and 5 + 10 = 15. So, 15 + 8 = 23.\n",
      "Step 4: Finall...\n"
     ]
    }
   ],
   "source": [
    "def generate_teacher_traces(teacher, tokenizer, problems: List[str],\n",
    "                            n_per_problem: int = 3,\n",
    "                            max_tokens: int = 150) -> List[dict]:\n",
    "    \"\"\"\n",
    "    Generate reasoning traces from the teacher model.\n",
    "    \n",
    "    We'll generate multiple traces per problem and filter for correctness.\n",
    "    \"\"\"\n",
    "    traces = []\n",
    "    \n",
    "    for problem in problems:\n",
    "        prompt = f\"Problem: {problem}\\n\\nSolution: Let me solve this step by step.\\n\"\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "        \n",
    "        for _ in range(n_per_problem):\n",
    "            with torch.no_grad():\n",
    "                outputs = teacher.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=max_tokens,\n",
    "                    temperature=0.7,\n",
    "                    do_sample=True,\n",
    "                    pad_token_id=tokenizer.eos_token_id,\n",
    "                )\n",
    "            \n",
    "            full_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            trace = full_text[len(prompt):]\n",
    "            \n",
    "            traces.append({\n",
    "                \"problem\": problem,\n",
    "                \"prompt\": prompt,\n",
    "                \"trace\": trace,\n",
    "                \"full_text\": prompt + trace\n",
    "            })\n",
    "    \n",
    "    return traces\n",
    "\n",
    "\n",
    "# Generate some traces\n",
    "problems = [\n",
    "    \"What is 15 + 28?\",\n",
    "    \"If a train travels 60 miles in 2 hours, what is its speed?\",\n",
    "    \"A store has 50 items. They sell 20% of them. How many are left?\",\n",
    "]\n",
    "\n",
    "print(\"Generating teacher traces...\")\n",
    "teacher_traces = generate_teacher_traces(teacher, tokenizer, problems, n_per_problem=2)\n",
    "\n",
    "print(f\"\\nGenerated {len(teacher_traces)} traces\")\n",
    "print(\"\\nExample trace:\")\n",
    "print(\"=\"*60)\n",
    "print(teacher_traces[0][\"full_text\"][:300] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Trace Distillation Loss\n",
    "\n",
    "The simplest form: train the student to produce the same reasoning traces as the teacher.\n",
    "\n",
    "This is just supervised fine-tuning on teacher-generated data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T21:25:15.366755Z",
     "iopub.status.busy": "2025-12-10T21:25:15.366678Z",
     "iopub.status.idle": "2025-12-10T21:25:15.415242Z",
     "shell.execute_reply": "2025-12-10T21:25:15.414883Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distillation loss: 0.9728\n"
     ]
    }
   ],
   "source": [
    "def compute_trace_distillation_loss(student, tokenizer, \n",
    "                                     trace: dict) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute loss for matching a teacher trace.\n",
    "    \n",
    "    This is just cross-entropy on the reasoning steps.\n",
    "    \"\"\"\n",
    "    full_text = trace[\"full_text\"]\n",
    "    prompt_len = len(tokenizer(trace[\"prompt\"])[\"input_ids\"])\n",
    "    \n",
    "    inputs = tokenizer(full_text, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = student(**inputs, labels=inputs[\"input_ids\"])\n",
    "    \n",
    "    # We only care about loss on the reasoning trace, not the prompt\n",
    "    # In practice, we'd mask the prompt tokens\n",
    "    # For simplicity, we'll use the full loss here\n",
    "    \n",
    "    return outputs.loss\n",
    "\n",
    "\n",
    "# Test\n",
    "loss = compute_trace_distillation_loss(student, tokenizer, teacher_traces[0])\n",
    "print(f\"Distillation loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Token-Level Knowledge Distillation\n",
    "\n",
    "A more sophisticated approach: match the teacher's probability distribution at each token position.\n",
    "\n",
    "$$\\mathcal{L}_{\\text{KD}} = \\sum_t \\text{KL}\\left( \\frac{P_T(y_t|y_{<t})}{\\tau} \\bigg|\\bigg| \\frac{P_S(y_t|y_{<t})}{\\tau} \\right)$$\n",
    "\n",
    "Where $\\tau$ is a temperature that softens the distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T21:25:15.416222Z",
     "iopub.status.busy": "2025-12-10T21:25:15.416119Z",
     "iopub.status.idle": "2025-12-10T21:25:15.511831Z",
     "shell.execute_reply": "2025-12-10T21:25:15.511501Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge distillation losses:\n",
      "  KL loss: 60.5000\n",
      "  Hard target loss: 0.9727\n",
      "  Total: 121.5000\n"
     ]
    }
   ],
   "source": [
    "def knowledge_distillation_loss(teacher, student, tokenizer,\n",
    "                                 text: str, temperature: float = 2.0,\n",
    "                                 alpha: float = 0.5) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Token-level knowledge distillation.\n",
    "    \n",
    "    Combines:\n",
    "    1. KL divergence from teacher distributions\n",
    "    2. Hard target cross-entropy\n",
    "    \n",
    "    Args:\n",
    "        teacher: Teacher model (frozen)\n",
    "        student: Student model (training)\n",
    "        tokenizer: Tokenizer\n",
    "        text: Text to distill on\n",
    "        temperature: Softening temperature\n",
    "        alpha: Weight on distillation vs. hard targets\n",
    "    \n",
    "    Returns:\n",
    "        Combined loss\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # Get teacher logits\n",
    "    with torch.no_grad():\n",
    "        teacher_outputs = teacher(**inputs)\n",
    "        teacher_logits = teacher_outputs.logits\n",
    "    \n",
    "    # Get student logits\n",
    "    student_outputs = student(**inputs)\n",
    "    student_logits = student_outputs.logits\n",
    "    \n",
    "    # Soft targets (temperature-scaled)\n",
    "    teacher_probs = F.softmax(teacher_logits / temperature, dim=-1)\n",
    "    student_log_probs = F.log_softmax(student_logits / temperature, dim=-1)\n",
    "    \n",
    "    # KL divergence loss\n",
    "    kl_loss = F.kl_div(\n",
    "        student_log_probs[:, :-1, :],  # Predict next token\n",
    "        teacher_probs[:, :-1, :],\n",
    "        reduction='batchmean'\n",
    "    )\n",
    "    \n",
    "    # Hard target loss (standard cross-entropy)\n",
    "    hard_loss = F.cross_entropy(\n",
    "        student_logits[:, :-1, :].reshape(-1, student_logits.size(-1)),\n",
    "        inputs[\"input_ids\"][:, 1:].reshape(-1)\n",
    "    )\n",
    "    \n",
    "    # Combined loss\n",
    "    # Scale KL by T^2 (standard practice)\n",
    "    total_loss = alpha * (temperature ** 2) * kl_loss + (1 - alpha) * hard_loss\n",
    "    \n",
    "    return total_loss, kl_loss, hard_loss\n",
    "\n",
    "\n",
    "# Test\n",
    "test_text = teacher_traces[0][\"full_text\"]\n",
    "total, kl, hard = knowledge_distillation_loss(\n",
    "    teacher, student, tokenizer, test_text\n",
    ")\n",
    "\n",
    "print(f\"Knowledge distillation losses:\")\n",
    "print(f\"  KL loss: {kl.item():.4f}\")\n",
    "print(f\"  Hard target loss: {hard.item():.4f}\")\n",
    "print(f\"  Total: {total.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## Training Loop for Distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T21:25:15.512742Z",
     "iopub.status.busy": "2025-12-10T21:25:15.512662Z",
     "iopub.status.idle": "2025-12-10T21:25:17.349331Z",
     "shell.execute_reply": "2025-12-10T21:25:17.348983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training student with distillation...\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 110.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss = 84.5833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss = 75.0417\n",
      "\n",
      "Distillation complete!\n"
     ]
    }
   ],
   "source": [
    "def train_distillation_epoch(teacher, student, tokenizer,\n",
    "                              traces: List[dict], optimizer,\n",
    "                              temperature: float = 2.0,\n",
    "                              alpha: float = 0.5) -> float:\n",
    "    \"\"\"\n",
    "    Train student for one epoch on teacher traces.\n",
    "    \"\"\"\n",
    "    student.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for trace in traces:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss, _, _ = knowledge_distillation_loss(\n",
    "            teacher, student, tokenizer,\n",
    "            trace[\"full_text\"],\n",
    "            temperature=temperature,\n",
    "            alpha=alpha\n",
    "        )\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(traces)\n",
    "\n",
    "\n",
    "# Train for a few epochs\n",
    "optimizer = torch.optim.AdamW(student.parameters(), lr=1e-5)\n",
    "\n",
    "print(\"Training student with distillation...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for epoch in range(3):\n",
    "    loss = train_distillation_epoch(\n",
    "        teacher, student, tokenizer,\n",
    "        teacher_traces, optimizer\n",
    "    )\n",
    "    print(f\"Epoch {epoch+1}: Loss = {loss:.4f}\")\n",
    "\n",
    "print(\"\\nDistillation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## Quality Filtering\n",
    "\n",
    "Not all teacher traces are worth imitating. We should filter for:\n",
    "1. **Correct answers** — Don't teach wrong reasoning\n",
    "2. **Clear steps** — Mumbled reasoning is hard to learn from\n",
    "3. **Diverse approaches** — Multiple ways to solve problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T21:25:17.350190Z",
     "iopub.status.busy": "2025-12-10T21:25:17.350105Z",
     "iopub.status.idle": "2025-12-10T21:25:17.352816Z",
     "shell.execute_reply": "2025-12-10T21:25:17.352514Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered: 6/6 traces kept\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def filter_traces(traces: List[dict], correct_answers: dict = None) -> List[dict]:\n",
    "    \"\"\"\n",
    "    Filter teacher traces for quality.\n",
    "    \n",
    "    Args:\n",
    "        traces: List of trace dicts\n",
    "        correct_answers: Dict mapping problems to correct answers\n",
    "    \n",
    "    Returns:\n",
    "        Filtered list of high-quality traces\n",
    "    \"\"\"\n",
    "    filtered = []\n",
    "    \n",
    "    for trace in traces:\n",
    "        text = trace[\"trace\"]\n",
    "        problem = trace[\"problem\"]\n",
    "        \n",
    "        # Filter 1: Must have step-by-step structure\n",
    "        has_steps = any(marker in text.lower() \n",
    "                       for marker in ['step', 'first', 'then', 'next', 'finally'])\n",
    "        if not has_steps:\n",
    "            continue\n",
    "        \n",
    "        # Filter 2: Must have reasonable length\n",
    "        if len(text.split()) < 20 or len(text.split()) > 300:\n",
    "            continue\n",
    "        \n",
    "        # Filter 3: Check correctness if we have answers\n",
    "        if correct_answers and problem in correct_answers:\n",
    "            correct = str(correct_answers[problem])\n",
    "            if correct not in text:\n",
    "                continue\n",
    "        \n",
    "        filtered.append(trace)\n",
    "    \n",
    "    return filtered\n",
    "\n",
    "\n",
    "# Example filtering\n",
    "correct_answers = {\n",
    "    \"What is 15 + 28?\": \"43\",\n",
    "    \"If a train travels 60 miles in 2 hours, what is its speed?\": \"30\",\n",
    "    \"A store has 50 items. They sell 20% of them. How many are left?\": \"40\",\n",
    "}\n",
    "\n",
    "filtered = filter_traces(teacher_traces, correct_answers)\n",
    "print(f\"Filtered: {len(filtered)}/{len(teacher_traces)} traces kept\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## Results from DeepSeek\n",
    "\n",
    "From the DeepSeek-R1 paper:\n",
    "\n",
    "| Model | Method | AIME 2024 | MATH |\n",
    "|-------|--------|-----------|------|\n",
    "| Qwen2.5-7B | Base | 3.3% | 75.5% |\n",
    "| Qwen2.5-7B | + RL alone | 10.0% | 79.3% |\n",
    "| Qwen2.5-7B | **+ R1 distillation** | **26.7%** | **83.9%** |\n",
    "| Qwen2.5-32B | + R1 distillation | 43.3% | 90.2% |\n",
    "\n",
    "Key insight: A 7B model with distillation dramatically outperforms a 7B model trained with RL alone. The reasoning patterns from the larger model transfer!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## What We've Learned\n",
    "\n",
    "Reasoning distillation transfers thinking patterns from large to small models:\n",
    "\n",
    "1. **Generate** high-quality reasoning traces from teacher\n",
    "2. **Filter** for correctness and clarity\n",
    "3. **Train** student to reproduce the traces (SFT or KD)\n",
    "\n",
    "The key insight:\n",
    "> Small models can't discover complex reasoning on their own, but they *can* learn to imitate it.\n",
    "\n",
    "Two loss functions:\n",
    "- **Trace SFT**: $\\mathcal{L} = -\\log P_S(\\text{trace})$\n",
    "- **KD**: $\\mathcal{L} = \\alpha \\cdot T^2 \\cdot \\text{KL}(P_T/T || P_S/T) + (1-\\alpha) \\cdot \\text{CE}$\n",
    "\n",
    "This completes our journey through reasoning techniques!\n",
    "\n",
    "## Summary of the Section\n",
    "\n",
    "We covered:\n",
    "1. **Chain-of-Thought** — Think step by step\n",
    "2. **Self-Consistency** — Sample many, vote\n",
    "3. **Tree of Thoughts** — Explore and backtrack\n",
    "4. **Process Reward Models** — Score each step\n",
    "5. **Best-of-N** — Generate and verify\n",
    "6. **MCTS** — Smart search\n",
    "7. **Budget Forcing** — Control thinking length\n",
    "8. **GRPO** — RL without a critic\n",
    "9. **Distillation** — Transfer to smaller models\n",
    "\n",
    "These techniques, combined, power the reasoning capabilities of models like o1 and DeepSeek-R1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
