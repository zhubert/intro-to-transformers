{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": "# Tree of Thoughts\n\n**Exploring multiple reasoning paths with look-ahead and backtracking**\n\nChain-of-thought is linear: one step follows another, marching toward an answer. But human problem-solving isn't linear. We explore options, hit dead ends, backtrack, and try different approaches.\n\nTree of Thoughts (ToT) brings that flexibility to language models."
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## From Chain to Tree\n",
    "\n",
    "Compare the two paradigms:\n",
    "\n",
    "**Chain-of-Thought:**\n",
    "```\n",
    "Question → Step 1 → Step 2 → Step 3 → Answer\n",
    "                                      (hope it's right!)\n",
    "```\n",
    "\n",
    "**Tree of Thoughts:**\n",
    "```\n",
    "                    Question\n",
    "                       │\n",
    "           ┌───────────┼───────────┐\n",
    "           ▼           ▼           ▼\n",
    "        Step 1a     Step 1b     Step 1c\n",
    "           │           │           ✗ (bad idea, prune)\n",
    "       ┌───┴───┐   ┌───┴───┐\n",
    "       ▼       ▼   ▼       ▼\n",
    "    Step 2a  Step 2b  Step 2c  Step 2d\n",
    "       │       ✗       │       │\n",
    "       ▼               ▼       ▼\n",
    "    Answer          Answer  Answer\n",
    "                       ✓\n",
    "```\n",
    "\n",
    "Key differences:\n",
    "\n",
    "1. **Branching**: At each step, generate *multiple* possible continuations\n",
    "2. **Evaluation**: Score each branch to identify promising vs. hopeless paths\n",
    "3. **Pruning**: Abandon bad branches early (save compute!)\n",
    "4. **Backtracking**: If a path leads nowhere, try a different one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## The ToT Framework\n",
    "\n",
    "Tree of Thoughts has four key components:\n",
    "\n",
    "### 1. Thought Decomposition\n",
    "How do we break the problem into \"thoughts\" (intermediate steps)?\n",
    "\n",
    "- For math: each computation step\n",
    "- For writing: each paragraph or idea\n",
    "- For puzzles: each move or decision\n",
    "\n",
    "### 2. Thought Generation\n",
    "How do we generate candidate thoughts at each step?\n",
    "\n",
    "- **Sample**: Generate N thoughts independently (like self-consistency)\n",
    "- **Propose**: Have the model propose several alternatives in one call\n",
    "\n",
    "### 3. Thought Evaluation\n",
    "How do we know which thoughts are promising?\n",
    "\n",
    "- **Self-evaluation**: Ask the model to rate its own thoughts\n",
    "- **Voting**: Generate continuations, see which lead to success\n",
    "- **Heuristics**: Problem-specific scoring functions\n",
    "\n",
    "### 4. Search Algorithm\n",
    "How do we navigate the tree?\n",
    "\n",
    "- **Breadth-First Search (BFS)**: Explore all options at each level before going deeper\n",
    "- **Depth-First Search (DFS)**: Go deep first, backtrack on failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T05:03:40.776117Z",
     "iopub.status.busy": "2025-12-10T05:03:40.776033Z",
     "iopub.status.idle": "2025-12-10T05:03:43.780632Z",
     "shell.execute_reply": "2025-12-10T05:03:43.780232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading gpt2-medium...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded on cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Callable\n",
    "import re\n",
    "\n",
    "# Load model\n",
    "model_name = \"gpt2-medium\"\n",
    "print(f\"Loading {model_name}...\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"Loaded on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T05:03:43.781737Z",
     "iopub.status.busy": "2025-12-10T05:03:43.781567Z",
     "iopub.status.idle": "2025-12-10T05:03:43.785009Z",
     "shell.execute_reply": "2025-12-10T05:03:43.784714Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ThoughtNode defined.\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class ThoughtNode:\n",
    "    \"\"\"\n",
    "    A node in the Tree of Thoughts.\n",
    "    \n",
    "    Each node represents a partial solution state.\n",
    "    \"\"\"\n",
    "    thought: str           # The reasoning step at this node\n",
    "    state: str             # Full state (all thoughts so far)\n",
    "    score: float = 0.0     # Evaluation score\n",
    "    depth: int = 0         # How deep in the tree\n",
    "    parent: Optional['ThoughtNode'] = None\n",
    "    children: List['ThoughtNode'] = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.children is None:\n",
    "            self.children = []\n",
    "    \n",
    "    def get_path(self) -> List[str]:\n",
    "        \"\"\"Get the full reasoning path from root to this node.\"\"\"\n",
    "        path = []\n",
    "        node = self\n",
    "        while node is not None:\n",
    "            path.append(node.thought)\n",
    "            node = node.parent\n",
    "        return list(reversed(path))\n",
    "\n",
    "\n",
    "def generate_text(prompt: str, max_new_tokens: int = 50, \n",
    "                  temperature: float = 0.7) -> str:\n",
    "    \"\"\"Generate text continuation.\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=temperature,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    \n",
    "    full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return full_response[len(prompt):].strip()\n",
    "\n",
    "\n",
    "print(\"ThoughtNode defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Example: Game of 24\n",
    "\n",
    "The original ToT paper used the \"Game of 24\" as a key benchmark. The rules:\n",
    "\n",
    "- You're given 4 numbers (e.g., 1, 2, 3, 4)\n",
    "- Use +, -, ×, ÷ to make 24\n",
    "- Use each number exactly once\n",
    "\n",
    "Example: 1, 2, 3, 4 → (1 + 2 + 3) × 4 = 24 ✓\n",
    "\n",
    "This is perfect for ToT because:\n",
    "- There are many possible paths (which operation to try first?)\n",
    "- Some paths are dead ends (can't reach 24)\n",
    "- We can evaluate intermediate states (\"is 24 still reachable?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T05:03:43.785814Z",
     "iopub.status.busy": "2025-12-10T05:03:43.785744Z",
     "iopub.status.idle": "2025-12-10T05:03:45.509852Z",
     "shell.execute_reply": "2025-12-10T05:03:45.509492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating candidate thoughts...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhubert/intro-to-transformers/.venv/lib/python3.12/site-packages/transformers/integrations/sdpa_attention.py:83: UserWarning: Flash Efficient attention on Current AMD GPU is still experimental. Enable it with TORCH_ROCM_AOTRITON_ENABLE_EXPERIMENTAL=1. (Triggered internally at /pytorch/aten/src/ATen/native/transformers/hip/sdp_utils.cpp:316.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "/home/zhubert/intro-to-transformers/.venv/lib/python3.12/site-packages/transformers/integrations/sdpa_attention.py:83: UserWarning: Mem Efficient attention on Current AMD GPU is still experimental. Enable it with TORCH_ROCM_AOTRITON_ENABLE_EXPERIMENTAL=1. (Triggered internally at /pytorch/aten/src/ATen/native/transformers/hip/sdp_utils.cpp:373.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 4.\n",
      "2. 5.\n",
      "3. I have 3, 4, 6! They are all the same.\n"
     ]
    }
   ],
   "source": [
    "def generate_thoughts(state: str, n_thoughts: int = 3,\n",
    "                      problem_type: str = \"math\") -> List[str]:\n",
    "    \"\"\"\n",
    "    Generate multiple candidate next thoughts.\n",
    "    \n",
    "    We ask the model to propose several possible next steps.\n",
    "    \n",
    "    Args:\n",
    "        state: Current reasoning state\n",
    "        n_thoughts: Number of candidates to generate\n",
    "        problem_type: Type of problem (affects prompting)\n",
    "    \n",
    "    Returns:\n",
    "        List of candidate next thoughts\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"{state}\n",
    "\n",
    "What are {n_thoughts} different possible next steps? List them as:\n",
    "1.\n",
    "2.\n",
    "3.\"\"\"\n",
    "    \n",
    "    response = generate_text(prompt, max_new_tokens=100, temperature=0.8)\n",
    "    \n",
    "    # Parse numbered list\n",
    "    thoughts = []\n",
    "    lines = response.split('\\n')\n",
    "    for line in lines:\n",
    "        # Match lines starting with a number\n",
    "        match = re.match(r'^\\d+\\.\\s*(.+)', line.strip())\n",
    "        if match:\n",
    "            thoughts.append(match.group(1).strip())\n",
    "    \n",
    "    # If parsing failed, just split by newlines\n",
    "    if len(thoughts) < n_thoughts and lines:\n",
    "        thoughts = [l.strip() for l in lines if l.strip()][:n_thoughts]\n",
    "    \n",
    "    return thoughts[:n_thoughts]\n",
    "\n",
    "\n",
    "# Test thought generation\n",
    "test_state = \"\"\"Problem: Use 2, 3, 4, 6 with +, -, ×, ÷ to make 24.\n",
    "Current: I have numbers 2, 3, 4, 6.\"\"\"\n",
    "\n",
    "print(\"Generating candidate thoughts...\\n\")\n",
    "thoughts = generate_thoughts(test_state, n_thoughts=3)\n",
    "for i, t in enumerate(thoughts, 1):\n",
    "    print(f\"{i}. {t}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Self-Evaluation\n",
    "\n",
    "The key to ToT is evaluating which thoughts are promising. We can ask the model to rate its own ideas.\n",
    "\n",
    "For Game of 24, we might ask:\n",
    "- \"Can you still make 24 from the remaining numbers?\"\n",
    "- Rate as: sure / likely / unlikely / impossible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T05:03:45.510914Z",
     "iopub.status.busy": "2025-12-10T05:03:45.510834Z",
     "iopub.status.idle": "2025-12-10T05:03:45.787757Z",
     "shell.execute_reply": "2025-12-10T05:03:45.787437Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating thoughts:\n",
      "\n",
      "  The word 'Awesome' might work.\n",
      "  → Score: 0.50\n",
      "\n",
      "  The word 'Sad' could be it.\n",
      "  → Score: 0.50\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  I'll think about 'Afraid'.\n",
      "  → Score: 0.50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_thought(state: str, thought: str,\n",
    "                     evaluation_prompt: str = None) -> float:\n",
    "    \"\"\"\n",
    "    Have the model evaluate a thought on a 0-1 scale.\n",
    "    \n",
    "    We ask the model to rate the thought as:\n",
    "    - sure (1.0): This will definitely work\n",
    "    - likely (0.7): This looks promising\n",
    "    - possible (0.4): Maybe, not sure\n",
    "    - unlikely (0.1): Probably won't work\n",
    "    \n",
    "    Args:\n",
    "        state: Current problem state\n",
    "        thought: The candidate thought to evaluate\n",
    "        evaluation_prompt: Custom evaluation prompt\n",
    "    \n",
    "    Returns:\n",
    "        Score from 0.0 to 1.0\n",
    "    \"\"\"\n",
    "    if evaluation_prompt is None:\n",
    "        evaluation_prompt = f\"\"\"{state}\n",
    "\n",
    "Proposed next step: {thought}\n",
    "\n",
    "Evaluate this step. Is it a good approach to solving the problem?\n",
    "Rate as: sure / likely / possible / unlikely\n",
    "\n",
    "Rating:\"\"\"\n",
    "    \n",
    "    response = generate_text(evaluation_prompt, max_new_tokens=10, temperature=0.3)\n",
    "    response_lower = response.lower().strip()\n",
    "    \n",
    "    # Parse the rating\n",
    "    if 'sure' in response_lower:\n",
    "        return 1.0\n",
    "    elif 'likely' in response_lower:\n",
    "        return 0.7\n",
    "    elif 'possible' in response_lower:\n",
    "        return 0.4\n",
    "    elif 'unlikely' in response_lower or 'impossible' in response_lower:\n",
    "        return 0.1\n",
    "    else:\n",
    "        # Default to middle score if we can't parse\n",
    "        return 0.5\n",
    "\n",
    "\n",
    "# Test evaluation\n",
    "state = \"Problem: Find a word that starts with 'A' and means 'happy'.\"\n",
    "thoughts = [\"The word 'Awesome' might work.\", \"The word 'Sad' could be it.\", \"I'll think about 'Afraid'.\"]\n",
    "\n",
    "print(\"Evaluating thoughts:\\n\")\n",
    "for thought in thoughts:\n",
    "    score = evaluate_thought(state, thought)\n",
    "    print(f\"  {thought}\")\n",
    "    print(f\"  → Score: {score:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Breadth-First Search (BFS)\n",
    "\n",
    "BFS explores the tree level by level:\n",
    "1. Start with the initial state\n",
    "2. Generate all possible first steps\n",
    "3. Evaluate and keep the best $k$ (\"beam width\")\n",
    "4. For each kept state, generate next steps\n",
    "5. Repeat until reaching a solution or max depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T05:03:45.788790Z",
     "iopub.status.busy": "2025-12-10T05:03:45.788718Z",
     "iopub.status.idle": "2025-12-10T05:03:45.792541Z",
     "shell.execute_reply": "2025-12-10T05:03:45.792269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFS Tree of Thoughts solver ready.\n"
     ]
    }
   ],
   "source": [
    "class TreeOfThoughtsBFS:\n",
    "    \"\"\"\n",
    "    Tree of Thoughts with Breadth-First Search.\n",
    "    \n",
    "    Explores all options at each level, keeps top-k,\n",
    "    then goes deeper.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, tokenizer, device=\"cuda\",\n",
    "                 n_candidates: int = 3, beam_width: int = 2, max_depth: int = 3):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device\n",
    "        self.n_candidates = n_candidates  # How many thoughts to generate per node\n",
    "        self.beam_width = beam_width      # How many nodes to keep at each level\n",
    "        self.max_depth = max_depth        # How deep to search\n",
    "    \n",
    "    def solve(self, problem: str, is_solution: Callable[[str], bool] = None) -> dict:\n",
    "        \"\"\"\n",
    "        Solve a problem using BFS over thoughts.\n",
    "        \n",
    "        Args:\n",
    "            problem: The problem statement\n",
    "            is_solution: Function to check if a state is a solution\n",
    "        \n",
    "        Returns:\n",
    "            Dict with best solution, path, and all explored nodes\n",
    "        \"\"\"\n",
    "        # Initialize with root node\n",
    "        root = ThoughtNode(\n",
    "            thought=\"Start\",\n",
    "            state=f\"Problem: {problem}\\n\\nLet me think step by step.\",\n",
    "            score=1.0,\n",
    "            depth=0\n",
    "        )\n",
    "        \n",
    "        current_level = [root]\n",
    "        all_nodes = [root]\n",
    "        best_solution = None\n",
    "        best_score = -float('inf')\n",
    "        \n",
    "        for depth in range(self.max_depth):\n",
    "            print(f\"\\nDepth {depth + 1}: Exploring {len(current_level)} nodes...\")\n",
    "            \n",
    "            next_level = []\n",
    "            \n",
    "            for node in current_level:\n",
    "                # Generate candidate thoughts\n",
    "                thoughts = generate_thoughts(\n",
    "                    node.state, \n",
    "                    n_thoughts=self.n_candidates\n",
    "                )\n",
    "                \n",
    "                for thought in thoughts:\n",
    "                    # Create new state\n",
    "                    new_state = f\"{node.state}\\n\\nStep {depth + 1}: {thought}\"\n",
    "                    \n",
    "                    # Evaluate\n",
    "                    score = evaluate_thought(node.state, thought)\n",
    "                    \n",
    "                    # Create child node\n",
    "                    child = ThoughtNode(\n",
    "                        thought=thought,\n",
    "                        state=new_state,\n",
    "                        score=score,\n",
    "                        depth=depth + 1,\n",
    "                        parent=node\n",
    "                    )\n",
    "                    node.children.append(child)\n",
    "                    all_nodes.append(child)\n",
    "                    next_level.append(child)\n",
    "                    \n",
    "                    # Check if solution\n",
    "                    if is_solution and is_solution(new_state):\n",
    "                        if score > best_score:\n",
    "                            best_solution = child\n",
    "                            best_score = score\n",
    "            \n",
    "            # Keep only top-k nodes for next level\n",
    "            next_level.sort(key=lambda n: n.score, reverse=True)\n",
    "            current_level = next_level[:self.beam_width]\n",
    "            \n",
    "            print(f\"  Generated {len(next_level)} candidates, kept {len(current_level)}\")\n",
    "            for node in current_level:\n",
    "                print(f\"    Score {node.score:.2f}: {node.thought[:50]}...\")\n",
    "        \n",
    "        # If no explicit solution found, return best final node\n",
    "        if best_solution is None and current_level:\n",
    "            best_solution = max(current_level, key=lambda n: n.score)\n",
    "        \n",
    "        return {\n",
    "            \"solution\": best_solution,\n",
    "            \"path\": best_solution.get_path() if best_solution else [],\n",
    "            \"final_state\": best_solution.state if best_solution else None,\n",
    "            \"all_nodes\": all_nodes,\n",
    "            \"nodes_explored\": len(all_nodes)\n",
    "        }\n",
    "\n",
    "\n",
    "# Create ToT solver\n",
    "tot_bfs = TreeOfThoughtsBFS(\n",
    "    model, tokenizer, device=device,\n",
    "    n_candidates=2,  # Generate 2 candidates per node\n",
    "    beam_width=2,    # Keep top 2 at each level\n",
    "    max_depth=2      # Go 2 levels deep\n",
    ")\n",
    "\n",
    "print(\"BFS Tree of Thoughts solver ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T05:03:45.793319Z",
     "iopub.status.busy": "2025-12-10T05:03:45.793249Z",
     "iopub.status.idle": "2025-12-10T05:03:48.793058Z",
     "shell.execute_reply": "2025-12-10T05:03:48.792759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem: What is 15 + 28? Show your reasoning.\n",
      "\n",
      "============================================================\n",
      "\n",
      "Depth 1: Exploring 1 nodes...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Generated 2 candidates, kept 2\n",
      "    Score 0.50: 4....\n",
      "    Score 0.50: 5....\n",
      "\n",
      "Depth 2: Exploring 2 nodes...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Generated 4 candidates, kept 2\n",
      "    Score 0.50: 4....\n",
      "    Score 0.50: 5....\n",
      "\n",
      "============================================================\n",
      "SOLUTION PATH:\n",
      "============================================================\n",
      "Step 0: Start\n",
      "Step 1: 4.\n",
      "Step 2: 4.\n",
      "\n",
      "Total nodes explored: 7\n"
     ]
    }
   ],
   "source": [
    "# Test ToT-BFS on a simple problem\n",
    "problem = \"What is 15 + 28? Show your reasoning.\"\n",
    "\n",
    "print(f\"Problem: {problem}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "result = tot_bfs.solve(problem)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SOLUTION PATH:\")\n",
    "print(\"=\"*60)\n",
    "for i, step in enumerate(result[\"path\"]):\n",
    "    print(f\"Step {i}: {step}\")\n",
    "\n",
    "print(f\"\\nTotal nodes explored: {result['nodes_explored']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## Depth-First Search (DFS)\n",
    "\n",
    "DFS explores deeply first, then backtracks:\n",
    "\n",
    "1. Start with initial state\n",
    "2. Generate candidates for next step\n",
    "3. Pick the best one and go deeper\n",
    "4. If stuck (bad evaluation), backtrack and try another branch\n",
    "\n",
    "DFS is more memory-efficient than BFS and can find solutions faster for some problems. But it might miss better solutions on other branches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T05:03:48.794058Z",
     "iopub.status.busy": "2025-12-10T05:03:48.793966Z",
     "iopub.status.idle": "2025-12-10T05:03:48.797826Z",
     "shell.execute_reply": "2025-12-10T05:03:48.797524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DFS Tree of Thoughts solver ready.\n"
     ]
    }
   ],
   "source": [
    "class TreeOfThoughtsDFS:\n",
    "    \"\"\"\n",
    "    Tree of Thoughts with Depth-First Search.\n",
    "    \n",
    "    Explores deeply first, backtracks on failure.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, tokenizer, device=\"cuda\",\n",
    "                 n_candidates: int = 3, max_depth: int = 4,\n",
    "                 prune_threshold: float = 0.2):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device\n",
    "        self.n_candidates = n_candidates\n",
    "        self.max_depth = max_depth\n",
    "        self.prune_threshold = prune_threshold  # Don't explore if score < this\n",
    "        self.nodes_explored = 0\n",
    "    \n",
    "    def dfs(self, node: ThoughtNode, is_solution: Callable = None) -> Optional[ThoughtNode]:\n",
    "        \"\"\"\n",
    "        Recursive DFS exploration.\n",
    "        \n",
    "        Returns the first solution found, or None.\n",
    "        \"\"\"\n",
    "        self.nodes_explored += 1\n",
    "        \n",
    "        # Check depth limit\n",
    "        if node.depth >= self.max_depth:\n",
    "            return node if is_solution is None or is_solution(node.state) else None\n",
    "        \n",
    "        # Check if already a solution\n",
    "        if is_solution and is_solution(node.state):\n",
    "            return node\n",
    "        \n",
    "        # Generate and evaluate candidates\n",
    "        thoughts = generate_thoughts(node.state, n_thoughts=self.n_candidates)\n",
    "        candidates = []\n",
    "        \n",
    "        for thought in thoughts:\n",
    "            new_state = f\"{node.state}\\n\\nStep {node.depth + 1}: {thought}\"\n",
    "            score = evaluate_thought(node.state, thought)\n",
    "            \n",
    "            # Prune low-scoring candidates\n",
    "            if score < self.prune_threshold:\n",
    "                continue\n",
    "                \n",
    "            candidates.append((thought, new_state, score))\n",
    "        \n",
    "        # Sort by score, explore best first\n",
    "        candidates.sort(key=lambda x: x[2], reverse=True)\n",
    "        \n",
    "        for thought, new_state, score in candidates:\n",
    "            child = ThoughtNode(\n",
    "                thought=thought,\n",
    "                state=new_state,\n",
    "                score=score,\n",
    "                depth=node.depth + 1,\n",
    "                parent=node\n",
    "            )\n",
    "            node.children.append(child)\n",
    "            \n",
    "            # Recurse\n",
    "            result = self.dfs(child, is_solution)\n",
    "            if result is not None:\n",
    "                return result\n",
    "        \n",
    "        # No solution found in this subtree\n",
    "        return None\n",
    "    \n",
    "    def solve(self, problem: str, is_solution: Callable = None) -> dict:\n",
    "        \"\"\"\n",
    "        Solve a problem using DFS.\n",
    "        \"\"\"\n",
    "        self.nodes_explored = 0\n",
    "        \n",
    "        root = ThoughtNode(\n",
    "            thought=\"Start\",\n",
    "            state=f\"Problem: {problem}\\n\\nLet me think step by step.\",\n",
    "            score=1.0,\n",
    "            depth=0\n",
    "        )\n",
    "        \n",
    "        solution = self.dfs(root, is_solution)\n",
    "        \n",
    "        return {\n",
    "            \"solution\": solution,\n",
    "            \"path\": solution.get_path() if solution else [],\n",
    "            \"final_state\": solution.state if solution else None,\n",
    "            \"nodes_explored\": self.nodes_explored\n",
    "        }\n",
    "\n",
    "\n",
    "# Create DFS solver\n",
    "tot_dfs = TreeOfThoughtsDFS(\n",
    "    model, tokenizer, device=device,\n",
    "    n_candidates=2,\n",
    "    max_depth=3,\n",
    "    prune_threshold=0.2\n",
    ")\n",
    "\n",
    "print(\"DFS Tree of Thoughts solver ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T05:03:48.798621Z",
     "iopub.status.busy": "2025-12-10T05:03:48.798553Z",
     "iopub.status.idle": "2025-12-10T05:03:54.801180Z",
     "shell.execute_reply": "2025-12-10T05:03:54.800794Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem: A store has 50 items. They sell 15 and receive 20 more. How many items do they have?\n",
      "Correct answer: 50 - 15 + 20 = 55\n",
      "\n",
      "============================================================\n",
      "BFS APPROACH:\n",
      "============================================================\n",
      "\n",
      "Depth 1: Exploring 1 nodes...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Generated 2 candidates, kept 2\n",
      "    Score 0.50: We could implement 1 of each but that's boring....\n",
      "    Score 0.50: So I implemented 2 different future actions and th...\n",
      "\n",
      "Depth 2: Exploring 2 nodes...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Generated 4 candidates, kept 2\n",
      "    Score 0.50: 4....\n",
      "    Score 0.50: 5....\n",
      "\n",
      "Nodes explored: 7\n",
      "\n",
      "============================================================\n",
      "DFS APPROACH:\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nodes explored: 4\n"
     ]
    }
   ],
   "source": [
    "# Compare BFS vs DFS\n",
    "problem = \"A store has 50 items. They sell 15 and receive 20 more. How many items do they have?\"\n",
    "\n",
    "print(f\"Problem: {problem}\")\n",
    "print(f\"Correct answer: 50 - 15 + 20 = 55\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BFS APPROACH:\")\n",
    "print(\"=\"*60)\n",
    "bfs_result = tot_bfs.solve(problem)\n",
    "print(f\"\\nNodes explored: {bfs_result['nodes_explored']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DFS APPROACH:\")\n",
    "print(\"=\"*60)\n",
    "dfs_result = tot_dfs.solve(problem)\n",
    "print(f\"\\nNodes explored: {dfs_result['nodes_explored']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## A Simpler Approach: Prompt-Based ToT\n",
    "\n",
    "The full ToT framework with explicit search algorithms is powerful but complex. There's a simpler version that works surprisingly well:\n",
    "\n",
    "Just... ask the model to do it!\n",
    "\n",
    "The idea (from Hulbert, 2023): prompt the model to imagine multiple experts, each contributing one step, with explicit backtracking.\n",
    "\n",
    "```\n",
    "Imagine three different experts are answering this question.\n",
    "All experts will write down 1 step of their thinking,\n",
    "then share it with the group.\n",
    "Then all experts will go on to the next step, etc.\n",
    "If any expert realizes they're wrong at any point then they leave.\n",
    "```\n",
    "\n",
    "This encodes the ToT idea entirely in the prompt!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T05:03:54.802178Z",
     "iopub.status.busy": "2025-12-10T05:03:54.802101Z",
     "iopub.status.idle": "2025-12-10T05:03:57.276329Z",
     "shell.execute_reply": "2025-12-10T05:03:57.275998Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PROMPT-BASED TREE OF THOUGHTS\n",
      "============================================================\n",
      "Problem: If I have 3 apples and buy 2 bags with 4 apples each, how many apples do I have?\n",
      "Correct: 3 + 2×4 = 11\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 per bag. Expert 2: 2 per bag. Expert 3: 4 per bag.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def prompt_based_tot(problem: str, n_experts: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Tree of Thoughts through clever prompting.\n",
    "    \n",
    "    No explicit search algorithm — just ask the model to simulate\n",
    "    multiple reasoning paths with self-critique.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"Imagine {n_experts} different experts are answering this question.\n",
    "All experts will write down 1 step of their thinking, then share it with the group.\n",
    "Then all experts will go on to the next step, etc.\n",
    "If any expert realizes they're wrong at any point, they leave.\n",
    "Continue until only one expert remains or all agree on the answer.\n",
    "\n",
    "Question: {problem}\n",
    "\n",
    "Expert 1:\"\"\"\n",
    "    \n",
    "    response = generate_text(prompt, max_new_tokens=300, temperature=0.7)\n",
    "    return prompt + response\n",
    "\n",
    "\n",
    "# Test prompt-based ToT\n",
    "problem = \"If I have 3 apples and buy 2 bags with 4 apples each, how many apples do I have?\"\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PROMPT-BASED TREE OF THOUGHTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Problem: {problem}\")\n",
    "print(f\"Correct: 3 + 2×4 = 11\")\n",
    "print(\"\\n\" + \"-\"*60 + \"\\n\")\n",
    "\n",
    "result = prompt_based_tot(problem, n_experts=3)\n",
    "# Just show the response part\n",
    "print(result.split(\"Expert 1:\")[1] if \"Expert 1:\" in result else result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## When to Use ToT\n",
    "\n",
    "Tree of Thoughts shines in specific scenarios:\n",
    "\n",
    "### Good for ToT:\n",
    "- **Planning problems** — Multiple strategies, some better than others\n",
    "- **Creative tasks** — Brainstorming with refinement\n",
    "- **Puzzles** — Clear win/lose states, backtracking helps\n",
    "- **Math with multiple approaches** — Different paths to same answer\n",
    "\n",
    "### Overkill for ToT:\n",
    "- **Simple factual questions** — No need for exploration\n",
    "- **Single-step problems** — Tree is trivial\n",
    "- **Time-sensitive applications** — Exploration takes time\n",
    "\n",
    "### Compared to Self-Consistency:\n",
    "- **ToT**: Smart exploration, can backtrack, uses evaluation\n",
    "- **Self-Consistency**: Dumb sampling, just vote on final answers\n",
    "\n",
    "ToT is more powerful but more complex. Self-consistency is simpler but wastes compute exploring bad paths."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## Benchmark Results\n",
    "\n",
    "From the original ToT paper (Yao et al., 2023):\n",
    "\n",
    "| Task | Standard | CoT | CoT-SC | ToT |\n",
    "|------|----------|-----|--------|-----|\n",
    "| Game of 24 | 7.3% | 4.0% | 9.0% | **74%** |\n",
    "| Creative Writing (coherence) | 6.2 | 6.9 | 7.0 | **7.6** |\n",
    "| Mini Crosswords | 4.4% | 15.6% | 16.4% | **60%** |\n",
    "\n",
    "(Using GPT-4)\n",
    "\n",
    "The Game of 24 result is striking: from 4% with CoT to 74% with ToT! That's the power of exploration and backtracking.\n",
    "\n",
    "But note: ToT uses many more API calls. The paper reports ~100 LLM calls per problem for Game of 24. That's 100× the cost of single-shot prompting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## What We've Learned\n",
    "\n",
    "Tree of Thoughts extends chain-of-thought reasoning:\n",
    "\n",
    "1. **Branch**: Generate multiple candidate thoughts at each step\n",
    "2. **Evaluate**: Score each candidate (self-evaluation or heuristics)\n",
    "3. **Search**: Use BFS or DFS to explore the tree\n",
    "4. **Prune**: Abandon low-scoring branches early\n",
    "5. **Backtrack**: When stuck, try different paths\n",
    "\n",
    "Key trade-offs:\n",
    "- **BFS**: Thorough but memory-intensive\n",
    "- **DFS**: Efficient but might miss good solutions\n",
    "- **Prompt-based**: Simple but less controllable\n",
    "\n",
    "When evaluation is unreliable (the model can't score its own thoughts well), ToT becomes less useful. That's why the next section on **Process Reward Models** is so important—we'll train a dedicated model to evaluate reasoning steps.\n",
    "\n",
    "**Next up:** Process Reward Models — training verifiers to score each step"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}