{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Process Reward Models\n",
    "\n",
    "In the Fine-Tuning section, we built reward models that score complete responses. Give it a prompt and response, get a number: \"this response is good\" or \"this response is bad.\"\n",
    "\n",
    "That's an **Outcome Reward Model (ORM)**. It judges the destination, not the journey.\n",
    "\n",
    "But for reasoning, the journey matters. A correct answer reached through flawed logic is a ticking time bomb. A **Process Reward Model (PRM)** scores each step along the way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## ORM vs PRM\n",
    "\n",
    "Consider this math solution:\n",
    "\n",
    "```\n",
    "Problem: What's 15% of 80?\n",
    "\n",
    "Step 1: 15% means 15/100 = 0.15          \u2713 (correct)\n",
    "Step 2: Multiply: 0.15 \u00d7 80               \u2713 (correct approach)\n",
    "Step 3: 0.15 \u00d7 80 = 15 \u00d7 8 = 120         \u2717 (wrong! should be 12)\n",
    "Step 4: Wait, that's too high. Let me check: 0.15 \u00d7 80 = 12  \u2713\n",
    "Final answer: 12                          \u2713 (correct)\n",
    "```\n",
    "\n",
    "**ORM sees**: Final answer is 12. Correct! Score: high.\n",
    "\n",
    "**PRM sees**: Step 3 was wrong, but Step 4 caught and fixed it. Scores:\n",
    "- Step 1: 1.0 (correct)\n",
    "- Step 2: 1.0 (correct)\n",
    "- Step 3: 0.0 (error!)\n",
    "- Step 4: 1.0 (good correction)\n",
    "\n",
    "The PRM gives us *much* more information. We know exactly where the reasoning went wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Why PRMs Matter\n",
    "\n",
    "From OpenAI's \"Let's Verify Step by Step\" paper:\n",
    "\n",
    "> Process supervision has several alignment advantages over outcome supervision. It directly rewards the model for following an aligned chain-of-thought, since each step in the process receives precise supervision.\n",
    "\n",
    "Three key benefits:\n",
    "\n",
    "### 1. Better Error Detection\n",
    "ORMs can be fooled by wrong answers that \"look right.\" PRMs catch logical errors even when the final answer happens to be correct.\n",
    "\n",
    "### 2. More Precise Feedback\n",
    "When training with RL, an ORM says \"this whole response was good/bad.\" A PRM says \"this specific step was the problem.\" Dense rewards lead to faster, more stable learning.\n",
    "\n",
    "### 3. Interpretability\n",
    "You can *see* where the model's reasoning breaks down. Useful for debugging and building trust.\n",
    "\n",
    "The numbers: on the MATH benchmark, OpenAI's PRM achieved **78.2%** accuracy vs **72.4%** for their best ORM. A significant gap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T21:23:46.625500Z",
     "iopub.status.busy": "2025-12-10T21:23:46.625424Z",
     "iopub.status.idle": "2025-12-10T21:23:49.648644Z",
     "shell.execute_reply": "2025-12-10T21:23:49.648182Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Qwen/Qwen2.5-0.5B as base for PRM...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded on cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load base model for our PRM\n",
    "# We'll use the base Qwen model (not instruct) as the backbone\n",
    "model_name = \"Qwen/Qwen2.5-0.5B\"\n",
    "print(f\"Loading {model_name} as base for PRM...\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "base_model = AutoModel.from_pretrained(model_name, dtype=\"auto\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "base_model = base_model.to(device)\n",
    "\n",
    "print(f\"Loaded on {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## PRM Architecture\n",
    "\n",
    "A PRM is similar to an ORM (from our reward modeling notebook), but with one key difference: it outputs a score for *each step*, not just one score for the whole response.\n",
    "\n",
    "The architecture:\n",
    "\n",
    "```\n",
    "Input: [problem] [step 1] [step 2] ... [step N]\n",
    "              \u2502       \u2502        \u2502           \u2502\n",
    "              \u25bc       \u25bc        \u25bc           \u25bc\n",
    "       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "       \u2502          Base Language Model         \u2502\n",
    "       \u2502         (GPT, LLaMA, etc.)          \u2502\n",
    "       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "              \u2502       \u2502        \u2502           \u2502\n",
    "              \u25bc       \u25bc        \u25bc           \u25bc\n",
    "            h_0     h_1      h_2         h_N   (hidden states)\n",
    "                      \u2502        \u2502           \u2502\n",
    "                      \u25bc        \u25bc           \u25bc\n",
    "                   score_1  score_2    score_N  (via value head)\n",
    "```\n",
    "\n",
    "We need to:\n",
    "1. Identify where each step *ends* in the token sequence\n",
    "2. Extract the hidden state at those positions\n",
    "3. Run each through a value head to get step scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T21:23:49.649916Z",
     "iopub.status.busy": "2025-12-10T21:23:49.649699Z",
     "iopub.status.idle": "2025-12-10T21:23:49.656471Z",
     "shell.execute_reply": "2025-12-10T21:23:49.656147Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRM created with 897 value head parameters\n"
     ]
    }
   ],
   "source": [
    "class ProcessRewardModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Process Reward Model \u2014 scores each reasoning step.\n",
    "    \n",
    "    Unlike an ORM which gives one score for the whole response,\n",
    "    a PRM gives a score for each step in the reasoning chain.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, base_model, hidden_size: int, \n",
    "                 step_separator: str = \"\\n\"):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.step_separator = step_separator\n",
    "        \n",
    "        # Value head: maps hidden state \u2192 step score\n",
    "        # Use same dtype as base model for compatibility\n",
    "        self.value_head = nn.Sequential(\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "    \n",
    "    def find_step_positions(self, input_ids: torch.Tensor,\n",
    "                            tokenizer) -> List[List[int]]:\n",
    "        \"\"\"\n",
    "        Find the token positions where each step ends.\n",
    "        \n",
    "        We look for newline tokens (or whatever separator is used)\n",
    "        and return their positions.\n",
    "        \n",
    "        Args:\n",
    "            input_ids: Token IDs, shape (batch, seq_len)\n",
    "            tokenizer: The tokenizer (to find separator token)\n",
    "        \n",
    "        Returns:\n",
    "            List of lists: step end positions for each sequence\n",
    "        \"\"\"\n",
    "        # Get token ID for the separator\n",
    "        sep_ids = tokenizer.encode(self.step_separator, add_special_tokens=False)\n",
    "        \n",
    "        batch_positions = []\n",
    "        for seq in input_ids:\n",
    "            positions = []\n",
    "            for i, token_id in enumerate(seq):\n",
    "                if token_id.item() in sep_ids:\n",
    "                    positions.append(i)\n",
    "            # Also include the last position (end of sequence)\n",
    "            seq_len = (seq != tokenizer.pad_token_id).sum().item()\n",
    "            if seq_len - 1 not in positions:\n",
    "                positions.append(seq_len - 1)\n",
    "            batch_positions.append(positions)\n",
    "        \n",
    "        return batch_positions\n",
    "    \n",
    "    def forward(self, input_ids: torch.Tensor, \n",
    "                attention_mask: torch.Tensor,\n",
    "                tokenizer) -> Tuple[torch.Tensor, List[List[int]]]:\n",
    "        \"\"\"\n",
    "        Compute step-level scores.\n",
    "        \n",
    "        Args:\n",
    "            input_ids: Token IDs\n",
    "            attention_mask: Attention mask\n",
    "            tokenizer: Tokenizer for finding step boundaries\n",
    "        \n",
    "        Returns:\n",
    "            (step_scores, step_positions)\n",
    "            step_scores is a list of tensors (one per sequence)\n",
    "        \"\"\"\n",
    "        # Get hidden states from base model\n",
    "        outputs = self.base_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        hidden_states = outputs.last_hidden_state  # (batch, seq, hidden)\n",
    "        \n",
    "        # Find step positions\n",
    "        step_positions = self.find_step_positions(input_ids, tokenizer)\n",
    "        \n",
    "        # Extract hidden states at step positions and compute scores\n",
    "        all_scores = []\n",
    "        for batch_idx, positions in enumerate(step_positions):\n",
    "            step_hidden = hidden_states[batch_idx, positions, :]  # (n_steps, hidden)\n",
    "            # Cast to float32 for value head computation, then back\n",
    "            scores = self.value_head(step_hidden.float()).squeeze(-1)  # (n_steps,)\n",
    "            all_scores.append(scores)\n",
    "        \n",
    "        return all_scores, step_positions\n",
    "\n",
    "\n",
    "# Create PRM\n",
    "prm = ProcessRewardModel(\n",
    "    base_model=base_model,\n",
    "    hidden_size=base_model.config.hidden_size,\n",
    "    step_separator=\"\\n\"\n",
    ")\n",
    "prm = prm.to(device)\n",
    "\n",
    "print(f\"PRM created with {sum(p.numel() for p in prm.value_head.parameters()):,} value head parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T21:23:49.657224Z",
     "iopub.status.busy": "2025-12-10T21:23:49.657146Z",
     "iopub.status.idle": "2025-12-10T21:23:50.242084Z",
     "shell.execute_reply": "2025-12-10T21:23:50.241732Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test input:\n",
      "Problem: What is 2 + 3?\n",
      "Step 1: I need to add 2 and 3.\n",
      "Step 2: 2 + 3 = 5.\n",
      "Answer: 5\n",
      "\n",
      "==================================================\n",
      "\n",
      "Step scores (before training - essentially random):\n",
      "  Step 0: -4.4805 \u2014 Problem: What is 2 + 3?...\n"
     ]
    }
   ],
   "source": [
    "# Test the PRM on example reasoning\n",
    "test_text = \"\"\"Problem: What is 2 + 3?\n",
    "Step 1: I need to add 2 and 3.\n",
    "Step 2: 2 + 3 = 5.\n",
    "Answer: 5\"\"\"\n",
    "\n",
    "inputs = tokenizer(test_text, return_tensors=\"pt\", padding=True).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    scores, positions = prm(\n",
    "        inputs[\"input_ids\"], \n",
    "        inputs[\"attention_mask\"],\n",
    "        tokenizer\n",
    "    )\n",
    "\n",
    "print(\"Test input:\")\n",
    "print(test_text)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\nStep scores (before training - essentially random):\")\n",
    "\n",
    "# Split text into steps for display\n",
    "steps = test_text.split('\\n')\n",
    "for i, (step, score) in enumerate(zip(steps, scores[0])):\n",
    "    print(f\"  Step {i}: {score.item():.4f} \u2014 {step[:40]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Training a PRM\n",
    "\n",
    "Training data for PRMs looks different from ORMs. Instead of:\n",
    "```\n",
    "(prompt, response_good, response_bad)\n",
    "```\n",
    "\n",
    "We need:\n",
    "```\n",
    "(prompt, solution_steps, step_labels)\n",
    "```\n",
    "\n",
    "Where `step_labels` marks each step as correct (+1) or incorrect (-1).\n",
    "\n",
    "### Where does this data come from?\n",
    "\n",
    "1. **Human annotation**: Pay people to label each step (expensive but high quality)\n",
    "2. **Automatic labeling**: Use final answer correctness + heuristics\n",
    "3. **Monte Carlo estimation**: Sample many continuations from each step, see which lead to correct answers\n",
    "\n",
    "OpenAI's PRM800K dataset used human annotation \u2014 800,000 step-level labels. That's a lot of work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T21:23:50.243254Z",
     "iopub.status.busy": "2025-12-10T21:23:50.243172Z",
     "iopub.status.idle": "2025-12-10T21:23:50.246219Z",
     "shell.execute_reply": "2025-12-10T21:23:50.245862Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 4 training samples\n",
      "\n",
      "Example sample:\n",
      "Problem: What is 8 \u00d7 3?\n",
      "Step 1: I need to multiply 8 by 3.\n",
      "Step 2: 8 \u00d7 3 = 21.\n",
      "Step 3: The answer is 21.\n",
      "Labels: [1, -1, -1]\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class PRMTrainingSample:\n",
    "    \"\"\"A training sample for the Process Reward Model.\"\"\"\n",
    "    problem: str\n",
    "    steps: List[str]\n",
    "    labels: List[int]  # +1 for correct, -1 for incorrect\n",
    "    \n",
    "    def to_text(self) -> str:\n",
    "        \"\"\"Convert to text format.\"\"\"\n",
    "        text = f\"Problem: {self.problem}\\n\"\n",
    "        for i, step in enumerate(self.steps):\n",
    "            text += f\"Step {i+1}: {step}\\n\"\n",
    "        return text.strip()\n",
    "\n",
    "\n",
    "# Create some synthetic training data\n",
    "# In practice, you'd load this from a dataset like PRM800K\n",
    "\n",
    "train_samples = [\n",
    "    PRMTrainingSample(\n",
    "        problem=\"What is 5 + 7?\",\n",
    "        steps=[\n",
    "            \"I need to add 5 and 7.\",\n",
    "            \"5 + 7 = 12.\",\n",
    "            \"The answer is 12.\"\n",
    "        ],\n",
    "        labels=[1, 1, 1]  # All correct\n",
    "    ),\n",
    "    PRMTrainingSample(\n",
    "        problem=\"What is 8 \u00d7 3?\",\n",
    "        steps=[\n",
    "            \"I need to multiply 8 by 3.\",\n",
    "            \"8 \u00d7 3 = 21.\",  # Wrong!\n",
    "            \"The answer is 21.\"\n",
    "        ],\n",
    "        labels=[1, -1, -1]  # Step 2 is wrong, so step 3 is also wrong\n",
    "    ),\n",
    "    PRMTrainingSample(\n",
    "        problem=\"What is 10 - 4?\",\n",
    "        steps=[\n",
    "            \"I need to subtract 4 from 10.\",\n",
    "            \"10 - 4 = 6.\",\n",
    "            \"The answer is 6.\"\n",
    "        ],\n",
    "        labels=[1, 1, 1]  # All correct\n",
    "    ),\n",
    "    PRMTrainingSample(\n",
    "        problem=\"What is 15 / 3?\",\n",
    "        steps=[\n",
    "            \"I need to divide 15 by 3.\",\n",
    "            \"15 / 3 = 3.\",  # Wrong! Should be 5\n",
    "            \"Wait, let me recalculate: 15 / 3 = 5.\",\n",
    "            \"The answer is 5.\"\n",
    "        ],\n",
    "        labels=[1, -1, 1, 1]  # Caught the error\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(f\"Created {len(train_samples)} training samples\")\n",
    "print(\"\\nExample sample:\")\n",
    "print(train_samples[1].to_text())\n",
    "print(f\"Labels: {train_samples[1].labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## The PRM Loss Function\n",
    "\n",
    "How do we train the PRM? We could use simple binary cross-entropy on each step:\n",
    "\n",
    "$$\\mathcal{L} = -\\sum_{i=1}^{N} \\left[ y_i \\log(\\sigma(s_i)) + (1 - y_i) \\log(1 - \\sigma(s_i)) \\right]$$\n",
    "\n",
    "Where:\n",
    "- $s_i$ is the raw score for step $i$\n",
    "- $y_i$ is the label (1 for correct, 0 for incorrect)\n",
    "- $\\sigma$ is the sigmoid function\n",
    "\n",
    "But there's a subtlety. Steps aren't independent! If step 3 is wrong, everything after it is probably wrong too. We might want to:\n",
    "\n",
    "1. Weight later steps more heavily (they're harder to get right)\n",
    "2. Mask steps after the first error (they're \"tainted\")\n",
    "3. Use a ranking loss between correct and incorrect steps\n",
    "\n",
    "For simplicity, we'll use weighted binary cross-entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T21:23:50.247002Z",
     "iopub.status.busy": "2025-12-10T21:23:50.246925Z",
     "iopub.status.idle": "2025-12-10T21:23:50.274600Z",
     "shell.execute_reply": "2025-12-10T21:23:50.274266Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example loss: 0.4665\n"
     ]
    }
   ],
   "source": [
    "def prm_loss(step_scores: List[torch.Tensor], \n",
    "             step_labels: List[List[int]],\n",
    "             pos_weight: float = 1.0) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute PRM training loss.\n",
    "    \n",
    "    Uses binary cross-entropy for each step.\n",
    "    \n",
    "    Args:\n",
    "        step_scores: List of score tensors (one per sequence)\n",
    "        step_labels: List of label lists (+1 correct, -1 incorrect)\n",
    "        pos_weight: Weight for positive examples\n",
    "    \n",
    "    Returns:\n",
    "        Average loss across all steps\n",
    "    \"\"\"\n",
    "    total_loss = 0.0\n",
    "    n_steps = 0\n",
    "    \n",
    "    for scores, labels in zip(step_scores, step_labels):\n",
    "        # Convert labels from [-1, 1] to [0, 1]\n",
    "        targets = torch.tensor(\n",
    "            [(l + 1) / 2 for l in labels], \n",
    "            device=scores.device,\n",
    "            dtype=torch.float\n",
    "        )\n",
    "        \n",
    "        # Handle case where we have more positions than labels\n",
    "        n = min(len(scores), len(targets))\n",
    "        scores = scores[:n]\n",
    "        targets = targets[:n]\n",
    "        \n",
    "        # Binary cross-entropy loss\n",
    "        # We apply sigmoid inside BCEWithLogitsLoss for numerical stability\n",
    "        loss = F.binary_cross_entropy_with_logits(\n",
    "            scores, targets,\n",
    "            pos_weight=torch.tensor([pos_weight], device=scores.device)\n",
    "        )\n",
    "        \n",
    "        total_loss += loss * n\n",
    "        n_steps += n\n",
    "    \n",
    "    return total_loss / max(n_steps, 1)\n",
    "\n",
    "\n",
    "# Test the loss function\n",
    "dummy_scores = [torch.tensor([0.5, -0.3, 0.8], device=device)]\n",
    "dummy_labels = [[1, -1, 1]]\n",
    "\n",
    "loss = prm_loss(dummy_scores, dummy_labels)\n",
    "print(f\"Example loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T21:23:50.275508Z",
     "iopub.status.busy": "2025-12-10T21:23:50.275437Z",
     "iopub.status.idle": "2025-12-10T21:23:53.012422Z",
     "shell.execute_reply": "2025-12-10T21:23:53.012010Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training PRM...\n",
      "========================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 0.1757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss = 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss = 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Loss = 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Loss = 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "def train_prm_epoch(prm: ProcessRewardModel, \n",
    "                    samples: List[PRMTrainingSample],\n",
    "                    optimizer: torch.optim.Optimizer,\n",
    "                    tokenizer) -> float:\n",
    "    \"\"\"\n",
    "    Train PRM for one epoch.\n",
    "    \n",
    "    Args:\n",
    "        prm: The process reward model\n",
    "        samples: Training samples\n",
    "        optimizer: The optimizer\n",
    "        tokenizer: Tokenizer\n",
    "    \n",
    "    Returns:\n",
    "        Average loss for the epoch\n",
    "    \"\"\"\n",
    "    prm.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for sample in samples:\n",
    "        # Tokenize\n",
    "        text = sample.to_text()\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", padding=True).to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        step_scores, _ = prm(\n",
    "            inputs[\"input_ids\"],\n",
    "            inputs[\"attention_mask\"],\n",
    "            tokenizer\n",
    "        )\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = prm_loss(step_scores, [sample.labels])\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(samples)\n",
    "\n",
    "\n",
    "# Train for a few epochs\n",
    "optimizer = torch.optim.AdamW(prm.parameters(), lr=1e-4)\n",
    "\n",
    "print(\"Training PRM...\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "for epoch in range(10):\n",
    "    loss = train_prm_epoch(prm, train_samples, optimizer, tokenizer)\n",
    "    if epoch % 2 == 0:\n",
    "        print(f\"Epoch {epoch+1}: Loss = {loss:.4f}\")\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T21:23:53.013497Z",
     "iopub.status.busy": "2025-12-10T21:23:53.013405Z",
     "iopub.status.idle": "2025-12-10T21:23:53.039130Z",
     "shell.execute_reply": "2025-12-10T21:23:53.038828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing trained PRM:\n",
      "============================================================\n",
      "\n",
      "Problem: What is 6 + 4?\n",
      "  Step 1: P(correct)=1.00 [\u2713] I need to add 6 and 4....\n",
      "\n",
      "Problem: What is 9 \u00d7 2?\n",
      "  Step 1: P(correct)=1.00 [\u2713] I need to multiply 9 by 2....\n"
     ]
    }
   ],
   "source": [
    "# Test the trained PRM\n",
    "prm.eval()\n",
    "\n",
    "test_samples = [\n",
    "    # Correct solution\n",
    "    PRMTrainingSample(\n",
    "        problem=\"What is 6 + 4?\",\n",
    "        steps=[\"I need to add 6 and 4.\", \"6 + 4 = 10.\", \"The answer is 10.\"],\n",
    "        labels=[1, 1, 1]\n",
    "    ),\n",
    "    # Incorrect solution\n",
    "    PRMTrainingSample(\n",
    "        problem=\"What is 9 \u00d7 2?\",\n",
    "        steps=[\"I need to multiply 9 by 2.\", \"9 \u00d7 2 = 16.\", \"The answer is 16.\"],\n",
    "        labels=[1, -1, -1]\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(\"Testing trained PRM:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for sample in test_samples:\n",
    "    text = sample.to_text()\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        scores, _ = prm(inputs[\"input_ids\"], inputs[\"attention_mask\"], tokenizer)\n",
    "    \n",
    "    print(f\"\\nProblem: {sample.problem}\")\n",
    "    for i, (step, score, label) in enumerate(zip(sample.steps, scores[0], sample.labels)):\n",
    "        prob = torch.sigmoid(score).item()\n",
    "        correct = \"\u2713\" if label == 1 else \"\u2717\"\n",
    "        print(f\"  Step {i+1}: P(correct)={prob:.2f} [{correct}] {step[:35]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Aggregating Step Scores\n",
    "\n",
    "Once we have step-level scores, we need to aggregate them into an overall solution score. Common approaches:\n",
    "\n",
    "### 1. Minimum (most conservative)\n",
    "$$\\text{score}_{\\min} = \\min_i P(\\text{step}_i \\text{ is correct})$$\n",
    "\n",
    "If any step is wrong, the whole solution is suspicious.\n",
    "\n",
    "### 2. Product (independence assumption)\n",
    "$$\\text{score}_{\\text{prod}} = \\prod_i P(\\text{step}_i \\text{ is correct})$$\n",
    "\n",
    "Probability that *all* steps are correct, assuming independence.\n",
    "\n",
    "### 3. Last step\n",
    "$$\\text{score}_{\\text{last}} = P(\\text{step}_N \\text{ is correct})$$\n",
    "\n",
    "If the final step is right, earlier steps were probably right too.\n",
    "\n",
    "### 4. Weighted average\n",
    "$$\\text{score}_{\\text{avg}} = \\sum_i w_i \\cdot P(\\text{step}_i \\text{ is correct})$$\n",
    "\n",
    "With weights decreasing for later steps (errors compound)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T21:23:53.040191Z",
     "iopub.status.busy": "2025-12-10T21:23:53.040084Z",
     "iopub.status.idle": "2025-12-10T21:23:53.042947Z",
     "shell.execute_reply": "2025-12-10T21:23:53.042664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step probabilities: ['0.95', '0.90', '0.30', '0.85']\n",
      "\n",
      "Aggregation methods:\n",
      "  min:  0.300  \u2190 catches the bad step\n",
      "  prod: 0.218  \u2190 heavily penalized\n",
      "  last: 0.850  \u2190 misses the error!\n",
      "  mean: 0.750  \u2190 smoothed\n"
     ]
    }
   ],
   "source": [
    "def aggregate_prm_scores(step_probs: torch.Tensor, \n",
    "                         method: str = \"min\") -> float:\n",
    "    \"\"\"\n",
    "    Aggregate step-level probabilities into a solution score.\n",
    "    \n",
    "    Args:\n",
    "        step_probs: Probability of each step being correct\n",
    "        method: Aggregation method (\"min\", \"prod\", \"last\", \"mean\")\n",
    "    \n",
    "    Returns:\n",
    "        Overall solution score\n",
    "    \"\"\"\n",
    "    if len(step_probs) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    if method == \"min\":\n",
    "        return step_probs.min().item()\n",
    "    elif method == \"prod\":\n",
    "        return step_probs.prod().item()\n",
    "    elif method == \"last\":\n",
    "        return step_probs[-1].item()\n",
    "    elif method == \"mean\":\n",
    "        return step_probs.mean().item()\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "\n",
    "# Compare aggregation methods\n",
    "# Simulated step probabilities: [0.95, 0.90, 0.30, 0.85]\n",
    "# (Step 3 is suspicious)\n",
    "\n",
    "step_probs = torch.tensor([0.95, 0.90, 0.30, 0.85])\n",
    "\n",
    "print(\"Step probabilities:\", [f\"{p:.2f}\" for p in step_probs.tolist()])\n",
    "print(\"\\nAggregation methods:\")\n",
    "print(f\"  min:  {aggregate_prm_scores(step_probs, 'min'):.3f}  \u2190 catches the bad step\")\n",
    "print(f\"  prod: {aggregate_prm_scores(step_probs, 'prod'):.3f}  \u2190 heavily penalized\")\n",
    "print(f\"  last: {aggregate_prm_scores(step_probs, 'last'):.3f}  \u2190 misses the error!\")\n",
    "print(f\"  mean: {aggregate_prm_scores(step_probs, 'mean'):.3f}  \u2190 smoothed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Using PRMs for Verification\n",
    "\n",
    "Now let's put it together: use the PRM to verify reasoning chains and select the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T21:23:53.043953Z",
     "iopub.status.busy": "2025-12-10T21:23:53.043867Z",
     "iopub.status.idle": "2025-12-10T21:23:53.047136Z",
     "shell.execute_reply": "2025-12-10T21:23:53.046910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRM Verifier ready.\n"
     ]
    }
   ],
   "source": [
    "class PRMVerifier:\n",
    "    \"\"\"\n",
    "    Use a PRM to verify and rank reasoning chains.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, prm: ProcessRewardModel, tokenizer,\n",
    "                 aggregation: str = \"min\"):\n",
    "        self.prm = prm\n",
    "        self.tokenizer = tokenizer\n",
    "        self.aggregation = aggregation\n",
    "    \n",
    "    def score_solution(self, problem: str, steps: List[str]) -> dict:\n",
    "        \"\"\"\n",
    "        Score a complete solution.\n",
    "        \n",
    "        Returns step scores and aggregated score.\n",
    "        \"\"\"\n",
    "        # Format as text\n",
    "        text = f\"Problem: {problem}\\n\"\n",
    "        for i, step in enumerate(steps):\n",
    "            text += f\"Step {i+1}: {step}\\n\"\n",
    "        \n",
    "        # Tokenize and score\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", padding=True)\n",
    "        inputs = {k: v.to(next(self.prm.parameters()).device) for k, v in inputs.items()}\n",
    "        \n",
    "        self.prm.eval()\n",
    "        with torch.no_grad():\n",
    "            scores, _ = self.prm(\n",
    "                inputs[\"input_ids\"],\n",
    "                inputs[\"attention_mask\"],\n",
    "                self.tokenizer\n",
    "            )\n",
    "        \n",
    "        # Convert to probabilities\n",
    "        step_probs = torch.sigmoid(scores[0][:len(steps)])\n",
    "        overall_score = aggregate_prm_scores(step_probs, self.aggregation)\n",
    "        \n",
    "        return {\n",
    "            \"step_probs\": step_probs.tolist(),\n",
    "            \"overall_score\": overall_score,\n",
    "            \"weakest_step\": step_probs.argmin().item(),\n",
    "            \"weakest_prob\": step_probs.min().item()\n",
    "        }\n",
    "    \n",
    "    def rank_solutions(self, problem: str, \n",
    "                       solutions: List[List[str]]) -> List[dict]:\n",
    "        \"\"\"\n",
    "        Rank multiple solutions by PRM score.\n",
    "        \n",
    "        Args:\n",
    "            problem: The problem statement\n",
    "            solutions: List of step lists\n",
    "        \n",
    "        Returns:\n",
    "            Ranked list of (solution_idx, score_info) dicts\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        for i, steps in enumerate(solutions):\n",
    "            score_info = self.score_solution(problem, steps)\n",
    "            score_info[\"solution_idx\"] = i\n",
    "            score_info[\"steps\"] = steps\n",
    "            results.append(score_info)\n",
    "        \n",
    "        # Sort by overall score (descending)\n",
    "        results.sort(key=lambda x: x[\"overall_score\"], reverse=True)\n",
    "        return results\n",
    "\n",
    "\n",
    "# Create verifier\n",
    "verifier = PRMVerifier(prm, tokenizer, aggregation=\"min\")\n",
    "print(\"PRM Verifier ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T21:23:53.048116Z",
     "iopub.status.busy": "2025-12-10T21:23:53.048034Z",
     "iopub.status.idle": "2025-12-10T21:23:53.100070Z",
     "shell.execute_reply": "2025-12-10T21:23:53.099697Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem: What is 7 \u00d7 8?\n",
      "\n",
      "Ranking 3 different solutions...\n",
      "============================================================\n",
      "\n",
      "Rank 1: Solution 1\n",
      "  Overall score: 1.000\n",
      "  Step probs: ['1.00']\n",
      "  Weakest: Step 1 (p=1.00)\n",
      "  Steps: I need to multiply 7 by 8....\n",
      "\n",
      "Rank 2: Solution 2\n",
      "  Overall score: 1.000\n",
      "  Step probs: ['1.00']\n",
      "  Weakest: Step 1 (p=1.00)\n",
      "  Steps: I need to multiply 7 by 8....\n",
      "\n",
      "Rank 3: Solution 3\n",
      "  Overall score: 1.000\n",
      "  Step probs: ['1.00']\n",
      "  Weakest: Step 1 (p=1.00)\n",
      "  Steps: I need to multiply 7 by 8....\n"
     ]
    }
   ],
   "source": [
    "# Test: rank multiple solutions to the same problem\n",
    "problem = \"What is 7 \u00d7 8?\"\n",
    "\n",
    "solutions = [\n",
    "    # Solution 1: Correct\n",
    "    [\n",
    "        \"I need to multiply 7 by 8.\",\n",
    "        \"7 \u00d7 8 = 56.\",\n",
    "        \"The answer is 56.\"\n",
    "    ],\n",
    "    # Solution 2: Wrong arithmetic\n",
    "    [\n",
    "        \"I need to multiply 7 by 8.\",\n",
    "        \"7 \u00d7 8 = 54.\",  # Wrong!\n",
    "        \"The answer is 54.\"\n",
    "    ],\n",
    "    # Solution 3: Wrong but self-corrected\n",
    "    [\n",
    "        \"I need to multiply 7 by 8.\",\n",
    "        \"7 \u00d7 8 = 54.\",  # Wrong\n",
    "        \"Wait, let me check: 7 \u00d7 8 = 56.\",  # Corrected\n",
    "        \"The answer is 56.\"\n",
    "    ],\n",
    "]\n",
    "\n",
    "print(f\"Problem: {problem}\")\n",
    "print(\"\\nRanking 3 different solutions...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "ranked = verifier.rank_solutions(problem, solutions)\n",
    "\n",
    "for rank, result in enumerate(ranked, 1):\n",
    "    print(f\"\\nRank {rank}: Solution {result['solution_idx'] + 1}\")\n",
    "    print(f\"  Overall score: {result['overall_score']:.3f}\")\n",
    "    print(f\"  Step probs: {[f'{p:.2f}' for p in result['step_probs']]}\")\n",
    "    print(f\"  Weakest: Step {result['weakest_step'] + 1} (p={result['weakest_prob']:.2f})\")\n",
    "    print(f\"  Steps: {result['steps'][0][:30]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## Visualizing PRM Scores\n",
    "\n",
    "One of the great things about PRMs is interpretability. Let's visualize where the model thinks errors might be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T21:23:53.101025Z",
     "iopub.status.busy": "2025-12-10T21:23:53.100927Z",
     "iopub.status.idle": "2025-12-10T21:23:53.161390Z",
     "shell.execute_reply": "2025-12-10T21:23:53.161015Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem: What is 12 / 4?\n",
      "(Correct answer: 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_prm_scores(steps: List[str], probs: List[float], \n",
    "                         title: str = \"PRM Step Scores\"):\n",
    "    \"\"\"\n",
    "    Visualize PRM scores for a solution.\n",
    "    \"\"\"\n",
    "    n_steps = len(steps)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, max(3, n_steps * 0.5)))\n",
    "    \n",
    "    # Create horizontal bar chart\n",
    "    y_pos = np.arange(n_steps)\n",
    "    colors = ['green' if p > 0.7 else 'orange' if p > 0.4 else 'red' for p in probs]\n",
    "    \n",
    "    bars = ax.barh(y_pos, probs, color=colors, alpha=0.7)\n",
    "    \n",
    "    # Add step labels\n",
    "    for i, (step, prob) in enumerate(zip(steps, probs)):\n",
    "        # Truncate long steps\n",
    "        step_text = step[:50] + \"...\" if len(step) > 50 else step\n",
    "        ax.text(0.02, i, step_text, va='center', fontsize=9)\n",
    "        ax.text(prob + 0.02, i, f\"{prob:.2f}\", va='center', fontsize=9)\n",
    "    \n",
    "    ax.set_xlim(0, 1.1)\n",
    "    ax.set_ylim(-0.5, n_steps - 0.5)\n",
    "    ax.set_xlabel(\"P(step is correct)\")\n",
    "    ax.set_ylabel(\"Step\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels([f\"Step {i+1}\" for i in range(n_steps)])\n",
    "    ax.invert_yaxis()  # Top step first\n",
    "    \n",
    "    # Add threshold line\n",
    "    ax.axvline(x=0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Visualize a solution with an error\n",
    "problem = \"What is 12 / 4?\"\n",
    "steps = [\n",
    "    \"I need to divide 12 by 4.\",\n",
    "    \"12 / 4 = 4.\",  # Wrong! Should be 3\n",
    "    \"The answer is 4.\"\n",
    "]\n",
    "\n",
    "result = verifier.score_solution(problem, steps)\n",
    "\n",
    "print(f\"Problem: {problem}\")\n",
    "print(f\"(Correct answer: 3)\")\n",
    "visualize_prm_scores(steps, result[\"step_probs\"], \n",
    "                     title=f\"PRM Analysis: {problem}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## What We've Learned\n",
    "\n",
    "Process Reward Models provide step-level supervision:\n",
    "\n",
    "1. **Architecture**: Base LM + value head, scoring at step boundaries\n",
    "2. **Training**: Binary classification on step correctness\n",
    "3. **Aggregation**: Combine step scores (min, product, mean, last)\n",
    "4. **Verification**: Rank solutions by PRM score\n",
    "\n",
    "Key insight from OpenAI:\n",
    "\n",
    "> Process supervision leads to significantly better performance, even when judged by outcomes.\n",
    "\n",
    "The math:\n",
    "$$\\mathcal{L} = -\\sum_{i=1}^{N} \\left[ y_i \\log(\\sigma(s_i)) + (1 - y_i) \\log(1 - \\sigma(s_i)) \\right]$$\n",
    "\n",
    "PRMs are essential for:\n",
    "- Guiding search (which path is promising?)\n",
    "- Best-of-N selection (which solution is most reliable?)\n",
    "- RLHF with dense rewards (step-level feedback)\n",
    "\n",
    "**Next up:** Best-of-N with verification \u2014 using PRMs to select the best solution from many candidates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "description": "Trains reward model to score individual reasoning steps rather than final answers."
 },
 "nbformat": 4,
 "nbformat_minor": 5
}