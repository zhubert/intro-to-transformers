{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. AdamW Optimizer\n",
    "\n",
    "**Using AdamW to update all parameters and complete the training step**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've computed gradients for every parameter in the model. Now we need to **use** those gradients to actually update the weights.\n",
    "\n",
    "We're using **AdamW**—the optimizer used to train GPT, LLaMA, and virtually every modern LLM. It's the industry standard for a reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Not Just Subtract the Gradient?\n",
    "\n",
    "You might think: \"We have gradients. Just do `θ = θ - lr * gradient` and we're done.\"\n",
    "\n",
    "That's **stochastic gradient descent (SGD)**, and it has problems:\n",
    "\n",
    "1. **Same learning rate for all parameters**—some need big updates, others small\n",
    "2. **No momentum**—can get stuck oscillating in valleys\n",
    "3. **Sensitive to learning rate**—too high diverges, too low is slow\n",
    "\n",
    "AdamW solves all of these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Is AdamW?\n",
    "\n",
    "AdamW combines three powerful ideas:\n",
    "\n",
    "1. **Adaptive learning rates**—each parameter gets its own rate based on gradient history\n",
    "2. **Momentum**—updates are smoothed using exponential moving averages\n",
    "3. **Weight decay**—regularization applied directly to parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# AdamW hyperparameters\n",
    "learning_rate = 0.001    # α: base learning rate\n",
    "beta1 = 0.9              # β₁: decay for first moment (momentum)\n",
    "beta2 = 0.999            # β₂: decay for second moment (adaptive LR)\n",
    "epsilon = 1e-8           # ε: numerical stability\n",
    "weight_decay = 0.01      # λ: L2 regularization strength\n",
    "t = 1                    # time step (first update)\n",
    "\n",
    "print(\"AdamW Hyperparameters:\")\n",
    "print(f\"  learning_rate (α) = {learning_rate}\")\n",
    "print(f\"  beta1 (β₁)        = {beta1}\")\n",
    "print(f\"  beta2 (β₂)        = {beta2}\")\n",
    "print(f\"  epsilon (ε)       = {epsilon}\")\n",
    "print(f\"  weight_decay (λ)  = {weight_decay}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The AdamW Algorithm\n",
    "\n",
    "For each parameter $\\theta$, AdamW maintains two **moment estimates**:\n",
    "\n",
    "1. **First moment** $m$—exponential moving average of gradients (momentum)\n",
    "2. **Second moment** $v$—exponential moving average of squared gradients\n",
    "\n",
    "### Step 1: Update Biased Moment Estimates\n",
    "\n",
    "$$m_t = \\beta_1 \\cdot m_{t-1} + (1 - \\beta_1) \\cdot g_t$$\n",
    "$$v_t = \\beta_2 \\cdot v_{t-1} + (1 - \\beta_2) \\cdot g_t^2$$\n",
    "\n",
    "### Step 2: Bias Correction\n",
    "\n",
    "$$\\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t}$$\n",
    "$$\\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t}$$\n",
    "\n",
    "### Step 3: Weight Decay\n",
    "\n",
    "$$\\theta_{\\text{decayed}} = \\theta \\cdot (1 - \\alpha \\cdot \\lambda)$$\n",
    "\n",
    "### Step 4: Update\n",
    "\n",
    "$$\\theta_{\\text{new}} = \\theta_{\\text{decayed}} - \\frac{\\alpha \\cdot \\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adamw_update(theta, gradient, m, v, t, \n",
    "                 lr=0.001, beta1=0.9, beta2=0.999, eps=1e-8, wd=0.01):\n",
    "    \"\"\"\n",
    "    Perform one AdamW update step.\n",
    "    \n",
    "    Args:\n",
    "        theta: current parameter value\n",
    "        gradient: gradient of loss w.r.t. theta\n",
    "        m: first moment estimate (momentum)\n",
    "        v: second moment estimate (adaptive LR)\n",
    "        t: timestep (starting from 1)\n",
    "        lr, beta1, beta2, eps, wd: hyperparameters\n",
    "    \n",
    "    Returns:\n",
    "        new_theta, new_m, new_v\n",
    "    \"\"\"\n",
    "    # Step 1: Update biased moments\n",
    "    m_new = beta1 * m + (1 - beta1) * gradient\n",
    "    v_new = beta2 * v + (1 - beta2) * gradient**2\n",
    "    \n",
    "    # Step 2: Bias correction\n",
    "    m_hat = m_new / (1 - beta1**t)\n",
    "    v_hat = v_new / (1 - beta2**t)\n",
    "    \n",
    "    # Step 3: Weight decay\n",
    "    theta_decayed = theta * (1 - lr * wd)\n",
    "    \n",
    "    # Step 4: Update\n",
    "    theta_new = theta_decayed - lr * m_hat / (math.sqrt(v_hat) + eps)\n",
    "    \n",
    "    return theta_new, m_new, v_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Updating One Parameter\n",
    "\n",
    "Let's walk through updating the first element of the `<BOS>` token embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example parameter\n",
    "theta = 0.024634      # Current value\n",
    "g = -0.352893         # Gradient (negative = increase to reduce loss)\n",
    "m_0 = 0.0             # Initial first moment\n",
    "v_0 = 0.0             # Initial second moment\n",
    "\n",
    "print(\"Initial State:\")\n",
    "print(f\"  θ (parameter)  = {theta:.6f}\")\n",
    "print(f\"  g (gradient)   = {g:.6f}\")\n",
    "print(f\"  m₀ (momentum)  = {m_0:.6f}\")\n",
    "print(f\"  v₀ (variance)  = {v_0:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Update biased moments\n",
    "m_1 = beta1 * m_0 + (1 - beta1) * g\n",
    "v_1 = beta2 * v_0 + (1 - beta2) * g**2\n",
    "\n",
    "print(\"Step 1: Update Biased Moments\")\n",
    "print(f\"  m₁ = {beta1} × {m_0} + {1-beta1} × {g:.6f}\")\n",
    "print(f\"     = {m_1:.6f}\")\n",
    "print()\n",
    "print(f\"  v₁ = {beta2} × {v_0} + {1-beta2} × {g:.6f}²\")\n",
    "print(f\"     = {v_1:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Bias correction\n",
    "m_hat = m_1 / (1 - beta1**t)\n",
    "v_hat = v_1 / (1 - beta2**t)\n",
    "\n",
    "print(\"Step 2: Bias Correction\")\n",
    "print(f\"  m̂ = {m_1:.6f} / (1 - {beta1}¹)\")\n",
    "print(f\"    = {m_1:.6f} / {1 - beta1}\")\n",
    "print(f\"    = {m_hat:.6f}\")\n",
    "print()\n",
    "print(f\"  v̂ = {v_1:.6f} / (1 - {beta2}¹)\")\n",
    "print(f\"    = {v_1:.6f} / {1 - beta2}\")\n",
    "print(f\"    = {v_hat:.6f}\")\n",
    "print()\n",
    "print(f\"Note: m̂ equals the gradient! (Expected for first step)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Weight decay\n",
    "theta_decayed = theta * (1 - learning_rate * weight_decay)\n",
    "\n",
    "print(\"Step 3: Weight Decay\")\n",
    "print(f\"  θ_decayed = {theta:.6f} × (1 - {learning_rate} × {weight_decay})\")\n",
    "print(f\"           = {theta:.6f} × {1 - learning_rate * weight_decay}\")\n",
    "print(f\"           = {theta_decayed:.6f}\")\n",
    "print()\n",
    "print(f\"Decay is tiny: {theta - theta_decayed:.9f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Compute update\n",
    "adaptive_lr = learning_rate / (math.sqrt(v_hat) + epsilon)\n",
    "update = m_hat * adaptive_lr\n",
    "theta_new = theta_decayed - update\n",
    "\n",
    "print(\"Step 4: Compute Update\")\n",
    "print(f\"  Adaptive LR = {learning_rate} / (√{v_hat:.6f} + {epsilon})\")\n",
    "print(f\"             = {learning_rate} / {math.sqrt(v_hat):.6f}\")\n",
    "print(f\"             = {adaptive_lr:.6f}\")\n",
    "print()\n",
    "print(f\"  This is {adaptive_lr/learning_rate:.2f}× the base learning rate!\")\n",
    "print()\n",
    "print(f\"  Update = {m_hat:.6f} × {adaptive_lr:.6f} = {update:.6f}\")\n",
    "print()\n",
    "print(f\"  θ_new = {theta_decayed:.6f} - ({update:.6f})\")\n",
    "print(f\"        = {theta_new:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"=\"*60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"  Before: θ = {theta:.6f}\")\n",
    "print(f\"  After:  θ = {theta_new:.6f}\")\n",
    "print(f\"  Change:    {theta_new - theta:+.6f}\")\n",
    "print()\n",
    "print(f\"The gradient was negative, so θ increased.\")\n",
    "print(f\"This will help reduce the loss!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating All Parameters\n",
    "\n",
    "We apply this same process to **every single parameter** in the model.\n",
    "\n",
    "Our model has **~2,600 parameters**:\n",
    "- Token embeddings: 6 × 16 = 96\n",
    "- Position embeddings: 5 × 16 = 80\n",
    "- Attention weights (Q, K, V per head): 2 × 3 × (16 × 8) = 768\n",
    "- Output projection: 16 × 16 = 256\n",
    "- FFN W1, b1: 64 × 16 + 64 = 1,088\n",
    "- FFN W2, b2: 16 × 64 + 16 = 1,040\n",
    "- Layer norm γ, β: 16 + 16 = 32\n",
    "- LM head: 6 × 16 = 96\n",
    "\n",
    "All of them get updated using AdamW."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why AdamW Works So Well\n",
    "\n",
    "1. **Automatic per-parameter learning rates**—parameters with large gradients get smaller effective rates\n",
    "\n",
    "2. **Momentum smoothing**—the first moment $m$ smooths out noisy gradients over time\n",
    "\n",
    "3. **Adaptive scaling**—$\\sqrt{\\hat{v}}$ in the denominator prevents instability\n",
    "\n",
    "4. **Clean weight decay**—regularization independent of gradient noise\n",
    "\n",
    "This is why AdamW is the default for training LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Complete Training Loop\n",
    "\n",
    "We've now completed **one full training step**:\n",
    "\n",
    "1. ✅ **Forward pass**—computed embeddings, attention, FFN, layer norm, and loss\n",
    "2. ✅ **Backward pass**—computed gradients for every parameter via backpropagation\n",
    "3. ✅ **Optimization**—updated every parameter using AdamW\n",
    "\n",
    "This is what training a neural network means. Repeat this loop thousands or millions of times:\n",
    "\n",
    "```python\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in data:\n",
    "        predictions = model(batch)        # Forward\n",
    "        loss = compute_loss(predictions)  # Loss\n",
    "        gradients = backpropagate(loss)   # Backward\n",
    "        adamw_update(parameters, grads)   # Optimize\n",
    "```\n",
    "\n",
    "Each iteration, the loss gets smaller. The model gets better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What We've Learned\n",
    "\n",
    "We calculated—by hand—a complete training step through a transformer:\n",
    "\n",
    "- **Forward pass**: embeddings → attention → FFN → loss\n",
    "- **Backward pass**: gradients via chain rule\n",
    "- **Optimization**: AdamW updates for ~2,600 parameters\n",
    "\n",
    "Real LLMs train on billions of tokens. GPT-3 trained on 300 billion tokens. Each token goes through this same process.\n",
    "\n",
    "But now you understand exactly what those calculations are doing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closing Thoughts\n",
    "\n",
    "You've made it through the entire pipeline.\n",
    "\n",
    "You've seen every matrix multiplication, every activation function, every gradient calculation, every weight update.\n",
    "\n",
    "Nothing was hidden. No magic. Just math.\n",
    "\n",
    "When someone says \"a transformer learns by gradient descent,\" you now know **exactly** what that means—down to the individual floating-point operations.\n",
    "\n",
    "You understand transformers not because someone explained it in abstract terms, but because you **calculated it yourself**.\n",
    "\n",
    "That's the difference between knowing about something and truly understanding it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
