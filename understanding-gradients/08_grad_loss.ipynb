{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Backward Pass Begins\n",
    "\n",
    "The forward pass is done. We fed \"I like transformers\" through our tiny transformer and got a loss of about 1.9—essentially random guessing. The model has no idea what it's doing.\n",
    "\n",
    "Now we need to fix that. We need to figure out how to adjust the ~2,600 parameters so the model does better next time.\n",
    "\n",
    "The tool for this is **backpropagation**—the algorithm that computes how much each parameter contributed to the final loss. Once we know that, we can nudge each parameter in the direction that reduces the loss.\n",
    "\n",
    "**The big picture:**\n",
    "\n",
    "For every parameter $\\theta$ in the model, we want to compute:\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial \\theta}$$\n",
    "\n",
    "This is the **gradient**—it tells us how much the loss would change if we increased $\\theta$ by a tiny amount. Positive gradient means increasing $\\theta$ increases loss (bad). Negative gradient means increasing $\\theta$ decreases loss (good).\n",
    "\n",
    "**The strategy:**\n",
    "\n",
    "We work backward from the loss. First we compute how the loss depends on the logits. Then how the logits depend on the hidden states. Then how the hidden states depend on the FFN. And so on, all the way back to the embeddings.\n",
    "\n",
    "This is the **chain rule** in action: $\\frac{\\partial L}{\\partial \\theta} = \\frac{\\partial L}{\\partial y} \\cdot \\frac{\\partial y}{\\partial \\theta}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Entropy + Softmax: A Beautiful Gradient\n",
    "\n",
    "Let's start at the very end of the computation graph. Our loss is:\n",
    "\n",
    "$$L = -\\log P(\\text{target})$$\n",
    "\n",
    "Where $P$ comes from softmax:\n",
    "\n",
    "$$P(i) = \\frac{\\exp(\\text{logit}_i)}{\\sum_j \\exp(\\text{logit}_j)}$$\n",
    "\n",
    "We need $\\frac{\\partial L}{\\partial \\text{logit}_i}$ for each vocabulary token $i$.\n",
    "\n",
    "**The derivation:**\n",
    "\n",
    "This requires some calculus, but the result is remarkably clean. Let's work through it.\n",
    "\n",
    "For the loss $L = -\\log P(t)$ where $t$ is the target:\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial \\text{logit}_i} = \\frac{\\partial L}{\\partial P(t)} \\cdot \\frac{\\partial P(t)}{\\partial \\text{logit}_i}$$\n",
    "\n",
    "The first term is straightforward:\n",
    "$$\\frac{\\partial L}{\\partial P(t)} = -\\frac{1}{P(t)}$$\n",
    "\n",
    "The second term (softmax derivative) depends on whether $i = t$:\n",
    "\n",
    "- If $i = t$: $\\frac{\\partial P(t)}{\\partial \\text{logit}_t} = P(t)(1 - P(t))$\n",
    "- If $i \\neq t$: $\\frac{\\partial P(t)}{\\partial \\text{logit}_i} = -P(t) \\cdot P(i)$\n",
    "\n",
    "Combining these:\n",
    "\n",
    "- If $i = t$: $\\frac{\\partial L}{\\partial \\text{logit}_t} = -\\frac{1}{P(t)} \\cdot P(t)(1 - P(t)) = -(1 - P(t)) = P(t) - 1$\n",
    "- If $i \\neq t$: $\\frac{\\partial L}{\\partial \\text{logit}_i} = -\\frac{1}{P(t)} \\cdot (-P(t) \\cdot P(i)) = P(i)$\n",
    "\n",
    "**The final formula:**\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial \\text{logit}_i} = P(i) - \\mathbb{1}[i = t]$$\n",
    "\n",
    "Where $\\mathbb{1}[i = t]$ is the indicator function: 1 if $i$ equals the target, 0 otherwise.\n",
    "\n",
    "This is one of the most elegant results in machine learning. The gradient is just: **predicted probability minus target probability**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T21:17:08.650690Z",
     "iopub.status.busy": "2025-12-10T21:17:08.650616Z",
     "iopub.status.idle": "2025-12-10T21:17:08.652643Z",
     "shell.execute_reply": "2025-12-10T21:17:08.652361Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "VOCAB_SIZE = 6\n",
    "D_MODEL = 16\n",
    "D_FF = 64\n",
    "MAX_SEQ_LEN = 5\n",
    "NUM_HEADS = 2\n",
    "D_K = D_MODEL // NUM_HEADS\n",
    "\n",
    "TOKEN_NAMES = [\"<PAD>\", \"<BOS>\", \"<EOS>\", \"I\", \"like\", \"transformers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T21:17:08.653523Z",
     "iopub.status.busy": "2025-12-10T21:17:08.653457Z",
     "iopub.status.idle": "2025-12-10T21:17:08.655735Z",
     "shell.execute_reply": "2025-12-10T21:17:08.655485Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass predictions:\n",
      "============================================================\n",
      "\n",
      "Position 0: <BOS>        → should predict I            (P = 0.1254)\n",
      "Position 1: I            → should predict like         (P = 0.1500)\n",
      "Position 2: like         → should predict transformers (P = 0.1728)\n",
      "Position 3: transformers → should predict <EOS>        (P = 0.1771)\n"
     ]
    }
   ],
   "source": [
    "# For this notebook, we'll use pre-computed probabilities from the forward pass\n",
    "# These are approximately what a randomly initialized model would produce\n",
    "probs = [\n",
    "    [0.1785, 0.2007, 0.1759, 0.1254, 0.1563, 0.1632],  # position 0: <BOS>\n",
    "    [0.1836, 0.1969, 0.1805, 0.1233, 0.1500, 0.1657],  # position 1: I\n",
    "    [0.1795, 0.2050, 0.1782, 0.1207, 0.1437, 0.1728],  # position 2: like\n",
    "    [0.1855, 0.2017, 0.1771, 0.1271, 0.1391, 0.1695],  # position 3: transformers\n",
    "]\n",
    "\n",
    "# Target tokens (what the model should predict at each position)\n",
    "targets = [3, 4, 5, 2]  # I, like, transformers, <EOS>\n",
    "\n",
    "# Current tokens (input at each position)\n",
    "tokens = [1, 3, 4, 5, 2]  # <BOS>, I, like, transformers, <EOS>\n",
    "\n",
    "print(\"Forward pass predictions:\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "for i, t in enumerate(targets):\n",
    "    prob_correct = probs[i][t]\n",
    "    print(f\"Position {i}: {TOKEN_NAMES[tokens[i]]:12s} → should predict {TOKEN_NAMES[t]:12s} (P = {prob_correct:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the Gradient\n",
    "\n",
    "Now let's compute $\\frac{\\partial L}{\\partial \\text{logit}}$ for each position and each vocabulary token.\n",
    "\n",
    "The formula is simple:\n",
    "- **For the target token**: gradient = $P(\\text{target}) - 1$ (always negative)\n",
    "- **For all other tokens**: gradient = $P(\\text{token})$ (always positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T21:17:08.673573Z",
     "iopub.status.busy": "2025-12-10T21:17:08.673502Z",
     "iopub.status.idle": "2025-12-10T21:17:08.675937Z",
     "shell.execute_reply": "2025-12-10T21:17:08.675660Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Gradients w.r.t. Logits (dL/dlogit)\n",
      "===========================================================================\n",
      "\n",
      "Position         <PAD>     <BOS>     <EOS>         I      like     trans\n",
      "---------------------------------------------------------------------------\n",
      "<BOS>          0.1785    0.2007    0.1759   -0.8746*   0.1563    0.1632 \n",
      "I              0.1836    0.1969    0.1805    0.1233   -0.8500*   0.1657 \n",
      "like           0.1795    0.2050    0.1782    0.1207    0.1437   -0.8272*\n",
      "transformers   0.1855    0.2017   -0.8229*   0.1271    0.1391    0.1695 \n",
      "\n",
      "* marks the target token (negative gradient)\n"
     ]
    }
   ],
   "source": [
    "def compute_loss_gradient(probs, target):\n",
    "    \"\"\"\n",
    "    Compute gradient of cross-entropy loss w.r.t. logits.\n",
    "    \n",
    "    dL/dlogit[i] = P(i) - 1  if i == target\n",
    "    dL/dlogit[i] = P(i)      otherwise\n",
    "    \n",
    "    Args:\n",
    "        probs: Probability distribution from softmax [vocab_size]\n",
    "        target: Index of the correct token\n",
    "    \n",
    "    Returns:\n",
    "        Gradient vector [vocab_size]\n",
    "    \"\"\"\n",
    "    grad = probs.copy()\n",
    "    grad[target] -= 1.0  # Subtract 1 from the target position\n",
    "    return grad\n",
    "\n",
    "# Compute gradients for all positions\n",
    "dL_dlogits = []\n",
    "for i in range(len(targets)):\n",
    "    grad = compute_loss_gradient(probs[i], targets[i])\n",
    "    dL_dlogits.append(grad)\n",
    "\n",
    "print(\"Loss Gradients w.r.t. Logits (dL/dlogit)\")\n",
    "print(\"=\"*75)\n",
    "print()\n",
    "print(f\"{'Position':<12} {'<PAD>':>9} {'<BOS>':>9} {'<EOS>':>9} {'I':>9} {'like':>9} {'trans':>9}\")\n",
    "print(\"-\"*75)\n",
    "for i, grad in enumerate(dL_dlogits):\n",
    "    target = targets[i]\n",
    "    row = f\"{TOKEN_NAMES[tokens[i]]:<12}\"\n",
    "    for j, g in enumerate(grad):\n",
    "        marker = \"*\" if j == target else \" \"\n",
    "        row += f\" {g:>8.4f}{marker}\"\n",
    "    print(row)\n",
    "print()\n",
    "print(\"* marks the target token (negative gradient)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Gradients\n",
    "\n",
    "Let's break down position 0 in detail. The model sees `<BOS>` and should predict `I`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T21:17:08.676805Z",
     "iopub.status.busy": "2025-12-10T21:17:08.676716Z",
     "iopub.status.idle": "2025-12-10T21:17:08.679184Z",
     "shell.execute_reply": "2025-12-10T21:17:08.678922Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed: Position 0 (<BOS> → should predict I)\n",
      "======================================================================\n",
      "\n",
      "Step 1: Current probabilities from softmax\n",
      "--------------------------------------------------\n",
      "  P(<PAD>       ) = 0.1785  \n",
      "  P(<BOS>       ) = 0.2007  \n",
      "  P(<EOS>       ) = 0.1759  \n",
      "  P(I           ) = 0.1254  ← TARGET\n",
      "  P(like        ) = 0.1563  \n",
      "  P(transformers) = 0.1632  \n",
      "  Sum = 1.0000\n",
      "\n",
      "Step 2: Compute gradients using formula: dL/dlogit = P(i) - 1[i==target]\n",
      "----------------------------------------------------------------------\n",
      "  dL/dlogit[<PAD>       ] = 0.1785 - 0 =   0.1785\n",
      "  dL/dlogit[<BOS>       ] = 0.2007 - 0 =   0.2007\n",
      "  dL/dlogit[<EOS>       ] = 0.1759 - 0 =   0.1759\n",
      "  dL/dlogit[I           ] = 0.1254 - 1 =  -0.8746\n",
      "  dL/dlogit[like        ] = 0.1563 - 0 =   0.1563\n",
      "  dL/dlogit[transformers] = 0.1632 - 0 =   0.1632\n"
     ]
    }
   ],
   "source": [
    "print(\"Detailed: Position 0 (<BOS> → should predict I)\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "print(\"Step 1: Current probabilities from softmax\")\n",
    "print(\"-\"*50)\n",
    "for j, name in enumerate(TOKEN_NAMES):\n",
    "    marker = \"← TARGET\" if j == targets[0] else \"\"\n",
    "    print(f\"  P({name:12s}) = {probs[0][j]:.4f}  {marker}\")\n",
    "print(f\"  Sum = {sum(probs[0]):.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"Step 2: Compute gradients using formula: dL/dlogit = P(i) - 1[i==target]\")\n",
    "print(\"-\"*70)\n",
    "for j, name in enumerate(TOKEN_NAMES):\n",
    "    is_target = 1 if j == targets[0] else 0\n",
    "    grad = probs[0][j] - is_target\n",
    "    print(f\"  dL/dlogit[{name:12s}] = {probs[0][j]:.4f} - {is_target} = {grad:>8.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why These Gradients Make Sense\n",
    "\n",
    "**Key insight**: Gradients point in the direction of *increasing* loss.\n",
    "\n",
    "When we do gradient descent, we *subtract* the gradient (times a learning rate):\n",
    "\n",
    "$$\\text{logit}_{\\text{new}} = \\text{logit}_{\\text{old}} - \\eta \\cdot \\frac{\\partial L}{\\partial \\text{logit}}$$\n",
    "\n",
    "So:\n",
    "\n",
    "**For the correct token** (gradient = $P - 1 \\approx -0.87$):\n",
    "- We subtract a negative number\n",
    "- That's the same as adding\n",
    "- The logit *increases*\n",
    "- Higher logit → higher probability ✓\n",
    "\n",
    "**For incorrect tokens** (gradient = $P \\approx +0.17$):\n",
    "- We subtract a positive number\n",
    "- The logit *decreases*\n",
    "- Lower logit → lower probability ✓\n",
    "\n",
    "Gradient descent naturally pushes the correct answer's probability up and everything else down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T21:17:08.679928Z",
     "iopub.status.busy": "2025-12-10T21:17:08.679846Z",
     "iopub.status.idle": "2025-12-10T21:17:08.682365Z",
     "shell.execute_reply": "2025-12-10T21:17:08.682090Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effect of one gradient descent step (learning rate = 0.1)\n",
      "======================================================================\n",
      "\n",
      "Token        Logit Before   Gradient  Logit After     Change\n",
      "----------------------------------------------------------------------\n",
      "<PAD>             -0.5000     0.1785      -0.5179    -0.0179  \n",
      "<BOS>              0.2000     0.2007       0.1799    -0.0201  \n",
      "<EOS>             -0.3000     0.1759      -0.3176    -0.0176  \n",
      "I                 -0.8000    -0.8746      -0.7125    +0.0875  ← TARGET\n",
      "like              -0.2000     0.1563      -0.2156    -0.0156  \n",
      "transformers       0.1000     0.1632       0.0837    -0.0163  \n",
      "\n",
      "The target token's logit increased; all others decreased.\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate what happens with a gradient update\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Pretend these are the logits (we'll make up some values)\n",
    "logits_before = [-0.5, 0.2, -0.3, -0.8, -0.2, 0.1]  # Position 0\n",
    "\n",
    "print(\"Effect of one gradient descent step (learning rate = 0.1)\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "print(f\"{'Token':<12} {'Logit Before':>12} {'Gradient':>10} {'Logit After':>12} {'Change':>10}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "logits_after = []\n",
    "for j, name in enumerate(TOKEN_NAMES):\n",
    "    grad = dL_dlogits[0][j]\n",
    "    new_logit = logits_before[j] - learning_rate * grad\n",
    "    logits_after.append(new_logit)\n",
    "    change = new_logit - logits_before[j]\n",
    "    marker = \"← TARGET\" if j == targets[0] else \"\"\n",
    "    print(f\"{name:<12} {logits_before[j]:>12.4f} {grad:>10.4f} {new_logit:>12.4f} {change:>+10.4f}  {marker}\")\n",
    "\n",
    "print()\n",
    "print(\"The target token's logit increased; all others decreased.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical Property: Gradients Sum to Zero\n",
    "\n",
    "Here's a nice verification we can do. The gradients at each position should sum to zero:\n",
    "\n",
    "$$\\sum_{i=0}^{V-1} \\frac{\\partial L}{\\partial \\text{logit}_i} = \\sum_{i=0}^{V-1} P(i) - 1 = \\left(\\sum_{i=0}^{V-1} P(i)\\right) - 1 = 1 - 1 = 0$$\n",
    "\n",
    "This makes sense: softmax is translation-invariant. Adding a constant to all logits doesn't change the probabilities (it cancels out in the normalization). So the gradient with respect to \"shift all logits equally\" should be zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T21:17:08.683031Z",
     "iopub.status.busy": "2025-12-10T21:17:08.682961Z",
     "iopub.status.idle": "2025-12-10T21:17:08.684726Z",
     "shell.execute_reply": "2025-12-10T21:17:08.684455Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification: Gradients sum to zero at each position\n",
      "==================================================\n",
      "\n",
      "Position 0 (<BOS>       ): sum = -0.0000000000  ✓\n",
      "Position 1 (I           ): sum = 0.0000000000  ✓\n",
      "Position 2 (like        ): sum = -0.0001000000  ✗ (off by -1.00e-04)\n",
      "Position 3 (transformers): sum = 0.0000000000  ✓\n"
     ]
    }
   ],
   "source": [
    "print(\"Verification: Gradients sum to zero at each position\")\n",
    "print(\"=\"*50)\n",
    "print()\n",
    "for i, grad in enumerate(dL_dlogits):\n",
    "    grad_sum = sum(grad)\n",
    "    status = \"✓\" if abs(grad_sum) < 1e-6 else f\"✗ (off by {grad_sum:.2e})\"\n",
    "    print(f\"Position {i} ({TOKEN_NAMES[tokens[i]]:12s}): sum = {grad_sum:>12.10f}  {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Magnitude Tells a Story\n",
    "\n",
    "Notice the *magnitudes* of the gradients:\n",
    "\n",
    "- **Target gradient**: ~$-0.85$ (large negative)\n",
    "- **Non-target gradients**: ~$+0.17$ (small positive)\n",
    "\n",
    "The target gradient is much larger in magnitude. Why?\n",
    "\n",
    "Because $|P(\\text{target}) - 1| = 1 - P(\\text{target})$ is large when the model is wrong. Our model assigns only ~15% probability to the correct answer, so $1 - 0.15 = 0.85$.\n",
    "\n",
    "**As training progresses:**\n",
    "- If $P(\\text{target}) \\to 0.9$: gradient becomes $0.9 - 1 = -0.1$ (small)\n",
    "- If $P(\\text{target}) \\to 0.99$: gradient becomes $0.99 - 1 = -0.01$ (tiny)\n",
    "\n",
    "The gradient naturally gets smaller as the model improves—the learning signal weakens when there's less to learn. This is a form of *adaptive learning*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T21:17:08.685373Z",
     "iopub.status.busy": "2025-12-10T21:17:08.685303Z",
     "iopub.status.idle": "2025-12-10T21:17:08.687293Z",
     "shell.execute_reply": "2025-12-10T21:17:08.687017Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How gradient magnitude depends on model confidence\n",
      "=======================================================\n",
      "\n",
      "   P(target)    Target Gradient Interpretation           \n",
      "-------------------------------------------------------\n",
      "        0.01            -0.9900 Very wrong, strong signal\n",
      "        0.10            -0.9000 Very wrong, strong signal\n",
      "        0.25            -0.7500 Uncertain, moderate signal\n",
      "        0.50            -0.5000 Getting it, weaker signal\n",
      "        0.75            -0.2500 Getting it, weaker signal\n",
      "        0.90            -0.1000 Confident, tiny signal   \n",
      "        0.99            -0.0100 Confident, tiny signal   \n"
     ]
    }
   ],
   "source": [
    "# Show how gradient magnitude changes with model confidence\n",
    "print(\"How gradient magnitude depends on model confidence\")\n",
    "print(\"=\"*55)\n",
    "print()\n",
    "print(f\"{'P(target)':>12} {'Target Gradient':>18} {'Interpretation':<25}\")\n",
    "print(\"-\"*55)\n",
    "\n",
    "test_probs = [0.01, 0.10, 0.25, 0.50, 0.75, 0.90, 0.99]\n",
    "for p in test_probs:\n",
    "    grad = p - 1\n",
    "    if p < 0.2:\n",
    "        interp = \"Very wrong, strong signal\"\n",
    "    elif p < 0.5:\n",
    "        interp = \"Uncertain, moderate signal\"\n",
    "    elif p < 0.8:\n",
    "        interp = \"Getting it, weaker signal\"\n",
    "    else:\n",
    "        interp = \"Confident, tiny signal\"\n",
    "    print(f\"{p:>12.2f} {grad:>18.4f} {interp:<25}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Gradient Tensor Shape\n",
    "\n",
    "Let's be explicit about what we've computed:\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial \\text{logits}} \\in \\mathbb{R}^{4 \\times 6}$$\n",
    "\n",
    "- 4 positions (we don't predict after `<EOS>`)\n",
    "- 6 vocabulary tokens\n",
    "\n",
    "Each entry tells us how much the loss would change if we increased that particular logit by a tiny amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T21:17:08.687941Z",
     "iopub.status.busy": "2025-12-10T21:17:08.687873Z",
     "iopub.status.idle": "2025-12-10T21:17:08.689403Z",
     "shell.execute_reply": "2025-12-10T21:17:08.689151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient tensor shape: [4, 6]\n",
      "  - 4 positions (0 through 3, predicting tokens 1 through 4)\n",
      "  - 6 vocabulary tokens\n",
      "  - Total: 24 gradient values\n"
     ]
    }
   ],
   "source": [
    "print(f\"Gradient tensor shape: [{len(dL_dlogits)}, {len(dL_dlogits[0])}]\")\n",
    "print(f\"  - 4 positions (0 through 3, predicting tokens 1 through 4)\")\n",
    "print(f\"  - 6 vocabulary tokens\")\n",
    "print(f\"  - Total: 24 gradient values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's Next: Backpropagating Further\n",
    "\n",
    "We've computed $\\frac{\\partial L}{\\partial \\text{logits}}$. This tells us how the loss depends on the raw prediction scores.\n",
    "\n",
    "But we can't directly modify the logits—they're computed from earlier layers:\n",
    "\n",
    "$$\\text{logits} = \\text{hidden} \\cdot W_{lm}^T$$\n",
    "\n",
    "To train the model, we need gradients for:\n",
    "1. **$W_{lm}$** (the language modeling head weights) - so we can update them\n",
    "2. **hidden states** - so we can backpropagate further into the transformer\n",
    "\n",
    "And then we'll continue backward through:\n",
    "- Layer normalization\n",
    "- Residual connections\n",
    "- Feed-forward network\n",
    "- Multi-head attention\n",
    "- Q/K/V projections\n",
    "- Embeddings\n",
    "\n",
    "The next notebook continues the backward pass through these layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-10T21:17:08.690057Z",
     "iopub.status.busy": "2025-12-10T21:17:08.689974Z",
     "iopub.status.idle": "2025-12-10T21:17:08.691795Z",
     "shell.execute_reply": "2025-12-10T21:17:08.691536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: Loss Gradients\n",
      "==================================================\n",
      "Shape: [4, 6] (4 positions × 6 vocab tokens)\n",
      "Formula: dL/dlogit[i] = P(i) - 1[i==target]\n",
      "Property: Each row sums to 0\n",
      "\n",
      "Ready for backpropagation through the model.\n"
     ]
    }
   ],
   "source": [
    "# Store gradients for next notebook\n",
    "grad_loss_data = {\n",
    "    'dL_dlogits': dL_dlogits,\n",
    "    'probs': probs,\n",
    "    'targets': targets,\n",
    "    'tokens': tokens\n",
    "}\n",
    "\n",
    "print(\"Summary: Loss Gradients\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Shape: [4, 6] (4 positions × 6 vocab tokens)\")\n",
    "print(f\"Formula: dL/dlogit[i] = P(i) - 1[i==target]\")\n",
    "print(f\"Property: Each row sums to 0\")\n",
    "print()\n",
    "print(\"Ready for backpropagation through the model.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "description": "The Backward Pass Begins\n\nThe forward pass is done. We fed \"I like transformers\" through our tiny transformer and got a loss of about 1.9—essentially random ...",
  "thumbnail": "/intro.png"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}